{"0-legal-notice": "Legal warning - Hey, thanks for using Remotive's API, we appreciate it! Please note that API documentation and access is granted so that developers can share our jobs further. Please do not submit Remotive jobs to third Party websites, including but not limited to: Jooble, Neuvoo, Google Jobs, LinkedIn Jobs. Please link back to the URL found on Remotive AND mention Remotive as a source in order to Remotive to get traffic from your listing. If you don't do that, we'll terminate your API access, sorry! Jobs displayed are delayed by 24 hours, the goal being that jobs are attributed to Remotive on various platforms. Displaying our jobs in order to collect signups/email addresses to show a listing constitutes a breach of our terms of services. We offer a private, paid-for API, please email us at hello(at)remotive(dot)io for more information (starting budget is $5k/mo). Please find out terms of services on https://remotive.io/api-documentation. Please note that there is absolutely no need to request Remotive Job data too frequently. Typically, you only need to GET Remotive job data through this API a couple of times a day (we advise max. 4 times a day). Our data is not changing much faster than that anyway. Note that excessive requests will be blocked. Many thanks (Rodolphe & the Remotive team!)", "job-count": 96, "jobs": [{"id": 1019437, "url": "https://remotive.io/remote-jobs/data/data-analyst-1019437", "title": "Data Analyst", "company_name": "Perblue", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-12-04T13:39:23", "candidate_required_location": "USA Only", "salary": "", "description": "<p><span style=\"font-weight: 400;\">PerBlue is looking for our next great aspiring </span><strong>Data Analyst</strong><span style=\"font-weight: 400;\"> to join our team of experienced mobile game creators. </span><span style=\"font-weight: 400;\">We\u2019re a growing independent studio whose free-to-play midcore mobile games are being played by millions of people around the world, including the award-winning</span> <a href=\"https://www.disneyheroesgame.com/\" rel=\"nofollow\"><em><span style=\"font-weight: 400;\">Disney Heroes: Battle Mode</span></em></a><span style=\"font-weight: 400;\">.</span></p>\n<p><span style=\"font-weight: 400;\">Our team brings together experience from major studios in the videogame and technology industries. Headquartered in Madison, Wisconsin, we also work remotely around the United States for an unmatched quality of life and work.</span></p>\n<p><span style=\"font-weight: 400;\">In this early-career opportunity, you\u2019ll add your skillset to our Business Intelligence team, providing the analysis and insights to help our team create amazing experiences for our fans around the world. You\u2019re a thoughtful aspiring data wizard who can manage mountains of mobile game data from a variety of sources and discover new ways of understanding and presenting insights to our team from across the studio. You\u2019re a creative thinker who brings a commitment to delivering results.</span><br><br></p>\n<p><strong>Principal Responsibilities</strong></p>\n<ul>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Support and nurture a culture of honesty, trust, and collaboration via data.</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Develop a strong understanding of our games, game design principles, core metrics and underlying assumptions; then work collaboratively to effectively question, test, and verify their truthfulness.</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Break down questions and requests for data into smaller, actionable plans to guarantee stakeholders will get their real questions answered.</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Improve existing Tableau dashboards and create new ones with a keen eye toward end user experience (ease of understanding, clarity, dashboard responsiveness, consistency, etc)</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Write SQL for data exploration, quick question-answer, and for more in-depth understanding via Tableau Data Sources, statistical analysis, etc.</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Do more thorough analyses when needed, including coming up with your own hypotheses, testing, revising, and ultimately providing data-driven, evidenced recommendations.</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Provide summaries of actionable takeaways that are understandable to non-technical colleagues while also providing empirical evidence and thought process for stakeholders wanting deeper understanding.</span></li>\n</ul>\n<p>\u00a0</p>\n<p><strong>Your experience</strong></p>\n<ul>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Demonstrated professional and/or academic projects writing analytic SQL queries (emphasis on SELECTs using JOINs, GROUP BY, window functions, etc., not so much INSERTs/UPDATEs)</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Experience with data visualization</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Ability to effectively communicate findings and recommendations, and connect with a variety of stakeholders</span></li>\n</ul>\n<p>\u00a0</p>\n<p><strong>Your personal attributes</strong></p>\n<ul>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Naturally curious, organized, and analytical\u00a0</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Truly loves making sense of large amounts of data</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Close attention to detail, process driven, and results-focused</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Outstanding written and verbal communication skills</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Self motivated, with a strong desire to learn new things</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Love of games and interest in game development pipelines</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Willingness to step in and help where needed</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Alignment with PerBlue\u2019s efforts to be a welcoming, inclusive and diverse workplace</span></li>\n</ul>\n<p>\u00a0</p>\n<p><strong>Additional qualifications to highlight in your application--\u00a0</strong></p>\n<ul>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Mobile and/or free-to-play game industry experience</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Tableau or other data exploration, visualization and interactive dashboarding software\u00a0\u00a0</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Postgres and/or Snowflake/Redshift cloud database querying</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Machine learning / artificial intelligence</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Data modeling</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Basic statistics (AB testing, confidence intervals, etc)</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Programming, specifically Python</span></li>\n<li style=\"font-weight: 400;\"><span style=\"font-weight: 400;\">Version control systems, especially Git</span></li>\n</ul>\n<p><span style=\"font-weight: 400;\">\u00a0</span></p>\n<p><strong>Compensation and Benefits</strong></p>\n<p><span style=\"font-weight: 400;\">We are a Remote First company headquartered in downtown Madison, Wisconsin with team members based around the US. We offer a competitive base salary; incentive bonus structure; 6+ weeks of paid time off; comprehensive health, dental, vision, disability, and life insurance; a well-matched 401k; flexible hours; and a variety of other perks including daily lunch delivery.</span></p>\n<p><span style=\"font-weight: 400;\">You'll be part of a passionate, welcoming, and collaborative team that has received several \u201cBest Place to Work\u201d awards by a variety of publications. We are headquartered in the vibrant neighborhood around beautiful downtown</span><a href=\"https://agreatermadison.wistia.com/medias/9qqqkii21k\" rel=\"nofollow\"><span style=\"font-weight: 400;\"> Madison</span></a><span style=\"font-weight: 400;\">.</span></p>\n<p><em><span style=\"font-weight: 400;\">No agencies, please. This is a pretty good description of this position\u2019s roles and responsibilities but is not a comprehensive job description, so duties and supervisors may change. We regret that we cannot consider visa sponsorship or candidates based outside of the United States or Canada for this position at this time.</span></em></p>"}, {"id": 1019965, "url": "https://remotive.io/remote-jobs/data/data-analyst-finance-1019965", "title": "Data Analyst, Finance", "company_name": "Trusted Health", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-12-04T05:40:42", "candidate_required_location": "USA Only", "salary": "", "description": "<div><strong style=\"font-size: 18px;\">What is Trusted Health?</strong></div>\n<div>\u00a0</div>\n<div>Trusted is a technology platform that connects healthcare professionals with flexible job opportunities at caregiving facilities across the country. Founded in 2017, Trusted has grown rapidly in pursuit of its mission to help people everywhere get care.\u00a0In just a few short years, Trusted has become one of the fastest growing companies in the history of the healthcare staffing industry and was recognized as one of Forbes\u2019 \u201cNext Billion Dollar Companies.\u201d Hundreds of thousands of clinicians have already signed up for Trusted\u2019s platform, connecting with &amp; working at healthcare facilities in all 50 states and the District of Columbia.</div>\n<div>\u00a0</div>\n<div>Trusted\u2019s platform isn\u2019t just a labor marketplace, it\u2019s also an end-to-end employment system allowing the company to scalably serve as the employer-of-record for the healthcare professionals that they work with. This encourages deep relationships between Trusted and its clinicians and provides Trusted with the opportunity to create a best-in-class experience throughout the entire candidate lifecycle, from acquisition through retention, while eliminating stressful, employment-related overhead from both our clinical professionals and healthcare partners.</div>\n<div>\u00a0</div>\n<div>Trusted\u2019s headquarters is located in San Francisco\u2019s Financial District, though it has taken a digital-first approach to building its workforce and the majority of their team resides outside the Bay Area.</div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 18px;\">What we're looking for</strong></div>\n<div>\u00a0</div>\n<div>We\u2019re looking for a Data Analyst to partner with our Finance and Strategy teams to deliver high-quality reporting and insights.\u00a0 The ideal candidate has a passion for finance and has worked with financial teams before.\u00a0 A good balance of SQL and BI experience is what you\u2019ll need to excel in this role.</div>\n<div>\u00a0</div>\n<div>You\u2019ll excel in a startup environment dealing with ambiguity and working closely with financial and strategy stakeholders to deliver insightful reporting.\u00a0 You\u2019re curious and don\u2019t mind deep-diving into perceived problems to see if we can solve them, or understand them better through data analysis.</div>\n<p><br><br></p>\n<div class=\"h3\">Your responsibilities</div>\n<ul>\n<li>Delivery accurate and timely data to the Finance and Strategy team to support their financial operating model and answer key business questions</li>\n</ul>\n<ul>\n<li>Work with the Finance and Strategy team leaders to identify the \u201cwhy\u2019s\u201d or the key drivers behind performance\u00a0Own and manage Finance &amp; Strategy oriented data updates, internal reporting, and KPI delivery</li>\n</ul>\n<ul>\n<li>Create robust self-service data models to help the Finance and Strategy team answer a variety of questions easily within Looker with easy to use and understand data structures</li>\n</ul>\n<ul>\n<li>Be the go-to for any financial data related question, the expert of the systems that deliver that data, and knowledgeable of how that data flows systematically</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">Who you are</div>\n<ul>\n<li><em>Deals Well With Ambiguity.</em> You\u2019re able to deal with ambiguity and drive clear outcomes.\u00a0 You enjoy the challenge of a complex problem and the thrill that comes with getting to the bottom of it.</li>\n</ul>\n<ul>\n<li><em>Business Oriented. </em>You have experience at SaaS companies or dealing directly with financial data.\u00a0 Your key stakeholders are Finance oriented and having this background will help you build successful working relationships.</li>\n</ul>\n<ul>\n<li><em>Attention to Detail.</em> You have a critical eye and a high bar for accuracy.\u00a0 You find yourself checking your work regularly to catch mistakes before delivery.</li>\n</ul>\n<ul>\n<li><em>Problem Solver.</em> You are interested in guiding team members towards deeper analyses and a more holistic understanding of their problems. You\u2019re comfortable recommending alternative solutions and deep-diving the data to find additional areas of value to answer questions and solve problems.</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">You have</div>\n<ul>\n<li>3+ years of analytics oriented experience</li>\n</ul>\n<ul>\n<li>1+ year focus on Financial/SaaS data</li>\n</ul>\n<ul>\n<li>2+ years of business intelligence experience (Looker, Tableau, etc)</li>\n</ul>\n<ul>\n<li>2+ years of SQL experience</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">We offer</div>\n<ul>\n<li>Stock options and competitive compensation package</li>\n</ul>\n<ul>\n<li>Paid vacation &amp; sick time, paid family leave, and flexible work hours</li>\n</ul>\n<ul>\n<li>Employer-paid health insurance, vision, and dental</li>\n</ul>\n<ul>\n<li>Mindfulness and fitness reimbursement</li>\n</ul>\n<ul>\n<li>Monthly cellular phone reimbursement</li>\n</ul>\n<ul>\n<li>Employer-sponsored 401k</li>\n</ul>\n<div><span style=\"font-size: 15px;\">#LIRemote</span></div>\n<div>\u00a0</div>\n<div><em>Trusted Health provides equal employment opportunity for all applicants and employees. All qualified applicants will be considered regardless of an individual\u2019s race, color, sex, gender identity or expression, religion, age, national origin, citizenship, physical or mental disability, medical condition, family care status, marital status, domestic partner status, sexual orientation, military or veteran status, or any other basis protected by federal, state or local laws.\u00a0If you cannot submit your application due to a disability, please email hello@trustedhealth.com; we will reasonably accommodate individuals with disabilities to the extent required by applicable law.</em></div>\n"}, {"id": 1017067, "url": "https://remotive.io/remote-jobs/data/data-engineer-1017067", "title": "Data Engineer", "company_name": "Ceros", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-12-03T09:40:19", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>About Ceros</strong></p>\n<p>Ceros is an experiential platform that empowers the creation of bespoke, immersive digital experiences without code. We\u2019re passionate about helping companies transform their static digital content into engaging experiences. From custom microsites to immersive interactive webpages, you can build it with Ceros. Publish and update live content and instantly embed it into your site or social media platforms such as Pinterest or Snapchat. Join us and be part of the movement to enable everyone to create experiences that matter.</p>\n<p>Our customers include some of the world\u2019s leading brands, such as Mashable, Bloomberg, Red Bull, United Airlines, and AIG.</p>\n<p>We are well-funded and institutionally-backed by prominent investors including Sumeru Equity Partners, Grotech Ventures, Greycroft, and Starvest Partners.</p>\n<p><strong>The Role</strong></p>\n<p>As a data engineer, you'll be handling the design and construction of scalable management systems, ensure that all data systems meet company requirements, and also research new uses for data acquisition. You should also know the ins and outs of the industry such as data mining practices, algorithms, and how data can be used.</p>\n<p>In order to stand out as a candidate, you should express humility and patience. Data engineering is about building the underlying infrastructure, and so being able to pass the limelight to someone else is imperative. We want to see candidates with mechanical tendencies and a desire to know how things work and to improve them. Furthermore, being able to listen to your colleagues is essential.</p>\n<p>We are looking for a person who can maintain, transform, analyze and extract valuable insights from our different data sources and make these insights available to various stakeholders across the company. We are looking for candidates with an entrepreneurial spirit that will always be looking for ways to improve our data infrastructure and make our data more accessible to the business.\u00a0</p>\n<p><strong>Key Responsibilities</strong></p>\n<ul>\n<li>Creating and maintaining the optimal data pipeline architecture</li>\n<li>Assembling large, complex sets of data that meet business requirements</li>\n<li>Identifying, designing and implementing internal process improvements including re-designing infrastructure for greater scalability, optimizing data delivery, and automating manual processes\u00a0\u00a0</li>\n<li>Building required infrastructure for optimal extraction, transformation and loading of data from various data sources using AWS and SQL technologies</li>\n<li>Working with stakeholders including design, product and executive teams and assisting them with data-related technical issues</li>\n<li>Optimizing data retrieval and developing dashboards, reports and other visualizations for stakeholders</li>\n<li>Creating and maintaining documentation about our databases and ETL processes\u00a0</li>\n<li>Optimizing our data infrastructure for performance, scalability, security and redundancy</li>\n<li>Developing insights and evangelizing the value of our data to other stakeholders</li>\n</ul>\n<p><strong>Practical stuff we anticipate you having</strong></p>\n<ul>\n<li>Excellent communication skills to interface with multiple departments and stakeholders</li>\n<li>Experience building and maintaining data infrastructure utilizing infrastructure as code (IaC) principles and technologies.</li>\n<li>Experience deriving insights through the use of predictive analytics and/or machine learning techniques</li>\n<li>Excellent knowledge of both SQL and NoSQL database technologies and their pros and cons\u00a0</li>\n<li>Deep knowledge of SQL and database design</li>\n<li>At least 3 years experience as a data engineer or in a similar role</li>\n<li>Knowledge of programming languages\u00a0 (e.g. Javascript and Python)</li>\n<li>Experience with ETL tools such as Matillion and AWS DMS.</li>\n<li>Experience with business intelligence (BI) and visualization tools (e.g. Metabase, Looker, Tableau, etc..)</li>\n<li>Experience with data-related cloud services (e.g. Redshift, Aurora, S3, Glue, DMS)</li>\n<li>Experience maintaining and working with Elasticsearch</li>\n</ul>\n<p><strong>What we\u2019re looking for from the heart</strong></p>\n<ul>\n<li>Be a self-starter and operate with an entrepreneurial spirit</li>\n<li>Identify things that need to be done and get them done</li>\n<li>Identify opportunities to help Ceros scale and implement them</li>\n<li>An eagerness to learn. We\u2019re looking for engineers who are able and eager to keep up with the pace of our rapidly evolving field</li>\n</ul>\n<p><strong>Key Things to Know</strong></p>\n<ul>\n<li>We want you to start ASAP\u00a0</li>\n<li>This is a full-time position</li>\n<li>This is a remote first role with the ability to work on east coast time; travel periodically to our NY offices and team meetups</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<ul>\n<li>Competitive salary</li>\n<li>Stock options</li>\n<li>Premium health insurance</li>\n<li>401K match</li>\n<li>Paid parental leave</li>\n<li>Unlimited vacation days</li>\n<li>Wellness Fridays (Half Day Fridays)</li>\n<li>Excellent gear (Macbook, external monitor, etc.)</li>\n<li>Stipend for WFH set-up</li>\n<li>Growth and learning opportunities</li>\n<li>Virtual experiences in which Cerosians can collaborate, educate, and create social connections with one another</li>\n</ul>\n<p>\u00a0</p>\n<p><em>At Ceros, we are deeply committed to the recruitment, retention, and growth of diverse talent; uniting people from unique backgrounds in our shared passion for unlocking creativity through technology.</em></p>\n<p><em>As an equal opportunity employer, we prohibit any unlawful discrimination against a job applicant on the basis of their race, color, religion, veteran status, parental status, gender identity or expression, transgender status, sexual orientation, national origin, age, disability or genetic information.\u00a0 We respect the laws enforced by the EEOC and are dedicated to going above and beyond in fostering diversity across our company.</em></p>\n"}, {"id": 1007766, "url": "https://remotive.io/remote-jobs/data/data-engineer-1007766", "title": "Data Engineer", "company_name": "Prezi", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-12-03T01:42:01", "candidate_required_location": "Europe Only", "salary": "", "description": "<p>Prezi is the zooming presentation software that uses an open canvas instead of traditional slides to help people explore ideas, collaborate more effectively, and create visually dynamic presentations. Founded in 2009, and with offices in San Francisco, Budapest and Riga, Prezi provides its users a visually engaging, personalized way to express their ideas anytime, anywhere.</p>\n<p>The company\u2019s vision extends well beyond authoring software alone into becoming the inspiration and enabler of world-changing ideas for people, organizations, and businesses. Prezi has enjoyed explosive growth and developed a rapid following of passionate users. More than 85 million people from over 190 countries use Prezi from their desktops, browsers and mobile devices. Prezi is rapidly adding new users each month, and more than 1 Prezi is created every second. The company has over 300 employees and is backed by premier investors, including Accel Partners, Sunstone Capital (based in Copenhagen), and TED. We are looking for a talented software engineer to join our Data Infrastructure Team.</p>\n<div class=\"h3\"><strong>Data @ Prezi</strong></div>\n<p>We believe that data analytics should be easy for both technical and non-technical people. We aim to create the tools, build the data platform and train our users to make this possible.</p>\n<p>To better understand our users we collect data from all parts of our product and push it to a Kafka cluster and ingest data to Amazon distributed storage S3. We then use open source tools like Apache Gobblin to further process and analyze our data. We collect around 1TB data/day. Analysts who are interested in the data can crunch the data using Zeppelin or can schedule jobs with our ETL system to process the data with Spark/Trino. Data is then exposed through Hive tables for further analyses and reporting. See more from <a href=\"%22https:/www.youtube.com/watch?v=Gao32khhF6w&amp;t=50s%22\" rel=\"nofollow\" target='\"_blank\"'>our talk at Big Things</a>.</p>\n<p>Prezi has offices in Berlin, Budapest, Riga, and San Francisco, but we are a remote first company. For this position, we are looking for someone in the European time zones, so you\u2019ll have the flexibility to work remotely from anywhere in Europe. You'll be reporting to <a href=\"%22https:/www.linkedin.com/in/kevekutner/%22\" rel=\"nofollow\" target='\"_blank\"'>Keve Kutner</a>, Engineering Manager.\u00a0</p>\n<div class=\"h3\">Responsibilities:</div>\n<ul>\n<li>Keep petabyte-scale data flowing through our pipeline. We have hundreds of data-analytics jobs running every day.</li>\n<ul>\n<li>Define best practices.</li>\n</ul>\n<li>Work closely together with our Data Team</li>\n<li>Design and build data architecture and related tooling including:</li>\n<ul>\n<li>Logging framework</li>\n<li>ETL and batch processing infrastructure</li>\n<li>Realtime data systems, data pipelines, pub/sub interfaces</li>\n<li>Data warehouse modeling and design</li>\n<li>BI tooling, OLAP</li>\n</ul>\n</ul>\n<ul>\n<li>Future proof our system to enable new business opportunities e.g. through machine learning</li>\n<li>Partner with Data Analysts, provide tools and guidance on schema modeling, query optimization</li>\n<li>Oversee data lifecycle, understand it\u2019s current and future use cases and build a scalable, maintainable solution</li>\n<li>Automate data quality assurance and provide best practices to teams.</li>\n<li>Work together with Product Teams and provide them simple APIs to push and pull data</li>\n</ul>\n<div class=\"h3\"><strong>If you have:</strong></div>\n<ul>\n<li>Experience with k8s (at scale)</li>\n<li>Bachelor\u2019s Degree in Computer Sciences or related field</li>\n<li>Minimum 3 years of experience in software engineering</li>\n<li>Fluency in a scripting language (e.g. Python)</li>\n<li>Familiarity with *nix environment and tooling (e.g. bash, ssh, git)</li>\n<li>Up-to-date knowledge about big data tools and techniques</li>\n<li>Experience developing and working with ETL pipelines</li>\n<li>SQL knowledge</li>\n<li>Strong interpersonal and communications skills; ability to consult, partner and work effectively with business partners and technical partners across functions</li>\n<li>Enthusiasm for DevOps: we write it, we run it!</li>\n<li>Excitement for building on open sourced tools as well as contributing to existing products</li>\n<li>Get it done behaviour: you are smart and quick with a focus on delivery</li>\n<li>Bravery to try, pilot and eventually productise new technologies</li>\n</ul>\n<p><strong>...then we would love to talk to you.</strong>\u00a0</p>\n<div class=\"h3\"><strong>Bonus point if you have:</strong></div>\n<ul>\n<li>Experience with Amazon Web Services or similar cloud provider</li>\n<li>Experience with continuous integration, configuration management</li>\n<li>Experience with data warehouse design and maintenance</li>\n<li>Background in statistics, data analysis, data science, and machine learning</li>\n</ul>\n<div class=\"h3\"><strong>What we offer you:</strong></div>\n<ul>\n<li>Deploy to production from day one</li>\n<li>A working environment that supports career and skill growth</li>\n<li>People who listen to your opinions and value them</li>\n<li>Remote-first attitude (but we also have a centrally located office in downtown Budapest)</li>\n<li>Receive stock options to become your own employer</li>\n<li>Be yourself - we are proud to be colorful!</li>\n</ul>\n<p class='\"p1\"'><br><br></p>\n"}, {"id": 1009472, "url": "https://remotive.io/remote-jobs/data/director-user-analytics-and-experience-1009472", "title": "Director, User Analytics and Experience", "company_name": "Dealer Policy", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-12-02T01:39:34", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>Director, Experience</strong></p><p>Reports to Chief Strategy Officer</p><p>Job Description</p><p>Remote, US, Eastern or Central Time Zones strongly preferred</p><p><strong>Job Overview</strong></p><p>As the Director of Experience, you will be responsible for growing and managing the performance of automotive retail dealership personnel (\u201cusers\u201d) who serve as lead referral sources for DealerPolicy Insurance.  In this highly dynamic role, you\u2019ll lead collaboration and creativity across analytical analysis, design, promotions, community development, and incentive structures to optimize worker performance outcomes.</p><p><strong>About Us</strong></p><p>DealerPolicy is a leader in the emerging Insurtech sector. With its seamless integration into the car buying process, the company\u2019s innovative solution enables car-buying customers the opportunity to purchase insurance by connecting them with licensed insurance agents while simultaneously completing the purchase of their new car. The company delivers these benefits through an industry-first combination of partnerships with car dealers, a growing insurance carrier network, and team of licensed insurance advocates.</p><p>Responsibilities</p><ul> <li>Owner of performance and engagement of dealership personnel to generate leads for DealerPolicy Insurance</li> <li>Lead User Engagement and Performance program by collaborating across Product, Marketing, BI/Analytics, and Operations teams</li> <li>Lead the journey of gaining proficiency and expertise in the practice of behavioral economics and performance optimization of dealership personnel; be a resource across departments.</li> <li>Take a hands-on and collaborative approach to end-user research, product design, data analysis, and financial and performance modeling to optimize worker outcomes, such as LTV modeling, acquisition and ongoing engagement cost modeling</li> <li>Optimize user engagement investment performance, model scenarios and facilitate executive decision making on alternative investment scenarios</li> <li>Optimize user engagement messaging, cadence, approach, and content across channels including email, SMS, in-app alerts, and in-app experiences</li> <li>Research and apply behavioral psychology to grow active users and user performance</li> <li>Translate the brand strategy into reality in the execution of product design and across campaigns</li> <li>Establish and develop peer-to-peer referral/recruitment channel for dealership personnel.  Own and manage direct-to-user business.  Lead teams to achieve business growth and performance objectives.</li> <li>Develop and deliver large scale automated personalization of engagement methods and tools to maximize effectiveness</li> <li>Build user community, tiered achievement recognitions and rewards, ongoing education, and other program elements that use behavioral and psychological approaches to optimize user outcomes. </li> <li>At its core this role is a product management role.  However there will be a heavy emphasis on strategy, modeling and performance management as well as messaging, incentive structures, community development and engagement.  For product design and development, this role will be in collaboration with and support of core product owners/managers, UX/UI, and marketing.  This role will be supported by our BI/data team for advanced ad hoc analysis and reporting needs and will be supported by and collaborate with marketing for the design and execution of campaigns.</li> </ul><p><strong>Requirements</strong></p><p><strong>Requirements</strong></p><ul> <li>Preferred: Graduate degree in behavioral economics, marketing analytics, marketing science, or operations research</li> <li>Minimum: Bachelor's degree in behavioral economics, marketing analytics, economics, finance, engineering, statistics, analytics, or a related field</li> <li>Three years of experience leading professionals and teams</li> <li>At least six years of work-related experience</li> <li>Three years of experience designing and developing incentive structures, online communities, digital consumer products, online experiences or any combination thereof</li> <li>Proven track record of structuring ambiguous problems, breaking down complex issues into logical units of work, and successfully leading teams to take ownership of those deliverables and execute successfully</li> <li>A self-motivated, high-energy individual who can easily function in a fast-paced, performance-driven environment</li> <li>Accustomed to working on multiple tasks in parallel and committed to meeting deadlines</li> <li>High level of attention to detail Intellectually curious with a demonstrated interest in learning.</li> <li>Demonstrated expertise in written and verbal communication and storytelling through charts and graphs and contextualizing key points through selected real-life examples</li> </ul><p><strong>Benefits</strong></p><p><strong>DealerPolicy offers a comprehensive Benefits Package, which includes</strong></p><ul> <li>Medical, Dental and Vision Insurance</li> <li>Health Savings Account with company match</li> <li>FSA, Dependent Care FSA and Commuter pre-tax benefit</li> <li>PTO allowance and holidays</li> <li>401(k) plan with company match</li> <li>Working remotely or Hybrid</li> <li>Paid Volunteer Hours</li> </ul><p><br></p><p><strong>About DealerPolicy</strong></p><p>DealerPolicy is the most trusted and complete digital insurance marketplace for automotive retailers and their valued customers. The company\u2019s innovative mobile technology enables car-buyers to view multiple insurance quotes and immediately connect with licensed insurance agents to purchase insurance. With an exclusive combination of partnerships among premier automotive retailers and data providers, an industry-best insurance carrier network, and access to DealerPolicy Insurance licensed agents, DealerPolicy is recognized for its place at the forefront of Insurtech. DealerPolicy Insurance is a licensed insurance agency, with licenses to operate in the lower 48 states. For more information, visit <a class=\"external\" href=\"http://www.dealerpolicy.com\" rel=\"nofollow\">www.dealerpolicy.com</a>.</p>"}, {"id": 1009230, "url": "https://remotive.io/remote-jobs/data/analytics-engineer-1009230", "title": "Analytics Engineer", "company_name": "Settle-inc", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-12-01T21:43:48", "candidate_required_location": "USA Only", "salary": "", "description": "<div><strong style=\"font-size: 11.5pt;\">Who We Are\u00a0</strong></div>\n<div>\u00a0</div>\n<div><span style=\"font-size: 11.5pt;\">Settle is a FinTech company on a mission to help small and medium businesses thrive by taking the worry out of cash flow management. We\u2019re building software making it super easy for finance teams to track, pay, and reconcile invoices. We pair that with lending products to offer our customers the power and flexibility to choose who, when, and how to pay their customers. </span></div>\n<div>\u00a0</div>\n<div><span style=\"font-size: 11.5pt;\">Our small but growing team (40+ today) was founded in San Francisco along with an engineering hub in Lviv, Ukraine and a new office in NYC. We\u2019re building a fully distributed team, and we support you working from where you are. We're well funded (Series-B) with backing by Kleiner Perkins, Founder\u2019s Fund, Max Levchin's SciFi Ventures, Ribbit Capital, and others. We provide competitive benefits, compensation, and equity. We're looking for motivated engineers who are eager to build something from scratch to delight our customers! Check out this </span><a class=\"postings-link\" href=\"https://techcrunch.com/2021/05/18/settle-raises-15m-from-kleiner-perkins-to-give-e-commerce-companies-more-working-capital/\" rel=\"nofollow\" style=\"font-size: 11.5pt;\">Techcrunch article</a><span style=\"font-size: 11.5pt;\"> and </span><a class=\"postings-link\" href=\"https://www.kleinerperkins.com/perspectives/settle-series-A\" rel=\"nofollow\" style=\"font-size: 11.5pt;\">Kleiner blog post</a><span style=\"font-size: 11.5pt;\">.\u00a0</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11.5pt;\">What You\u2019ll Do</strong></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11.5pt;\">Develop Datasets </strong><span style=\"font-size: 11.5pt;\">to inform strategic priorities, streamline operations, and develop insights.</span></div>\n<div><strong style=\"font-size: 11.5pt;\">Warehouse Development</strong><span style=\"font-size: 11.5pt;\"> - You will help develop the infrastructure that will be the foundation for the analytics and business stakeholders.</span></div>\n<div><strong style=\"font-size: 11.5pt;\">Key Metrics </strong><span style=\"font-size: 11.5pt;\">- You will help define and analyze key metrics for the company, such as customer lifetime value.</span></div>\n<div><strong style=\"font-size: 11.5pt;\">Product Analytics </strong><span style=\"font-size: 11.5pt;\">- You will build data pipelines to help our customer success, operations, rIsk, finance, and product teams be data-driven.\u00a0\u00a0</span></div>\n<div><strong style=\"font-size: 11.5pt;\">Own Data Pipelines </strong><span style=\"font-size: 11.5pt;\">- You will own end-to-end data pipelines and embrace data engineering best practices.</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11.5pt;\">What We Look For</strong></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11.5pt;\">Background in Data Engineering, Business Intelligence, or Data Analytics. </strong><span style=\"font-size: 11.5pt;\">Ideally 3+ years of experience building high quality datasets and insights.</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11.5pt;\">Data Modeling.</strong><span style=\"font-size: 11.5pt;\"> You are experienced in thoughtfully creating data models in a data warehouse or lake for analytics or data science use-cases. You also have experience in data delivery methodologies that are approachable and scalable.</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11.5pt;\">Data Pipeline Experience.</strong><span style=\"font-size: 11.5pt;\"> You have some experience in DBT/Airflow (or related technologies) to build data pipelines on a scheduled basis. Experience with data warehouse administration is a plus.</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11.5pt;\">Coding skills. </strong><span style=\"font-size: 11.5pt;\">You are comfortable writing your own SQL to answer questions. Ideally, you are fluent in all the SQL basics (joining, filtering, aggregating) and familiar with more advanced functions (ie window functions). You also have a basic understanding of GitHub best practices. While it\u2019s not required, knowledge of scripting languages for automation is a plus.</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11.5pt;\">Business System Familiarity</strong><span style=\"font-size: 11.5pt;\">. You have worked with business systems used by sales, marketing, finance, and/or customer success (for example Salesforce or Stripe). You\u2019ve worked with stakeholders and helped develop a data strategy to manage the flow of data and how it is consumed by the business.</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11.5pt;\">Adaptability</strong><span style=\"font-size: 11.5pt;\">. We\u2019re a startup and project needs can change quickly. You\u2019re someone that loves to jump into a new problem, learn what\u2019s needed, and solve it.</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11.5pt;\">Customer-centric and data-driven mentality. </strong><span style=\"font-size: 11.5pt;\">You care about the user, strive to understand their needs, and build to solve their problems. You pair that customer empathy with hard-nosed analytical skills using SQL, notebooks, and more to pull quantitative insights out of our datasets.</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11.5pt;\">Leadership. </strong><span style=\"font-size: 11.5pt;\">With rapid growth, we need and expect everyone to be a leader. You have the humility and self-awareness to understand and navigate the unknown. You hold yourself and others to a high bar. You enjoy mentoring and growing others.</span></div>\n"}, {"id": 1007845, "url": "https://remotive.io/remote-jobs/data/data-lake-engineer-1007845", "title": "Data Lake Engineer", "company_name": "Distributed", "category": "Data", "tags": [], "job_type": "contract", "publication_date": "2021-12-01T13:40:04", "candidate_required_location": "Anywhere", "salary": "", "description": "<p><strong>Who are we?</strong></p>\n<p>We're a software development company building the world's Elastic Workforce, reinventing work and challenging the assumption that a local team = the best team.</p>\n<p>We help businesses deliver technical projects better than ever before through our platform and on-demand Elastic Teams\u2122. Customers use our platform to scope any software project and are then paired with a fully managed Elastic Team of the world's best permanent freelancers that deliver it.</p>\n<p>We are backed by Guinness Asset Management, Fuel Ventures and Capita; just secured \u00a35m in Series A funding, and are growing at 500% per year. We are now hiring a number of exciting roles to add to our fully remote team for exceptional growth ahead.</p>\n<p>As a member of the team, you'll be working with scientists, engineers, product managers, salespeople and operational leaders from a diverse set of backgrounds who are challenging every assumption about the future of work.</p>\n<p>Want to know more? read:<a href=\"https://distributed.co/about\" rel=\"nofollow\"> https://distributed.co/about</a></p>\n<p><strong>The Role</strong></p>\n<p>Distributed needs to upgrade our data infrastructure in order to allow us to do things such as forecasting, deep analytics, automation and advanced data manipulation. The Data Lake Engineer will be responsible for the design &amp; build of this infrastructure, with guidance from our CIO and Technology Team.</p>\n<p><strong>Responsibilities</strong></p>\n<ul>\n<li>Design and create optimal data pipelines</li>\n<li>Design &amp; build the infrastructure or the Extraction, Transformation and loading of data from a wide variety of data sources</li>\n<li>Connect API endpoints to the central data infrastructure</li>\n<li>Assemble complex datasets in order to meet both functional and non-functional requirements</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<ul>\n<li>Advanced knowledge of SQL, relational databases and query authoring (SQL)</li>\n<li>Experience building and optimizing \u2018big data\u2019 pipelines</li>\n<li>Experience architecturing and building data lake, and ETL models</li>\n<li>Experience connecting system APIs such as: Salesforce, Xero and Azure DevOps</li>\n<li>Knowledge of best practices to ensure data integrity across diverse data sources</li>\n<li>A successful history of manipulating, processing and extracting value from disconnected datasets</li>\n<li>Experience with Azure big data and data lake tooling</li>\n<li>Experience with a Microsoft stack (.Net, PowerBI, SQL)</li>\n</ul>\n<p><strong>Compensation</strong></p>\n<ul>\n<li>Competitive compensation (dependent on experience)</li>\n<li>3 months fixed-term contract\u00a0</li>\n<li>Work from anywhere; we're a fully remote company</li>\n</ul>\n<p><em><strong>About us</strong></em></p>\n<p><em>Distributed is proud to be an equal opportunities employer. Employees and contractors, as well as prospective employees and contractors, will all be treated equally and fairly. Distributed is committed to ensuring no less favourable treatment is experienced by any current or prospective employee because of any of the protected characteristics under the UK Equality Act 2010 or equivalent local equality legislation.</em>\u00a0</p>\n<p><em>By submitting your application you give us permission to store and use the information from your CV and your answers to application questions.</em></p>\n"}, {"id": 813840, "url": "https://remotive.io/remote-jobs/data/full-stack-data-813840", "title": "Full Stack Data", "company_name": "Gitbook", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-30T17:41:45", "candidate_required_location": "", "salary": "", "description": "<div><span style=\"font-size: 18px\">\ud83e\udd14 Why are we opening this position?</span></div><div><br></div><div><a class=\"postings-link\" href=\"https://www.gitbook.com/\" rel=\"nofollow\">GitBook</a> is a modern documentation platform. Our ambition is to empower teams through a new document standard suited for modern work and collaboration.</div><div><br></div><div>GitBook is now used by over 1M users and thousands of teams such as Adobe, Netflix, Decathlon, or Google. With close to 25,000 sign-ups per month, <b>we're looking for our very first joiner in the Data team to actively contribute to our growth.</b></div><div><br></div><div><span style=\"font-size: 18px\">\ud83d\ude4c What will you be doing ?</span></div><div><br></div><div>You will be joining <a class=\"postings-link\" href=\"https://www.linkedin.com/in/remigonnu/en/?originalSubdomain=fr\" rel=\"nofollow\">Remi</a>, our Head of Data to spread insights across the company.</div><div>\u200c</div><div>As a product led company with high growth, we strongly believe that data should be involved in any decision process: from product to sales.</div><div><br></div><div>On the team philosophy, we want to bring people who could handle any part of the process: data engineering, data analytics and data science. It doesn't mean being an expert in all three fields but we believe that any data folks should aim to cover most of the scope.</div><br><br><div class=\"h3\">As a data team member, you will be involved in:</div><ul><li>having a full understanding of the data stack to maintain and improve it</li></ul><ul><li>being able to perform any product analysis using Amplitude</li></ul><ul><li>being a contributor to our early stage data warehouse</li></ul><ul><li>empower everyone in the company by making data available to them</li></ul><ul><li>pro-actively suggesting ideas and potential of growth through our business drivers</li></ul><br><br><div class=\"h3\"> \ud83d\udee0\ufe0f What environment will you be working on ? </div><ul><li><b>Data stack: </b>Amplitude, Segment, Airflow, DBT, BigQuery, Cloud Functions, Tableau, Zapier, Python, Stitch</li></ul><ul><li><b>Main 3rd party system: </b>Hubspot, Intercom, Stripe</li></ul><br><br><div class=\"h3\">\ud83d\ude4c You will be valued for : </div><ul><li>your <b>curiosity and passion</b> in the data field that pushed to work on any data pillars (engineer, analyst and scientist)</li></ul><ul><li>your ability to <b>build and maintain any data layer, </b>as you have past experience in the data enginery field</li></ul><ul><li>your ability to get insights from <b>product analytics data</b></li></ul><ul><li>your <b>determination</b> to make data the heart of GitBook success (evangelist part)</li></ul><ul><li>your knowledge of the <b>B2B SaaS industry</b> allowing you to quickly understand our challenge</li></ul><ul><li>your ability to jump into any GitBook members shoes to <b>understand their needs</b></li></ul><ul><li>your ability to successfully collaborate on cross-team work in a <b>remote and async environment</b></li></ul><ul><li><b>your proactivity</b>. You know how to bring new ideas to the table and you always present problems with potential solutions</li></ul><div>\u2728 <b style=\"font-size: 18px\">What's next ?</b></div><div>\u200c</div><div>First, we will take the time to review your application and we will get back to you within a week, regardless of our decision.</div><div><br></div><div>Here's what our process will look like:</div><div>1. Discover call (30min) with Morgane, our Talent Manager to ensure there is a correlation between GitBook's expectations, the role and your own expectations.</div><div>2. Deep dive (45min) with Remi (Head of Data) to discuss about role specifics such as required skills, knowledge, abilities as well as working environment, day-to-day life..</div><div>3. Work on a concrete project</div><div>4. Cross-team dive (45min) giving you the opportunity to debrief the take home while meeting with Remi (Head of Data) and Adrien (Head of Customer Experience).</div><div>5. The last discussion will be around cultural alignment. You will have the opportunity to meet with Samy (co-founder) to learn more about GitBook history, ambition and culture.</div><div><br></div><div><b style=\"font-size: 18px\">Learn more:</b></div><div>\u200c</div><div><span style=\"font-size: 0px\">\ud83d\udc65</span>\ud83d\udc65 <b>Every single team member is a value addition to our culture</b>, so it's important for us to state <a class=\"postings-link\" href=\"https://jobs.gitbook.com/life-at-gitbook/our-values\" rel=\"nofollow\">our values</a>. </div><div><br></div><div><span style=\"font-size: 0px\">\ud83d\udc4d</span>\ud83d\udc4d While joining GitBook, <b>you will also appreciate our <a class=\"postings-link\" href=\"https://jobs.gitbook.com/life-at-gitbook/perks-and-benefits\" rel=\"nofollow\">Perks &amp; Benefits</a>.</b></div>", "company_logo_url": "https://remotive.io/job/813840/logo"}, {"id": 1009464, "url": "https://remotive.io/remote-jobs/data/data-analytics-lead-1009464", "title": "Data Analytics Lead", "company_name": "Belvo", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-30T17:40:40", "candidate_required_location": "CEST timezone", "salary": "", "description": "<p>\u00a0<strong>A little bit about us:</strong></p>\n<p>\u00a0</p>\n<p>We are Belvo, a financial API platform with the bold vision of democratizing access to financial services in Latin America. We enable any company or developer to access and interpret their end-users\u2019 financial information. We are turning the rich and diverse Latin American financial ecosystem into a set of developer-friendly tools and APIs.<br><br></p>\n<p>We\u2019re a highly-technical, passionate and driven team. We are currently 70 people, projected to be 100+ by the end of 2021. Our team currently represents 15 nationalities and we have offices in Barcelona, Mexico City, and S\u00e3o Paulo - while a large portion of us works remotely.<br><br></p>\n<p>We are tackling a very challenging problem: connecting fintech innovators with legacy financial infrastructure. We strive to go beyond the limits of what is possible today and to do so in an elegant and developer-first way.</p>\n<p><br><br>Since starting our adventure in May 2019, we have raised $56m from the leading VC investors globally.<br><br></p>\n<p>You can read more about us and why we\u2019re doing what we\u2019re doing <a href=\"https://techcrunch.com/2020/02/18/meet-belvo-a-yc-backed-startup-building-a-financial-api-for-latin-america/\" rel=\"nofollow\" target=\"_blank\">here</a> and <a href=\"https://belvo.com/blog/belvo-turning-two-years-old/\" rel=\"nofollow\" target=\"_blank\">here</a>.</p>\n<p><br><br></p>\n<p><strong>About the team:</strong><br><br></p>\n<ul>\n<li>\n<p>We work in cross-functional, autonomous teams. We follow continuous delivery best practices executed on top of a modern technology stack.\u00a0</p>\n</li>\n<li>\n<p>Our products are built for developers, by developers. Technological excellence is at the heart of what we do.\u00a0\u00a0</p>\n</li>\n<li>\n<p>We are pragmatic and customer-focused. We strive to find the right set of trade-offs in order to validate our hypothesis as early as possible, iterating on our products based on customer feedback.\u00a0</p>\n</li>\n<li>\n<p>We communicate transparently. We do weekly all-hands where we get together to discuss company performance and goals.</p>\n</li>\n<li>\n<p>We are a flexible international team focused on creating cool stuff. Some of us prefer to work together in one of our offices and others prefer remote. For us, there's no difference as long as you have an excellent internet connection and are able to overlap with the team between 3 pm and 6 pm, CEST timezone.\u00a0</p>\n</li>\n<li>\n<p>Also, we are backed by some of the leading investors in Silicon Valley and Latin America, including Founders Fund, Kaszek Ventures, and YCombinator.<br><br><br></p>\n</li>\n</ul>\n<p><strong>Your challenge:</strong></p>\n<p>\u00a0</p>\n<p>On a daily basis Belvo retrieves millions of financial data points from people and business for our clients. One of the major needs we have is to properly monitor and analyze this data so we can improve the quality of our product and drive the research of new potential solutions for our clients.</p>\n<p>\u00a0</p>\n<p>As the Data Analytics Lead, you will:</p>\n<p>\u00a0</p>\n<ul>\n<li>\n<p>Be the point of contact for the entire company for all data quality related topics</p>\n</li>\n<li>\n<p>Lead a data analytics team, define its roadmap, organize the processes, tools and rituals to follow to achieve the goals of the company</p>\n</li>\n<li>\n<p>Work closely with customer success, product and engineering teams to understand the needs, questions and issues from our customers and how these can be addressed</p>\n</li>\n<li>\n<p>Ensure the data quality of our product by analyzing potential problems such as: transaction duplicates, missing information, fields validation</p>\n</li>\n<li>\n<p>Implement the proper monitoring tools and dashboards to provide the right metrics to track the status of the data quality</p>\n</li>\n<li>\n<p>Drive research on our data to post-process and calculate metrics that can be useful for our clients: analyze how to calculate credit metrics, comparisons between users or any interesting insight that could be relevant for the business</p>\n</li>\n<li>\n<p>Benchmark solutions from the market to understand how these can be applied at Belvo</p>\n</li>\n<li>\n<p>Be in conversations directly with clients to get their inputs and explain our processes</p>\n</li>\n<li>\n<p>Create proper tasks for the product and engineering teams to improve our product<br><br></p>\n</li>\n</ul>\n<p><strong>This position may be for you if:</strong><br><br></p>\n<ul>\n<li>\n<p>3+ years of experience as Data Analytics expert in a big data company</p>\n</li>\n<li>\n<p>Experience in fast-paced or startup environment working with Agile methodologies</p>\n</li>\n<li>\n<p>You have dealt with complex data problems that have required deep knowledge of data analysis\u00a0</p>\n</li>\n<li>\n<p>You are data driven, extremely organized and curious</p>\n</li>\n<li>\n<p>A bachelor\u2019s degree or equivalent in engineering, data science, mathematics or similar</p>\n</li>\n<li>\n<p>Deep SQL expertise and decent coding experience, with familiarity with different BI tools</p>\n</li>\n<li>\n<p>Excellent analytical/problem-solving skills</p>\n</li>\n<li>\n<p>Strong written and verbal communication skills with a talent for articulating customer challenges</p>\n</li>\n<li>\n<p>Excellent spoken and written English<br><br></p>\n</li>\n</ul>\n<p><strong>Amazing if:</strong><br><br></p>\n<ul>\n<li>\n<p>You have worked in fintech and/or an API based product</p>\n</li>\n<li>\n<p>You have experience working with remote teams</p>\n</li>\n<li>\n<p>You\u2019ve launched data science projects</p>\n</li>\n<li>\n<p>Spanish and/or Portuguese<br><br></p>\n</li>\n</ul>\n<p><strong>Our perks:</strong></p>\n<p>\u00a0</p>\n<p>\ud83d\ude80 Stock options (we are all owners and this is very important to us)</p>\n<p>\ud83d\udd06 Flexible working hours</p>\n<p>\ud83d\udd1d Remote friendly</p>\n<p>\ud83d\udc36 Pet friendly</p>\n<p>\ud83e\uddd8\ud83c\udffe\u200d\u2640\ufe0f Access to mental health service</p>\n<p>\ud83d\udc69\ud83c\udffb\u200d\u2695\ufe0f Health Insurance</p>\n<p>\ud83c\udf8a Paid time off on your birthday</p>\n<p>\ud83c\udf0e Work from any office twice per year</p>\n<p>\ud83d\udcbb Renew your laptop every 2 years</p>\n<p>\ud83d\ude4b Training Budget</p>\n<p>\ud83d\ude0e Team building events</p>\n<p>\ud83d\ude40 Bank holidays swap inside the same month</p>\n<p>\ud83d\udd0b Fitness/ wellness stipends</p>\n<p>\ud83d\ude80 Yearly offsite</p>\n<p>\ud83c\udf52 Fresh fruit every week, all-you-can-drink tea and coffee</p>\n<p>\ud83c\udf7b Friday happy hours after our weekly team meetings<br><br></p>\n"}, {"id": 1008841, "url": "https://remotive.io/remote-jobs/data/software-engineer-data-infrastructure-1008841", "title": "Software Engineer, Data Infrastructure", "company_name": "Dune Analytics", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-30T09:40:02", "candidate_required_location": "USA and Europe only", "salary": "", "description": "<p><strong>About Dune</strong></p>\n<p>Dune Analytics is on a mission to make crypto data accessible. We\u2019re a collaborative multi-blockchain analytics platform which is used by thousands of developers, analysts, investors and community members to better understand how the crypto ecosystem works.</p>\n<p>We\u2019re a fast growing team (3 to 21 in a year) working remotely from all across Europe and the US east coast. We cherish working on a product that empowers our users to create and do their own research. We\u2019re backed by some of the world's best investors, and are profitable.</p>\n<p>We\u2019re now at a crucial stage in our journey as the financial activity in crypto is exploding and need many more talented people to join the team.</p>\n<p>\u00a0</p>\n<p><strong>About the role</strong></p>\n<p>Dune is a small team building large things. We are generalist engineers who pick up any and all challenges together. We like to think and design before jumping into coding. We mainly use Go and TypeScript to build scalable systems that are easy to build upon.</p>\n<p>\u00a0</p>\n<p>As a software engineer in Dune focused on Data Infrastructure you will play a key role in ensuring our data platform scales to accommodate an ever-growing volume of public blockchain data. This is a role that involves thinking about large scale distributed systems and distributed databases, and is ideal for anyone passionate about those topics.</p>\n<p>\u00a0</p>\n<p>We are building a data platform that\u00a0</p>\n<ul>\n<li>\n<p>Can ingest and process large volumes of data</p>\n</li>\n<li>\n<p>Allows third parties to ingest data</p>\n</li>\n<li>\n<p>Facilitates performant SQL queries across datasets</p>\n</li>\n<li>\n<p>Will serve as the foundation for many, if not all, future Dune products</p>\n</li>\n</ul>\n<p>\u00a0</p>\n<p><strong>In this role you will:</strong></p>\n<ul>\n<li>\n<p>Design and develop distributed systems in a principled way and take part in high impact architectural decisions</p>\n</li>\n<li>\n<p>Engage in stimulating technical challenges in topics such as distributed systems, very large databases, SQL processing, data modelling, or systems performance</p>\n</li>\n<li>\n<p>Assume ownership of components within our data infrastructure, e.g., data ingestion, query performance, etc.</p>\n</li>\n<li>\n<p>Write code mostly in Go with a strong emphasis on good design and performance</p>\n</li>\n<li>\n<p>Collaborate in a respectful team environment that is fully distributed</p>\n</li>\n</ul>\n<p><strong>You might be a great fit for this role if:</strong></p>\n<ul>\n<li>\n<p>You are a strong generalist with fundamental computer science knowledge. You use this knowledge to easily adapt to new technologies and scenarios, and to find the right solutions for the problems at hand.</p>\n</li>\n<li>\n<p>You have an understanding of distributed system design, or the drive to learn if you\u2019re a more junior engineer. Our work is as much about understanding and designing systems as it is about coding in a particular language.</p>\n</li>\n<li>\n<p>You have great collaboration and communication skills. We work on the principle that the best output emerges from effective team work and respectful/constructive discussions.</p>\n</li>\n<li>\n<p>Coding experience in Go or similar language, along with a zeal for writing well-designed, testable software</p>\n</li>\n</ul>\n<p><strong>Not required but a plus if:</strong></p>\n<ul>\n<li>\n<p>You have a Master\u2019s or PhD degree in Computer Science, related field, or equivalent experience</p>\n</li>\n<li>\n<p>You have experience with database internals, massive data storage and processing, and systems performance</p>\n</li>\n</ul>\n<p>\u00a0</p>\n<p>\u00a0</p>\n<p><strong>Perks and Benefits</strong></p>\n<ul>\n<li>\n<p>Remote role with flexible working hours within a fully distributed team</p>\n</li>\n<li>\n<p>Competitive salary and equity package</p>\n</li>\n<li>\n<p>Regular offsites with the team</p>\n</li>\n<li>\n<p>5 weeks paid vacation + local public holidays</p>\n</li>\n<li>\n<p>Stipend for setting up your home office / co-working space</p>\n</li>\n</ul>\n"}, {"id": 1008784, "url": "https://remotive.io/remote-jobs/data/data-engineer-systems-1008784", "title": "Data Engineer, Systems", "company_name": "Standard", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-29T17:40:42", "candidate_required_location": "USA Only", "salary": "", "description": "<p style=\"min-height: 1.5em;\">At Standard Cognition, we\u2019re revolutionizing the way the world shops. By replacing cash registers with computer vision-powered checkout, we\u2019re creating a frictionless experience for shoppers. Since launching in 2017, Standard has contracts with multiple global retailers and is in the process of deploying our Standard Checkout solution across thousands of stores globally. We\u2019re backed by some of Silicon Valley\u2019s leading investors including Softbank, CRV, Initialized, EQT, Draper Associates and YCombinator. We just announced our <a href=\"https://www.grocerydive.com/news/standard-cognition-hits-1b-valuation-with-150m-investment/595278/?utm_source=Sailthru&amp;utm_medium=email&amp;utm_campaign=Issue: 2021-02-18 Grocery Dive [issue:32526]&amp;utm_term=Grocery Dive\" rel=\"nofollow\">series C in February 2021</a>! <br><br>Data is central to decision-making at Standard, and our data infrastructure plays a critical role in informing and evangelizing data-driven decision making across our operations, product, and engineering teams. <br><br>The Systems team colocates and queries data across many disparate engineering and operations teams at Standard. Their goal is to better understand product metrics like receipt accuracy. As a Data Engineer on the Systems team, you will be tasked with building data pipelines that underlie our product metrics. You will be focused on building ETL pipelines, data processing jobs and developing data schemas that enable downstream analysts and data scientists. <br><br>This is a <strong>FULL-TIME remote</strong> role located in the United States.<br><br><strong>What you'll do here:</strong></p>\n<ul>\n<li>Build and maintain the data infrastructure underlying our key product metrics like receipt accuracy</li>\n<li>Work with engineering and operations teams to ingest, join and clean data sources for downstream analysts/data scientists</li>\n<li>Support, spec and optimize the queries and datasets needed for downstream analysis</li>\n<li>Democratize our data by exposing derived data sources as APIs to other engineering and operations teams</li>\n</ul>\n<p style=\"min-height: 1.5em;\">\u00a0</p>\n<p style=\"min-height: 1.5em;\"><strong>Who you are:</strong></p>\n<ul>\n<li>You are an expert with building, maintaining and optimizing data pipelines, architectures, queries and datasets</li>\n<li>You have worked extensively with SQL and NoSQL databases</li>\n<li>You have experience querying large structure/unstructured datasets in SQL/Hive, Redshift, Spark etc.</li>\n<li>You are proficient in Python or another scripting language</li>\n<li>You are skilled in manipulating, processing and extracting value from large disconnected datasets</li>\n<li>You are accomplished in writing and maintaining ETL jobs for ingesting data across systems into a data warehouse</li>\n<li>You are knowledgable of GCP cloud services: Cloud SQL, BigQuery, Spanner</li>\n</ul>\n<p style=\"min-height: 1.5em;\"><br>Only meet some of these traits or experiences? We'd still love to hear from you! <br><br><strong>Why you might want to work with us:</strong></p>\n<ul>\n<li>We take care of you and your family with health, vision, and dental insurance.</li>\n<li>You will have the option to contribute to a 401k.</li>\n<li>You're excited to work on a product that will impact almost any consumer, almost anywhere.</li>\n<li>Standard is a remote first company. We trust you to get your job done in the location that works best for you.</li>\n<li>We dress casually. Some of us wear slippers in the office. In current work from home standings, we\u2019re super comfy.</li>\n<li>We believe in a culture of learning, and want to keep building our skills, experiences, and capabilities.</li>\n<li>We offer flexible work schedules. We trust our team to know how they will do their best work.</li>\n<li>We're family friendly. We want our teammates to focus on what they need to when they need to.</li>\n<li>We offer very competitive compensation, including equity in Standard, to each one of our employees.</li>\n</ul>\n<p style=\"min-height: 1.5em;\"><br>Standard provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion, sex, national origin, age, disability, genetics, sexual orientation, gender identity, or gender expression. We are committed to a diverse and inclusive workforce and welcome people from all backgrounds, experiences, perspectives, and abilities. <br><br>Not quite ready to apply? Send us an email at <a href=\"http://jobs@standard.ai\" rel=\"nofollow\">jobs@standard.ai</a>. Someone from the team will follow up to answer your questions.</p>\n"}, {"id": 1008284, "url": "https://remotive.io/remote-jobs/data/senior-data-engineer-matillion-1008284", "title": "Senior Data Engineer - Matillion", "company_name": "Aimpoint Digital", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-29T09:40:59", "candidate_required_location": "USA and UK only", "salary": "", "description": "<div class=\"h1\">What you will do</div>\n<p>You will become a trusted advisor working\u00a0hand-in-hand\u00a0with\u00a0our\u00a0software partners\u00a0and\u00a0clients.\u00a0You will engage in multi-disciplinary teams to deliver complex data / analytic\u00a0solution\u00a0across a variety of industries. These cases can range from:\u00a0</p>\n<ul>\n<li>Working with clients to assess\u00a0existing infrastructure and business processes\u00a0for modernization and performance enhancements</li>\n<li>Assisting\u00a0Matillion with executing tactical proof of concepts, migration assessments, guided trial programs, and pre-sales training session</li>\n<li>Designing and developing the analytical layer (data warehouse, data lake, ETL, ELT, etc.)\u00a0</li>\n<li>Enabling business analysts by understanding their processes and attentively listening to their needs to deliver impactful solutions</li>\n<li>Supporting data scientists and deploying machine learning models into production\n<ul>\n<li><em>Note: You will not be developing machine learning models</em><em>\u00a0or algorithms\u00a0</em></li>\n</ul>\n</li>\n<li>Optimizing non-performant databases, queries, pipelines, and ML models</li>\n</ul>\n<div class=\"h1\">Who we are looking for</div>\n<p>We are looking for people who deeply understand business problems and enjoy solving them. You are a driven self-starter who loves working with data and transforming it to pull out valuable business insights. You love building analytical tools that business users can leverage daily to do their jobs better. You are passionate about contributing to a growing team and establishing best practices. A Senior Data Engineer will also be expected to be able to manage a workstream within a client engagement.</p>\n<ul>\n<li>Degree educated in Computer Science, Engineering, Mathematics, or equivalent experience</li>\n<li>Strong exposure to Data Integration projects and good knowledge in ETL/ELT concepts and ETL/ELT tools \u2013 preferably a combination of Snowflake or Databricks, and Matillion</li>\n<li>Experience with other ETL/ELT platforms such as Fivetran, Talend, Informatica is also desirable</li>\n<li>Experience with managing stakeholders and collaborating with customers</li>\n<li>Strong written and verbal communication skills required</li>\n<li>3-5 years working with relational databases and query languages</li>\n<li>3-5 years building data pipelines in production and ability to work across structured, semi-structured and unstructured data</li>\n<li>3-5 years data modeling (e.g., star schema, entity-relationship)</li>\n<li>1+ years writing clean, maintainable, and robust code in Python, Scala, Java, or similar coding languages</li>\n<li>Expertise in software engineering concepts and best practices</li>\n<li>DevOps experience preferred</li>\n<li>Experience working with cloud platforms (AWS, Azure, GCP) and container technologies (Docker, Kubernetes) preferred</li>\n<li>Experience working with big data technologies (Spark, Hadoop) preferred</li>\n<li>Experience preparing data for analytics and following a data science workflow to drive business results preferred</li>\n<li>Consulting experience preferred</li>\n<li>Willingness to travel</li>\n</ul>\n<p><br>We are actively considering applicants that are fully remote within the US or the UK.\u00a0</p>\n"}, {"id": 1002327, "url": "https://remotive.io/remote-jobs/data/data-engineer-machine-learning-1002327", "title": "Data Engineer - Machine Learning", "company_name": "Goldstone Partners, Inc.", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-29T01:40:55", "candidate_required_location": "USA Only", "salary": "", "description": "<br><br><div class=\"h3\">Company Description</div><p>GeoVisual Analytics is changing the way crops are cared for in the US and around the world.\u00a0Using routine monitoring of fields with drones, in-field scouting, and satellites, we\u2019re applying our NASA-funded ML algorithms to analyze crop maturity, health, and predicted yields, helping farmers to dramatically reduce production uncertainties and increase profits.\u00a0We\u2019re headquartered conveniently between Boulder and Denver with a beautiful view of the front range right outside our window.\u00a0We\u2019re growing and looking for a few committed professionals to help us scale.\u00a0If you love the concept of combining drone-gathered imagery with Data Science then we might be your next great adventure.</p><p><strong>Our Values: Team Accountability, Social Impact, Intellectual Growth</strong></p><br><br><div class=\"h3\">Job Description</div><p>As a member of the GeoVisual team, your role is critical in building tools that consume and transform data sets into readily available information for analysis by the team. You understand the fundamentals of statistical methods that underlie machine learning and relish the opportunity to put them into practice.\u00a0Engineering data pipelines and visualizations that shed light on the complexities of our research is your passion. You have an entrepreneurial spirit and the idea of using data to help the world grow healthy food and protect its natural resources excites you.\u00a0If you are ready for your next challenge \u2013 let\u2019s talk!</p><p><strong>Your Values: Social Impact, Optimization, Intellectual Curiosity</strong></p><p><strong>Spend your days:</strong></p><ul><li>Creating and maintaining data pipe architecture optimizing ML data delivery to analyze growth and predict yields using drone, satellite, and weather data</li><li>Leveraging historical and real-time data that will allow informed labor and equipment scheduling</li><li>Productionizing models into UI for visualization to leveraging data</li><li>Designing, constructing, installing, testing, and maintaining highly scalable data pipelines</li><li>Getting involved in developing the creative vision, design, development, and delivery of some amazing remote sensing solutions</li></ul><br><br><div class=\"h3\">Qualifications</div><p><strong>What you\u2019ll bring to the table:</strong></p><ul><li>Undergraduate degree in Math or Engineering \u2013 Advanced degree preferred</li><li>At least 3 years of experience as a data engineer using Python and PyTorch</li><li>Demonstrated comprehensive experience with data modeling and data visualization \u2013 bonus points for GIS or Geo-Positioning exposure</li><li>High proficiency with AWS infrastructure</li><li>Knowledge of deep learning modeling techniques and trends, especially CNN based model architectures for computer vision applications</li><li>Ability to build processes that support data transformation, data structures, metadata, dependency, and workload management</li><li>Comfortable working within an Agile framework</li><li>Creative, articulate, and competent communication style \u2013 you deliver your messages clearly, concisely, and confidently</li><li>Strong interest in continuous learning and keeping up with emerging ML trends</li><li>You have worked in a small company so you know what it means to shift priorities and wear many hats</li><li>Desire to contribute to a team who is doing great things for humanity</li></ul><br><br><div class=\"h3\">Additional Information</div><p>Our team members enjoy:</p><ul><li>Salary $90 - $115k plus benefits</li><li>An engaged, committed team of thought leaders to hang out with every day</li><li>The opportunity to get in on the ground floor and help build a truly impactful company</li></ul><p>Goldstone Partners is helping this scrappy, and talented team find focused professionals who want to help improve crop yield for the global population.\u00a0Principals only please.\u00a0Applications welcome from US Citizens and Green Card Holders.\u00a0</p>"}, {"id": 1002832, "url": "https://remotive.io/remote-jobs/data/data-scientist-1002832", "title": "Data Scientist", "company_name": "CloudWalk", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-28T05:44:22", "candidate_required_location": "Anywhere", "salary": "", "description": "<div>This position is for adventurers, explorers, people that want to do something meaningful with their lives.</div>\n<div>If you are looking for just a month to month paycheck this position is not for you. Please do not apply.</div>\n<div>\u00a0</div>\n<div><span style=\"font-size: 24px;\">What is </span><strong style=\"font-size: 24px;\">CloudWalk</strong><span style=\"font-size: 24px;\">? </span></div>\n<div><strong>CloudWalk</strong> is an AI first company building its own technology to bring justice to the broken payment system in Brazil. We are building what one would call a <strong>\"self-driving bank\"</strong>. Our AI team aims to be the best so, if you have knowledge and grit, I invite you to read on, apply, and help bring fairness to our society.</div>\n<div>\u00a0</div>\n<div><span style=\"font-size: 24px;\">The AI team:</span>\u00a0</div>\n<div>The AI team at <strong>CloudWalk</strong> does not set clear goals or objectives to its participants. We allow them to explore and propose solutions to any interesting problem that can improve the life of our customers.</div>\n<div>\u00a0</div>\n<div>We are deeply inspired by the book <em>\"Why Greatness Cannot Be Planned: The Myth of the Objective\" </em>by Kenneth O. Stanley and Joel Lehman and, for this reason, we consider ourselves as a <strong>\"non-objective\"</strong> team, iterating fast and failing fast.</div>\n<div>\u00a0</div>\n<div><span style=\"font-size: 24px;\">People we like: </span></div>\n<div>We are looking for people who can manage themselves, that are critical thinkers, that are makers. We want problem solvers, not coders. No one will hold your hand and tell you what to do. We want people that are able to navigate chaos by themselves. <strong>CloudWalk</strong> is not a corp company, we don't want corp heads, we want the wild mads ones. We don't care if you didn't graduate from high school. As Elon Musk nicely said: <em>\"All that matters is a deep understanding of AI &amp; ability to implement NNs in a way that is actually useful\" </em></div>\n<div>\u00a0</div>\n<div><span style=\"font-size: 24px;\">Recruiting process outline:</span></div>\n<div>Our selection method is simple but hard. If you pass, you are definitely smart.</div>\n<div>1. Online technical assessment\u00a0</div>\n<div>2. Technical interview</div>\n<div>3. Cultural interviews</div>\n<div>\u00a0</div>\n<div>If you are not willing to do an online quiz, please do not apply.</div>\n<p><br><br></p>\n<div class=\"h3\">Technical Requirements:</div>\n<ul>\n<li>Deep understanding of Machine Learning and Data Science</li>\n</ul>\n<ul>\n<li>Ability to implement ML models in a way that is actually useful</li>\n</ul>\n<ul>\n<li>Communicate and debate in English. (Portuguese is only required if you are interested in working with NLP)</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">What will you do?</div>\n<ul>\n<li>Explore DS problems such: anomaly detection, natural language processing, complex networks , credit scoring, evolutionary algorithms and whatever else you think it will generate exponential impacts in our society today</li>\n</ul>\n<ul>\n<li>Build and deploy stuff every week</li>\n</ul>\n<ul>\n<li>Work on every aspect of ML-Systems</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">Benefits:</div>\n<ul>\n<li>Health insurance for you + 1 family member</li>\n</ul>\n<ul>\n<li>Life insurance</li>\n</ul>\n<ul>\n<li>Meal allowance\u00a0</li>\n</ul>\n<ul>\n<li>Internet/ electricity allowance</li>\n</ul>\n<ul>\n<li>30 days of paid vacation</li>\n</ul>\n<ul>\n<li>Full home office (live anywhere in the world)\u00a0</li>\n</ul>\n<ul>\n<li>ZenKlub Partnership for wellness</li>\n</ul>\n<ul>\n<li>Learning and Development resources</li>\n</ul>\n<ul>\n<li>Extended maternity and paternity leaves</li>\n</ul>\n<div><span style=\"font-size: 24px;\">Diversity and Inclusion:</span></div>\n<div>We believe in social inclusion, respect and appreciation of all people. We promote a welcoming work environment, where each CloudWalker can be authentic, regardless of gender, ethnicity, race, religion, sexuality, mobility, disability or education.</div>\n"}, {"id": 1003103, "url": "https://remotive.io/remote-jobs/data/senior-data-scientist-1003103", "title": "Senior Data Scientist", "company_name": "Verikai", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-28T05:44:19", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong><u>Company Introduction</u></strong></p>\n<p>Verikai is an insurance technology company changing the way the industry views risk with true predictive analytics. Our well-established database includes over 4,000 behavior attributes for 250+ million people in the United States and provides deep insight to these individuals\u2019 true health risks. With this data, we help insurance companies improve underwriting precision, speed and efficiency using alternative data and machine learning \u2013 and ultimately, we provide consumers and small businesses with greater access to a broader range of insurance products.</p>\n<p>Verikai isn\u2019t your typical startup. And we aren\u2019t looking for typical employees. For starters, we are a fully remote organization, meaning your home base can be your sofa, your favorite caf\u00e9, or a (wifi-equipped) cabin in the woods. All you need is your brain and a laptop\u2026and we provide the laptop. We\u2019re looking for people who want to do inspired work for a higher purpose. We are a growing and well-funded tech startup with a great product and even better ideas. If you want to make an immediate impact on the way the insurance industry operates while working in a fun, fast-paced and supportive environment, you\u2019ve come to the right place.</p>\n<p><strong><u>About the role</u></strong></p>\n<p>As part of the analytics team at Verikai, you will be in front of real customer issues and the data they generate in real time. You will be tasked with analyzing large-scale datasets and rewarded by witnessing your analysis been leveraged by the customers and creating tremendous value for them. You will have the opportunity to train yourself, with help from more senior team members, on using various data tools to analyze various types of complex datasets. You will also be able to manipulate our cutting-edge machine learning platform and improve it to build insightful models while learning and practicing how to build a truly operational model. Our start up culture will allow you to will work closely with all aspects of the business, and really shine on building up our analytics process and infrastructure.</p>\n<p><strong><u>Responsibilities</u></strong></p>\n<ul>\n<li>Develop cutting-edge machine learning algorithms, complement to our proprietary modeling platform, to extract greater lift from our data and provide more value for the customers</li>\n<li>Refine/tailor our proprietary machine learning algorithm to better fit into various scenarios presented by the customers and our own visions</li>\n<li>Constantly look for useful attributes to expand our core data assets from various data sources, like US census bureau, and validate the usefulness of the new data</li>\n<li>Utilize proper tools to clean customer data, like PySpark, R, Python, or Excel, to prepare for upcoming data analysis or modeling exercises</li>\n<li>Conduct descriptive analysis or other statistical analysis on customer data to identify valuable patterns to guide customers\u2019 business decisions. Analyze the data creatively so that the results directly meet what customers want</li>\n<li>Help prepare presentations or other customer-facing materials to demonstrate the value of our insights and to educate the customers on what we did and how we did it</li>\n<li>Present the results/findings/models to customers as a technical expert, an industry insider, and a company promoter</li>\n</ul>\n<p><strong><u>Skills and Qualifications</u></strong></p>\n<ul>\n<li>Bachelor\u2019s degree or above in Statistics, Mathematics, or Computer Science with 3-5 years of relevant working experience</li>\n<li>Demonstrates experience dealing with large datasets and creating models to solve real customer problems; Experience of modeling insurance data is a plus</li>\n<li>Deep knowledge in statistical modeling, knowing what\u2019s good and what\u2019s bad and how to tweak the parameters</li>\n<li>Proficient in Python or R, familiar with PySpark and Excel</li>\n<li>Critical and independent thinking, able to establish logical assumptions and think through scenarios</li>\n<li>Creative, open-minded, and positive attitude when challenges present themselves</li>\n<li>Not afraid of doing independent research, not settling on trivial progress</li>\n<li>Attention to detail; Sense of ownership in your work</li>\n<li>Effective communication, able to explain complex statistical terms and results to both technical and non-technical audiences</li>\n</ul>\n"}, {"id": 1002549, "url": "https://remotive.io/remote-jobs/data/senior-director-data-analytics-1002549", "title": "Senior Director, Data & Analytics", "company_name": "Dodge Construction Network", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-26T21:40:48", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>About Dodge Construction Network:</strong></p>\n<p>Dodge Construction Network leverages an unmatched offering of data, analytics, and industry-spanning relationships to generate the most powerful source of information, knowledge, insights, and connections in the commercial construction industry. The company powers four longstanding and trusted industry solutions\u2014Dodge Data &amp; Analytics, The Blue Book Network, Sweets, and IMS\u2014to connect the dots across the entire commercial construction ecosystem. Together, these solutions provide clear and actionable opportunities for both small teams and enterprise firms. Purpose-built to simplify the complex, Dodge Construction Network ensures that construction professionals have the information they need to build successful businesses and thriving communities. With over a century of industry experience, Dodge Construction Network is the catalyst for modern commercial construction.</p>\n<p>To learn more, visit: <a href=\"https://www.construction.com/\" rel=\"nofollow\" target=\"_blank\">construction.com </a></p>\n<p><strong>About the Role:</strong></p>\n<p>Are you passionate about changing the trajectory of the Commercial Construction market by deploying world-class digital and data science products and platforms that impact a $1T industry ripe for change? </p>\n<p>Are you a product leader who wants to shape the data products and capabilities for a leader in Commercial Construction data, blending customer intimacy, user-centricity, and business outcomes? </p>\n<p>Analytics and data science are a key focus of everything we do at Dodge Construction Network (DCN). We are modernizing our core data platforms, increasing visibility, and investing in scalable and reusable data science platforms and products built on our modern digital stack, to unlock new predictive/prescriptive insights that leverage the strength of our industry-leading data network. </p>\n<p>We are searching for a <strong>Senior Director, Data &amp; Analytics</strong>. The position can be remote. As the Senior Director, Data &amp; Analytics you will be responsible for partnering closely with the product and data platforms leaders to define, prioritize, and deploy the portfolio of use cases that can be solved at scale by leveraging different digital and data science platforms. </p>\n<p>You will shape and lead the discussions to create a capability-suite that enables transformative value for our customers and business. You will define and evangelize the data science and visualization product vision, strategy, and roadmap that are closely aligned with business strategy and priorities. You will work closely with the product engineering team to productize innovative practices and tools that help organizations transform their operations and increase their velocity. </p>\n<p>You will also create and nurture strong collaboration with key internal and external stakeholders. Collaborating with our partners, other product leaders, and the product engineering team, you will bring some of the most innovative never-been-done-before capabilities to DCN. </p>\n<p><strong>What you'll do:</strong> </p>\n<ul><li>         Define data science and visualization product vision, strategy, and build short / long term roadmap to enable transformative value in the Commercial Construction market.</li><li>         Lead and grow a strong team of DS&amp;A product managers, continuously raising the bar on performance, technical depth, product management results, and people leadership skills. </li><li>         Partner closely with business leaders to drive alignment on digital and data science strategy, priorities, deployment roadmap. </li><li>         Define and lead high-impact digital and data science portfolio of use cases (\u201cBook of Work\u201d), deploy and scale the advanced products and platforms in partnership with other product leaders and the product engineering team,</li><li>         Develop a deep understanding and empathy of the customer and stakeholder landscape. </li><li>         Build the voice of the users into product features. Own and drive the digital and data science product lifecycle from envision to deploy and operate </li><li>         Partner with business team to identify new opportunities, gather requirements, develop, and activate business cases. </li><li>         Champion and drive large strategic and complex projects, with executive visibility and many critical dependencies</li><li>         Define and build your own scorecard to continuously monitor and analyze roadmap durability, backlog health, velocity, quality, throughput, product performance and use the data to drive improvements </li><li>         Proactively and effectively communicate product strategy, roadmap, deployment status, value realization, and portfolio results with senior management. </li><li>         Create and nurture partnerships and alliances to expand our product footprint and speed up time-to-market for customers. </li></ul>\n<p><strong>What you'll bring:</strong></p>\n<ul><li>         Bachelor's degree in Engineering, Business, Technology, Computer Science with a focus on data science / advanced analytics / AI / Machine Learning, or related field. MBA or Advanced degree in these fields is preferred. </li><li>         8+ years of experience as a data/data science product management leader with a focus on stakeholder management, product strategy, prioritizing the use cases with business, and galvanizing the organization is required. </li><li>         Solid understanding of how to create actionable insights and use cases that can unlock significant value in terms of strengthening relationships, transforming customer experiences, generating cost-saving, revenue lift, capex reduction, and margin improvement </li><li>         Proven ability to work cross-functionally and build partnerships to deliver results and influence</li><li>         Proven track record of innovation and launching digital and data/data science products that achieve success and impact</li><li>         Proven ability to drive, manage, and influence multiple, competing priorities and projects in a fast-paced environment where continuous innovation is desired</li><li>         Demonstrated ability to develop business cases and track business benefits, including calculating return on investment (ROI), P&amp;L savings, cash flow impact, and other key business metrics in supply chain</li><li>         Excellent communication skills and ability to simplify complex topics for broad audiences across levels. Data-driven decision making and quantitative analysis skills</li><li>         Familiar with machine learning, AI, advanced analytics, and visualization applications</li><li>         Ability to manage senior, high performing staff</li><li>         Energetic, self-driven, passionate, accountable, keen on continuous learning</li><li>         Experience working in the Commercial Construction market is a plus. </li></ul>\n<p><strong>As a federal contractor and sub-contractor, Dodge Construction Network (DCN) is required to comply with Executive Order # 14042. This mandate requires all of our US-based DCN team members to be fully vaccinated against COVID-19 or have an approved exemption due to medical need or a sincerely held religious belief. We welcome candidate questions about this requirement.</strong></p><p><strong>We are committed to leveraging the talent of a diverse workforce to create great opportunities for our business and our people. EOE/AA. Minority/Female/Sexual Orientation/Gender Identity/Disability/Veteran</strong></p>\n"}, {"id": 1001924, "url": "https://remotive.io/remote-jobs/data/applied-data-scientist-1001924", "title": "Applied Data Scientist", "company_name": "Virtualitics", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-26T01:41:21", "candidate_required_location": "USA Only", "salary": "", "description": "<p>Location: <strong>Pasadena, CA HQ or</strong> <strong>Remote within USA</strong><br></p>\n<div class=\"h2\"><strong><u>The Role</u></strong></div>\n<p>Our fast-growing AI and Solutions teams are looking for a highly-motivated Applied Data Scientist to create compelling AI use-cases and solutions using Virtualitics platforms. You will be responsible for developing and enabling pre-sales demo's, data stories, and executing POC and prototypes of AI solutions. You will not only be helping sell our groundbreaking technology, but be a part of building a truly great company and culture.</p>\n<div class=\"h2\"><strong><u>Responsibilities</u></strong></div>\n<ul><li>         Applying recent and emerging trends in data science and AI in a diverse set of verticals (healthcare, biotech, energy, transportation, financial services, etc.). Work with the rest of the Solutions team and AI team to scope and build out amazing solutions concepts with VIP and Virtualitics Predict!</li><li>         Meet and pitch to executives and domain experts regularly. </li><li>         Collaborate with product teams to design and conceptualize new capabilities</li></ul>\n<div class=\"h2\"><strong><u>Qualifications</u></strong></div>\n<ul><li>         Degree in Computer Science/EE/Applied Math/Statistics or related</li><li>         2-3 years of experience in Python data science stack: numpy, pandas, scikit-learn, tensorflow/pytorch, pyspark, dask, matplotlib, seaborn, bokeh, etc. </li><li>         Excellent written and verbal communication skills. Comfortable with public speaking and presenting to executives. </li><li>         Patience and excitement to work with customers through proof-of-concepts. </li><li>         Experience with SQL/NoSQL or other databases (elasticsearch, graph databases, etc.).</li><li>         Experience with Git (or an alternative version control tool).</li><li>         A strong sense of ownership and accountability; eagerness to learn skills as needed by business focus</li><li>         Major Pluses: Consulting experience</li></ul>\n<div class=\"h2\"><strong><u>Compensation</u></strong></div>\n<p>We offer: </p>\n<ul><li>         Competitive base salary based on experience</li><li>         100% employer paid health benefit premiums (medical, dental, vision)</li><li>         Unlimited Paid Time Off</li><li>         Paid Time Off for National Holidays</li><li>         Stock options at sign-on</li><li>         401k plan</li><li>         Company equipment (Laptop computer, monitor, iPhone, etc.)</li><li>         Remote work from home</li></ul>\n<div class=\"h2\"><strong><u>About Us</u></strong></div>\n<p>Virtualitics is an augmented analytics company that helps our clients expand access to complex data to make their work more visual, collaborative, and actionable. Our powerful suite of augmented analytical tools allows our clients to harness the power of artificial intelligence (AI) and multidimensional visualizations to elevate their unstructured data analysis in a no-code environment and communicate their findings in ways that are instantly understood across their entire organization.\u00a0 </p>\n<p>Our patented technology is based on over 11 years of research at the California Institute of Technology and NASA/JPL and supported by a talented team of data scientists, designers, and engineers with several hundred publications in the field of artificial intelligence and data visualization. We have office space in Pasadena, CA, but are also open to fully remote candidates. </p>\n<p>Virtualitics is committed to building a company where every individual can bring their full impact and reach their fullest potential. Our mission is to build a diverse and inclusive environment where talented people of all cultures, ages, perspectives, opinions, education, backgrounds, races, gender identity, religions, orientations, abilities, and beliefs can grow and thrive with Virtualitics.</p>\n<p>Check us out at \u200bhttps://virtualitics.com/careers</p>\n<p></p>\n"}, {"id": 1003152, "url": "https://remotive.io/remote-jobs/data/commercial-analytics-engineer-1003152", "title": "Commercial Analytics Engineer", "company_name": "Urban Grid Solar Projects", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-25T17:43:49", "candidate_required_location": "USA Only", "salary": "", "description": "<p>Urban Grid Solar Projects is a leader in building clean energy solutions through utility-scale solar project development. Urban Grid has provided utilities and corporate clients with more 497MWac of clean energy to date and is actively developing a growing portfolio consisting of 9,300 MWac solar PV and 1,728 MWac energy storage throughout eleven states across the U.S. Our large-scale photovoltaic power plants are a vital source of clean, renewable energy that will help shape the diversified electric grid of the future.<br></p><p>At Urban Grid, we are focused on taking utility-scale solar power and energy storage facilities through the full development process, from land acquisition through initial commercial operation. We are actively developing a growing portfolio of projects that will require strong stakeholder relationships to be successful.<br></p><p><strong>Job Summary</strong></p> <p>The Commercial Analytics Engineer will contribute to the company\u2019s expanding standalone energy storage and renewable project portfolio as a subject matter expert on nodal market and congestion analysis. The Commercial Analytics Engineer will be responsible for identification of risk/opportunities, perform production cost modeling, perform fundamental analysis of congestion risk in nodal power markets, and transmission capacity/upgrade costs evaluation.</p> <p><strong>Responsibilities</strong></p> <ul> <li>Perform near and long-term nodal production cost studies to forecast the projected price impacts and performance of a changing generation fleet.</li> <li>Manage and maintain the latest model inputs (Generation data, fuel forecasts, monitored flowgates, etc.) in order to forecast LMPs.</li> <li>Perform detailed analysis of congestion in nodal markets.</li> <li>Perform and calibrate optimal power flow models to help with understanding congestion (i.e. PowerWorld).</li> <li>Develop and streamline processes and automation to support an efficient workflow.</li> <li>Articulate and explain nodal market model inputs/outputs to all project stakeholders with analysis, modelling and assessments of impacts.</li> <li>Represent Urban Grid in RTO/ISO stakeholder committees and processes.  <br> </li> </ul><p><strong>Requirements</strong></p><p><br></p> <ul> <li>Bachelor\u2019s Degree or higher in Engineering, Mathematics, Economics, or Finance preferred.</li> <li>Excellent oral and written communication skills are required. The candidate must possess the ability to translate complex analysis into executive summaries.</li> <li>Minimum of 1 year of experience in the electric utility, renewable industry, trading firm, or consulting firm.</li> <li>Proficient with PROMOD required.</li> <li>Proficient in running optimal power flow studies in PowerWorld required.</li> <li>Advanced Excel skills, Python, VBA, SQL, or other programming skills highly desired. </li> <li>Understanding or growing knowledge of power market pricing, basis risk, and congestion is required.</li> <li>Familiarity with FERC OATT and regional interconnection processes is preferred.</li> <li>Strong work ethic and exceptionally high work standards.</li> <li>Must have strong organizational capacity to simultaneously manage multiple projects with competing deadlines and be able to quickly adapt to changes and shift priorities to meet project needs and deadline.</li> <li>Ability to work independently.</li> </ul> <p><strong>Location</strong>: Remote working is acceptable for this role. Position may require periodic trips to Richmond, VA for team meetings or site visits to support engineering and development activities.</p><p><strong>Benefits</strong></p><p>Urban Grid offers comprehensive benefits including: Health, Dental, Vision, Flexible Spending Account, Retirement plan with matching and paid parental leave. Full-time position with compensation commensurate with experience.</p>"}, {"id": 1002535, "url": "https://remotive.io/remote-jobs/data/data-analytics-and-insights-consultant-1002535", "title": "Data Analytics and Insights Consultant", "company_name": "SlashData", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-24T21:40:56", "candidate_required_location": "Europe Only", "salary": "", "description": "<p>SlashData is the leading research company in the developer economy: We help the world understand developers and developers understand the world. We survey 40,000+ developers annually - across mobile, IoT, desktop, cloud, AR/VR, web, games, data science, and machine learning - to help clients such as Microsoft, Facebook, Google and Amazon understand who developers are, what tools they love or hate and where they are going next.</p>\n<p>We\u2019re now looking for a Data Analytics and Insights consultant who will maximise the value of our data aiming to discover the opportunities that will help our clients improve their business outcomes.</p>\n<p>You\u2019ll be working based in Europe or MEA, working remotely to support our distributed team.</p>\n<p><strong>Who we\u2019re looking for</strong></p>\n<p>As a Data Analytics and Insights Consultant you will have a minimum of three years of experience in statistical consulting, data analysis and modelling, data visualisation, and data project delivery to clients. Your command of the English language will be second to none.</p>\n<p>You will be fearless in data crunching and keen to unearth meaningful patterns, actionable insights and intriguing stories from the data. You will have undertaken many data analysis projects in the past where your novel insights and attention to detail would impress. You will have experience in working alongside clients, either internal to your company or external, to guide them from a vague brief to a research outcome that answers their business questions, and you will have a proven record of communicating your findings to a non-technical audience, eloquently narrating the story behind the numbers. You might not have worked in the software industry before, but you have a basic understanding of how it works.</p>\n<p>If you\u2019re that person, we\u2019d love to talk.</p>\n<p><strong>Requirements</strong></p>\n<p><strong>As a Data Analytics and Insights Consultant you will be:</strong></p>\n<ul>\n<li>Based in Europe</li>\n<li>Performing data and statistical analysis using a broad array of visual, predictive and spatial techniques to identify new data-driven insights and value opportunities.</li>\n<li>Translating business problems into research projects and finding actionable data-driven solutions.</li>\n<li>Writing up your findings in short and long reports including visually appealing graphs and deep insights based on your analysis, answering the \u201cwhy\u201d behind the \u201cwhat\u201d, not just reporting numbers</li>\n<li>Tracking the latest trends in the software developer ecosystem.</li>\n<li>Helping shape our research agenda and developer surveys, asking the right questions given our and our clients\u2019 research goals.</li>\n<li>Helping clients identify key business questions and translate them into research questions and projects.</li>\n<li>Interacting with clients to provide insightful answers to tough data problems, and to support them in custom data insights projects.</li>\n<li>Delivering briefings and webinars, and presenting our insights in conferences, meetups and events by communicating results and new ideas convincingly to others and selling the value.</li>\n<li>Supporting the rest of the analyst team in their data and research quests as needed.</li>\n</ul>\n<p><br><br></p>\n<p><strong>What skills we are looking for</strong></p>\n<ul>\n<li>A statistical consultant or data scientist, with a background in statistics, applied mathematics or computer science, with a track record of authoring research or other technical reports.</li>\n<li>Demonstrated experience in converting data to insightful information.</li>\n<li>An ability to tell signal from noise in the data, and answer the \u2018so what?\u2019 question behind the observed numbers and patterns.</li>\n<li>An ability to author data stories, comprehensively and in an unbiased way, with proven previous experience in authoring insights reports, blog posts or other published writing.</li>\n<li>Experience in working alongside stakeholders to define and execute a data research project</li>\n<li>Excellent writing skills (English), with the ability to effectively communicate complex insights to non-technical audiences.</li>\n<li>Advanced Excel skills.</li>\n<li>At least basic programming skills, preferably in Python including Pandas.</li>\n<li>At least a basic grasp of clustering and classification methodologies and models.</li>\n<li>Ability to visualise data effectively, producing eye-catching and easy-to-understand graphs.</li>\n<li>Very good presentation skills, preferably with experience in delivering client briefings.</li>\n<li>Comfortable working as part of a distributed team across four continents.</li>\n</ul>\n<p><br><br></p>\n<p><strong>Bonus Points for</strong></p>\n<ul>\n<li>Having software development experience as a hobby or past work.</li>\n<li>Following trends in the tech industry, either through past experience or as a hobby.</li>\n<li>Advanced Python skills.</li>\n<li>Advanced data modelling skills.</li>\n<li>Past experience of working with complex survey data.</li>\n<li>Past experience of consulting clients on complex data projects.</li>\n</ul>\n<p><br><br></p>\n<p><strong>Key success metrics</strong></p>\n<p>You will be successful in the role if in the first 6 months you have:</p>\n<ul>\n<li>Developed a basic understanding of how the developer-led landscape works.</li>\n<li>Actively contributed in shaping the research agenda and questionnaire of the upcoming Developer Economics survey.</li>\n<li>Authored at least two research reports, carrying out all data analysis and background research as needed.</li>\n<li>Actively participated in at least one client research project.</li>\n<li>Delivered at least one client briefing or webinar to our high standards.</li>\n<li>Actively supported the rest of the analysts team, by reviewing other team mates\u2019 work.</li>\n<li>Supported our developer outreach and sales teams, promptly responding to any requests relevant to your work.</li>\n<li>Become a dependable team mate.</li>\n</ul>\n<p><br><br></p>\n<p><strong>Benefits</strong></p>\n<p>What we offer</p>\n<ul>\n<li>Opportunity to make a difference as part of the leading research company in the developer economy</li>\n<li>Part of an entrepreneurial company that's raising the bar, and calling the trends of the developer economy</li>\n<li>Opportunity to work with some of the biggest tech brands in the world</li>\n<li>International team, great work atmosphere &amp; flexible working environment</li>\n<li>Competitive salary + bonus twice yearly based on performance</li>\n<li>You will never work on your birthday</li>\n<li>Annual training budget to develop your skills and career</li>\n<li>Home office set up budget</li>\n<li>Annual allowance to spend on co-working with your colleagues</li>\n<li>Monthly book allowance from Amazon, on any book you like</li>\n<li>Spotify Premium subscription or Netflix vouchers</li>\n</ul>\n"}, {"id": 1003210, "url": "https://remotive.io/remote-jobs/data/data-engineer-web-scraper-1003210", "title": "Data Engineer - Web Scraper", "company_name": "The Dyrt", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-24T17:40:03", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>The Dyrt is the largest digital camping platform in the world.</strong> Every second, a new user visits The Dyrt to access our community-driven campground information.</p>\n<p>If you love the outdoors and want to be part of a fast-growing consumer app,\u00a0 you're in the right place.</p>\n<p><strong>The Role</strong></p>\n<p>As a Web Scraping focused Data Engineer, you will be responsible for identifying new sources of information, extracting, and ingesting data from those sources using web crawling and other tools. In this role you will own the creation process of these tools, services, and workflows to improve crawl/ scrape analysis, reports and data management. We will rely on you to test the data and the scrape to insure accuracy and quality. You will own the process to identify and rectify any issues with breaks as well as scale scrapes as needed.</p>\n<p>This position will <strong>report to the VP of Engineering</strong>.</p>\n<p><strong>We're looking for people who:</strong></p>\n<ul>\n<li>Are great communicators \u2014 Effective communication is key to how we work. We value patience and empathy in our product planning, support, and day-to-day relations.</li>\n<li>Work well both collaboratively and independently</li>\n<li>Are ready to learn and share knowledge \u2014 Everyone comes to our company with their own set of skills and experiences. Cross-training, mentorship, and curiosity all help us build better products.</li>\n</ul>\n<p><strong>Key Responsibilities:</strong></p>\n<ul>\n<li>Identify new sources of campgrounds to aid in filling our lead generation funnel</li>\n<li>Extract and verify data ingested from various websites\u00a0</li>\n<li>Develop tooling to efficiently monitor websites for changes and produce clean changesets</li>\n<li>Maintain and scale scraping infrastructure as needed</li>\n</ul>\n<p><strong>Experience and Requirements:</strong></p>\n<ul>\n<li>Experience running large scale web scrapes</li>\n<li>Solid Python knowledge</li>\n<li>Familiarity with Linux/UNIX, HTTP, HTML, Javascript and Networking</li>\n<li>Familiarity with techniques and tools for crawling, extracting and processing data (e.g. Scrapy, pandas, mapreduce, SQL, BeautifulSoup, etc).</li>\n<li>Familiarity with extracting data from publicly available API endpoints</li>\n<li>Experience with system monitoring/administration tools</li>\n<li>Experience with version control, open source practices, and code review</li>\n<li>Experience with applications designed to display archived web content</li>\n</ul>\n<p><strong>Extra Credit:</strong></p>\n<ul>\n<li>Experience with Scrapy, Mechanize or other scraping tools</li>\n</ul>\n<p>Not sure you meet all of the requirements, but are passionate about the outdoors and have product management experience?\u00a0 We'd still love to hear from you!</p>\n<p><strong>Working Here</strong></p>\n<p>The Dyrt is built by campers, for campers\u2014whether you're new to camping or have been camping your whole life.\u00a0</p>\n<p>We encourage everyone to spend more time outside, including employees. We offer competitive market-rate salaries, a generous vacation plan, and we even pay employee bonuses for using The Dyrt in the wild.</p>\n<p>This is a full-time remote position. Employees are expected to have high-speed internet and a professional working environment sufficient for clear video conferencing during regular working hours. Many of our employees work virtually from Portland, OR but we're flexible on location and encourage all to explore. Our founders even <a href=\"https://www.fox21news.com/news/camping-couple-develops-popular-app-to-help-plan-trips/\" rel=\"nofollow\">work from their van</a>.</p>\n<p>The Dyrt is an equal opportunity workplace. We are especially proud to have a female founder and a higher percentage of female employees than the national average for tech companies. We believe that the outdoors are for everyone, and are committed to building an inclusive platform and community that encourages, supports, and celebrates all people interested in camping.</p>\n<p>Interested candidates should submit a cover letter and resume.</p>\n<p><strong>About The Dyrt</strong></p>\n<p>The Dyrt was started in Portland, OR, is venture-backed, and has 40-50 employees working virtually around the U.S.</p>\n<p>\u00a0</p>\n"}, {"id": 993098, "url": "https://remotive.io/remote-jobs/data/petabyte-technology-inc-senior-data-engineer-993098", "title": "Petabyte Technology Inc: Senior Data Engineer", "company_name": "Loeb.nyc", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-23T17:40:20", "candidate_required_location": "USA Only", "salary": "", "description": "<p>About the company:</p>\n<p>Petabyte Technology is a well funded, fast growing startup, combining best tech talent with pet industry veterans. We build data driven solutions to bring veterinarians and pet parents together on a single platform. For veterinarians, Petabyte brings best-in-class practice management software, Rhapsody, with industry leading veterinary vocabulary, mobile workflow, and scalability for corporate groups of all sizes, as well as best in class analytics solutions to unlock full potential of the practice. For pet parents, Petabyte brings a best-in-class mobile app, Boop, a membership-based experience to deeply engage with their veterinarians. Through Boop, pet parents have seamless access to book appointments, manage their pets medical records, sign-up for wellness/insurance programs, and ultimately build a rich, long-term relationship with their veterinarians. Petabyte is industry first by combining pet parents and veterinarians onto a single platform, serving the entire per industry with best in class software. Join our growing team and help us transform the pet industry!</p>\n<p>About the role:</p>\n<p>You will be a part of an amazing, fast growing team, working on flagship products of the company, Rhapsody and Analytics. As lead data engineer will own one of the key subsystems, processing and categorizing all the incoming data. You will be tasked with analyzing complex unstructured data sets, making sense of that data, creating efficient ingesting pipelines to convert the data into a format our system understands. Solving those kinds of problems will require creative thinking, ability to work independently and pation to solve complex data problems.</p>\n<p><strong>Requirements</strong></p>\n<p>Qualifications:</p>\n<ul>\n<li>Computer Science degree or equivalent</li>\n<li>Solid understanding of algorithms and data structures</li>\n<li>5+ years of professional software development experience</li>\n<li>5+ years of programming experience with Java/JavaScript</li>\n<li>Proven experience working with modern SQL/NoSQL databases</li>\n<li>Proven experience working with large and complex data sets</li>\n<li>Proven experience building and supporting complex data processing pipelines</li>\n<li>Proven experience discovering and optimizing data processing solutions</li>\n<li>Proven experience in applying machine learning on large unstructured data sets</li>\n<li>Ability to think independently, solving data puzzles and making sense of unstructured data</li>\n<li>Mentoring junior developers</li>\n</ul>\n<p>Preferred Qualifications:</p>\n<ul>\n<li>Experience in training machine learning models for NLP</li>\n<li>Experience in training machine learning models for schema discovery and entity categorization</li>\n<li>Working with GCP</li>\n<li>Experience working with Kubernetes</li>\n<li>Experience working with Node.js</li>\n<li>Experience developing software for the medical industry</li>\n<li>Working with distributed teams in different timezones</li>\n</ul>\n"}, {"id": 993542, "url": "https://remotive.io/remote-jobs/data/engineering-manager-database-toolkit-993542", "title": "Engineering Manager - Database Toolkit", "company_name": "Timescale", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-23T05:41:28", "candidate_required_location": "Anywhere", "salary": "", "description": "<p>Timescale is building the world\u2019s next great database company on top of industry-standard PostgreSQL and we need your help!\u00a0 We are hiring an engineering manager to build and manage our Database Toolkit team responsible for our <a href=\"%22https:/github.com/timescale/timescaledb%22\" rel=\"nofollow\">TimescaleDB</a> developer <a href=\"%22https:/github.com/timescale/timescaledb-toolkit%22\" rel=\"nofollow\">toolkit</a>, which focuses on analytics, developer ergonomics and performance for developers.\u00a0\u00a0\u00a0</p>\n<p>TimescaleDB is our open source Postgres extension that enables SQL to be scalable for time series data.\u00a0 It provides automatic partitioning across time and space as well as full SQL support.\u00a0 The toolkit enable developers to easily perform more complicated tasks across their datasets, including <a href=\"%22https:/github.com/timescale/timescaledb-toolkit/blob/main/docs/percentile_approximation.md%22\" rel=\"nofollow\">Percentile Approximation</a>, <a href=\"%22https:/github.com/timescale/timescaledb-toolkit/blob/main/docs/lttb.md%22\" rel=\"nofollow\">LTTB</a>, <a href=\"%22https:/github.com/timescale/timescaledb-toolkit/blob/main/docs/hyperloglog.md%22\" rel=\"nofollow\">Hyperloglog</a> and <a href=\"%22https:/github.com/timescale/timescaledb-toolkit/blob/main/docs/asap.md%22\" rel=\"nofollow\">ASAP Smoothing</a>.\u00a0\u00a0</p>\n<p>If you love building and managing high-performing product teams in a dynamic, fast-paced, growth-minded startup environment, this is the right role for you.\u00a0 We are growing a global, fully distributed team that recruits, develops and promotes people with diverse backgrounds, experiences and views. We believe when people are included and feel appreciated, it creates a culture where people can do meaningful and impactful work. This inspires fearless ideas, innovation and amazing outcomes.\u00a0</p>\n<p><strong>What you\u2019ll do</strong></p>\n<p>As an engineering manager at Timescale, you will have the opportunity to manage top-notch engineers creating the next generation time series database.\u00a0 The Database Toolkit team is responsible for tools that make complicated database functions easier for developers.\u00a0 Your team will be experimenting with and building operators designed to make analytics across time series data easier.\u00a0\u00a0</p>\n<p>Engineering managers at Timescale are responsible for the overall operation of the team.\u00a0 You will be working directly with the engineers on your team to ensure they have the ability to grow in their career and feel fulfilled in their work.\u00a0 You will also be working to define and iteratively improve team processes with high-quality, rapid iteration of product features in mind.\u00a0 You will be working directly with the product manager to ensure roadmap items are properly defined, groomed, estimated and delivered.\u00a0 You will work with engineering and product managers from other teams to ensure any dependencies are scheduled and met.\u00a0\u00a0</p>\n<p>At Timescale, we value diverse talent.\u00a0 You will be the hiring manager for any roles open on your team.\u00a0 You will work with a recruiter to build a pipeline of diverse, talented individuals who will help Timescale grow.\u00a0 You will manage the hiring process for your roles, creating the hiring and sourcing plan, building an interview panel, and ultimately making the final decision on hiring.\u00a0 Ideally, you will bring a strong network of potential candidates with you to Timescale.\u00a0</p>\n<p><strong>Key qualities in the successful candidate</strong></p>\n<p>You should be intimately familiar with everything it takes to develop, build, deploy and operate modern software.\u00a0 You should have a significant track record of successful product launches.\u00a0 The people on your previous teams love working with you and have no problem giving positive feedback.\u00a0 You have a strong track record of delivering high-quality software on a schedule.\u00a0 You are able to manage people with empathy and respect and have tough conversations in a professional way.\u00a0</p>\n<p>Though coding experience is not required for this role (and we don\u2019t expect engineering managers to write or review code), you should have a good idea of how software is architected and be able to communicate effectively with engineers and other technical staff about technical issues related to your team and the software they are building.\u00a0 We value managers with a variety of backgrounds.\u00a0 We are looking for managers who take care of the people on their team and work to build processes and discipline to deliver excellent products for our customers.\u00a0\u00a0</p>\n<p>Timescale has an amazing culture built on strong values. \u00a0 We have learner mindsets and think like owners. We\u2019re kind to each other, and support each other. We achieve together. We are colleagues, here to do the best work of our lives.</p>\n<p>Timescale is a fully remote company, and this is a remote job. We're hiring from anywhere that makes sense for managing remote employees across time zones in western Europe and the eastern United States.</p>\n<p><strong>Benefits &amp; Compensation</strong></p>\n<p>We offer globally competitive salaries.\u00a0 Our benefits support our people and their families and we strive to provide premium benefits such as flexible time off and resources you need to support you in doing the best work of your career.\u00a0</p>\n<p><strong>How to Apply</strong></p>\n<p>Please submit an application through our careers site.</p>\n<p>Introduce yourself to us as a colleague and share some recent work that you\u2019re especially proud of. Tell us why you want this job and why you\u2019d like to work at Timescale. We value good writers, so be yourself, be creative, and have fun.</p>\n<p>If you've participated in open source, dev ops, or PostgreSQL, please include links to pull requests, bug reports, feature pitches, or any other public engagement. Open-source participation is by no means a requirement, but if it's something you've done, we'd love to look at it!</p>\n<p><strong>What Happens Next?</strong> \u00a0</p>\n<p>We regularly review resumes and pick the most promising for a 30 minute initial conversation.\u00a0 Upon a successful first call, you will speak with the hiring manager for 60 minutes to get a better understanding of your background and how you will apply it to Timescale.\u00a0 If you and the hiring manager decide to continue the conversation, you will be scheduled with a panel of interviewers.\u00a0 The final decision will be made by the hiring manager.\u00a0</p>\n"}, {"id": 993762, "url": "https://remotive.io/remote-jobs/data/lead-data-engineer-993762", "title": "Lead Data Engineer", "company_name": "AhoyConnect", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-22T13:40:59", "candidate_required_location": "Anywhere", "salary": "", "description": "<p><strong>About Ahoy:</strong></p>\n<p>We believe community-led is the \u2018next big thing\u2019 for how creators, startups, and enterprises grow, but... today, community managers lack the understanding of what really happens inside their audience and what value it brings. That is why we\u2019re building <a class=\"external\" href=\"https://www.ahoyconnect.com/\" rel=\"nofollow\">AhoyConnect</a> - a community data intelligence platform, that enables organizations to understand, grow, engage, automate, and derive value from their audiences.</p>\n<p>We are a fully remote team that values transparency, clear communication, and the discussion of facts and opinions. Also, we\u2019ve just closed our Seed round and we\u2019re looking for exceptional talent to join us on the journey to becoming the global tool of choice for community-led companies.</p>\n<p>We're looking for an exceptional Lead Data Engineer who will keep making sure our software is on the way to becoming impeccable! Does that sound like you? Read along! \ud83d\ude80</p>\n<p><strong>Requirements</strong></p>\n<div class=\"h3\">We would love you to:</div>\n<ul>\n<li>Design and build scalable and efficient ELT pipelines</li>\n<li>Take care of our warehousing and data modeling</li>\n<li>Ensure data consistency and performance of our data pipelines</li>\n<li>Closely liaise with our Backend Engineering Team &amp; Data Team</li>\n<li>Advocate best practices and well tested, reliable data pipelines</li>\n<li>Review code of commits, feedback, discussing ideas, take the time to learn yourself and teach others</li>\n</ul>\n<p><strong>Our Stack:</strong></p>\n<ul>\n<li>AWS Cloud</li>\n<li>Apache Airflow &amp; DBT</li>\n<li>Python &amp; SQL</li>\n<li>PostgreSQL, MongoDB, Snowflake</li>\n</ul>\n<div class=\"h3\"><strong>You\u2019re a perfect candidate if you have:</strong></div>\n<ul>\n<li>4+ years experience in data engineering roles 4\ufe0f\u20e3\u2795</li>\n<li>Advanced knowledge of Python and SQL \ud83d\udc0d</li>\n<li>Experience with cleaning, wrangling, and flattening non-normalized data (e.g. nested JSONs) \ud83e\uddfd</li>\n<li>Be able to solve problems without us holding your hands and turn ideas into elegant solutions \ud83d\udc69\u200d\ud83d\udcbb\ud83e\uddd1\u200d\ud83d\udcbb</li>\n<li>Experience using Git version control (we use Github) \ud83d\udd79</li>\n<li>Great communication (we use Slack &amp; Notion) \ud83d\udde3</li>\n<li>Friendly attitude, and an interest in the latest tech, and a passion for learning \ud83d\udcda</li>\n</ul>\n<p><strong>Nice but not essential:</strong></p>\n<ul>\n<li>Experience with data streaming solutions &amp; distributed data processing</li>\n<li>Experience with building custom integrations (APIs)</li>\n<li>DataOps skills</li>\n<li>Knowledge of Ruby</li>\n<li>Experience with a remote full-time role</li>\n<li>Watched the TV show 'Silicon Valley' at least twice \ud83d\ude0e</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<div class=\"h3\"><strong>Why choose Ahoy?</strong></div>\n<ul>\n<li>We believe in people over processes, results over tasks</li>\n<li>We just closed our Seed round with the leading VCs from the region, launched the product, and onboarded first clients. This is just the first, tiny step - we aim to build a successful global business that will shape the future of community-led growth. We want you to have an impact and be a part of this journey!</li>\n<li>You will have a lot of flexibility and autonomy - we trust you to tell us how things should be done, not the other way round.</li>\n<li>We've been remote before it was cool and will stay remote-first forever</li>\n<li>We run retreats (both before and after covid) \u2013 e.g., we've spent more than a month in Southeast Asia with the whole team. Next stop? Mallorca! \u2600\ufe0f</li>\n<li>You will work with extremely driven and collaborative teammates coming out of various places and backgrounds.</li>\n<li>Flexible working hours and environment, believing in asynchronous yet collaborative work, having as few internal meetings and procedures as possible \ud83d\ude42</li>\n</ul>\n<div class=\"h3\"><strong>Perks:</strong></div>\n<ul>\n<li>\ud83d\udcb0 Attractive salary with ESOP (stock options)</li>\n<li>\ud83e\udd1d Possibility to work with highly ambitious, energetic, diverse group of people</li>\n<li>\ud83d\udcbb MacBook Pro (or your preferred laptop) + accessories</li>\n<li>\ud83c\udf80 Regular recognition, gifts, and awards</li>\n<li>\ud83c\udfe1 Home-office stipends for remote work equipment</li>\n<li>\ud83d\udcda Budget for online courses, books, conferences, language lessons</li>\n<li>\ud83c\udf05 Unlimited vacation and sick days</li>\n<li>\ud83c\udfc4\ud83c\udffc Team retreats with <a class=\"external\" href=\"https://www.thesurfoffice.com/\" rel=\"nofollow\">Surf Office</a></li>\n<li>... and many more to come as we listen to your needs!</li>\n</ul>\n<p>Type of employment: Full-time independent contractor for an indefinite period (B2B invoice)</p>\n<p>Ahoy is an equal opportunity employer that is committed to diversity and inclusion in the workplace. Please do not hesitate to apply using the button below!</p>\n"}, {"id": 994000, "url": "https://remotive.io/remote-jobs/data/data-analyst-994000", "title": "Data Analyst", "company_name": "Opera", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-22T05:41:39", "candidate_required_location": "Eastern Europe Only", "salary": "", "description": "<p>Data Analyst (Business Domain) - Ukraine, Poland, remote\u00a0</p>\n<p>We are looking for a motivated and proactive data analyst to join our E-commerce team and help build the next generation of consumer shopping experiences in our browsers.\u00a0<br><br></p>\n<p><strong>Responsibilities\u00a0</strong></p>\n<ul>\n<li>Analyzing current revenue streams and suggesting ways to grow them\u00a0</li>\n<li>Researching new revenue sources</li>\n<li>Budget and revenue forecasting for the entire business unit</li>\n<li>Building data dashboards to visualize insights\u00a0</li>\n<li>Analyzing current product funnels and recommending ways to improve them\u00a0</li>\n<li>Fraud monitoring</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<ul>\n<li>At least 1 year of experience as a Data Analyst</li>\n<li>Experience with market and customer needs analysis</li>\n<li>Strong knowledge of SQL, Excel\u00a0</li>\n<li>Experience building product specifications and concepts is a plus\u00a0</li>\n<li>Ability to identify trends and structure problems and opportunities</li>\n<li>English, spoken and written: upper intermediate</li>\n<li>Team player\u00a0</li>\n<li>Responsive and attentive to details</li>\n<li>Proven track record of solving complex problems</li>\n<li>Good communication and presentation skills</li>\n</ul>\n<p><strong>About Opera</strong></p>\n<p>Opera is a leading global web innovator with an engaged and growing base of hundreds of millions of monthly active users who seek a better internet experience. Building on over 25 years of innovation that started with browser products, Opera is now leveraging its brand and highly engaged user base in order to expand its business into new segments. Today, Opera offers users around the world a range of products and services that include PC and mobile browsers, the newsreader Opera News, and apps dedicated to gaming, fintech, e-commerce and classifieds.</p>\n<p>Opera is headquartered in Oslo, Norway with major offices in Poland, China, Estonia and Sweden, as well as a presence in many additional countries. Opera is listed on the Nasdaq stock exchange under the \u201cOPRA\u201d ticker symbol.</p>\n"}, {"id": 993360, "url": "https://remotive.io/remote-jobs/data/full-stack-engineer-data-analytics-platform-f-m-d-993360", "title": "Full Stack Engineer | Data Analytics Platform (f/m/d)", "company_name": "DeepL", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-22T01:40:05", "candidate_required_location": "Germany, the Netherlands, the UK and Poland", "salary": "", "description": "<p>is Germany's best-known AI company. We develop neural networks to help people work with language. With DeepL Translator, we have created the world's best machine translation system and made it available free of charge to everyone online. Over the next few years, we aim to make DeepL the world's leading language technology company.</p>\n<p><strong><span style=\"font-size: 18px;\"><span style=\"color: #1f497d;\"><span style=\"font-size: 20px;\">Our goal is to overcome language barriers and bring cultures closer together.</span></span></span></strong></p>\n<p>\u00a0</p>\n<p><strong><span style=\"color: #1f497d;\"><span style=\"font-size: 18px;\"><span style=\"font-size: 20px;\">What distinguishes us from other companies?</span></span></span></strong></p>\n<p>DeepL (formerly Linguee) was founded by developers and researchers. We focus on the development of new, exciting products, which is why we spend a lot of time actively researching the latest topics. We understand the challenges of developing new products and try to meet them with an agile and dynamic way of working. Our work culture is very open because we want our employees to feel comfortable. In our daily work we use modern technologies - not only to translate texts, but also to create the world's best dictionaries, and solve other language problems.</p>\n<p>When we tell people about DeepL as an employer, reactions are overwhelmingly positive. Maybe it's because they have enjoyed our services, or maybe they just want to get on board with our quest to break down language barriers and facilitate communication.</p>\n<p><span style=\"font-size: 18px;\"><span style=\"color: #1f497d;\">\u00a0</span></span></p>\n<p><strong><strong><span style=\"font-size: 18px;\"><span style=\"color: #1f497d;\"><span style=\"font-size: 20px;\">Your Choice</span></span></span></strong></strong></p>\n<p>We are constantly looking for outstanding employees! Currently we offer remote work in Germany, the Netherlands, the UK and Poland. Whether you would like to work from home in one of these countries or from one of our offices in Cologne or London: the choice is yours. No matter where you choose to work from, our way of working is designed to make you an essential part of the team.<span style=\"font-size: 18px;\"><span style=\"color: #1f497d;\"><br></span></span></p>\n<p><span style=\"font-size: 18px;\"><span style=\"color: #1f497d;\">\u00a0</span></span></p>\n<p><strong><span style=\"font-size: 18px;\"><span style=\"color: #1f497d;\"><span style=\"font-size: 20px;\">What will you be doing at DeepL?</span></span></span></strong></p>\n<div>\n<p><span style=\"color: #c0504d;\"><span style=\"color: #000000;\">You will be part of the highly motivated team that runs DeepL's analytics platform (short DAP). Our growing team is a cross-functional mix of Engineers, Data Analysts, and Data Scientist working towards our common goal of leveraging our user data. As a Full Stack Developer in this team, your responsibility is to develop and provide web applications and interfaces to your colleagues.\u00a0This gives you the chance to get to know many different areas and you'll be able\u00a0to contribute to many functions of the Analytics Platform.</span></span><span style=\"color: #c0504d;\"><br></span></p>\n</div>\n<p><span style=\"color: #1f497d; font-size: 20px;\"><strong>Your responsibilities</strong></span></p>\n<ul>\n<li>Gather requirements from internal stakeholders such as management and product</li>\n<li>Translate those requirements\u00a0autonomously into software specifications</li>\n<li>Design and implement new microservices and web applications for internal tooling and data analysis</li>\n<li>Work closely with our platform engineers to design and maintain a scalable data platform</li>\n</ul>\n<p><strong><span style=\"font-size: 20px;\"><span style=\"color: #1f497d;\">What we offer</span></span></strong></p>\n<ul>\n<li>Interesting challenges: design, programming and research at the highest level</li>\n<li>A friendly, international, and highly committed team with a lot of trust and very short decision making processes</li>\n<li>Work on a product that more than 100 million people already use</li>\n<li>Meaningful work: We break down language barriers worldwide and bring different cultures closer together</li>\n<li>Regular team events</li>\n<li>A comfortable office in Cologne or London (or a suitable equipment for your home office) and a lot of flexibility</li>\n</ul>\n<p><strong><span style=\"color: #1f497d;\"><span style=\"font-size: 20px;\">About you</span></span></strong></p>\n<ul>\n<li>You have already gained professional experience in Javascript or Typescript</li>\n<li>Helping other people by providing internal tooling makes you happy</li>\n<li>Python or Go are well known programming languages to you\u00a0</li>\n<li>General interest in Machine Learning or analytical topics, such as A/B\u00a0testing and statistics would be a big plus</li>\n<li>First experience with data visualizations libraries like d3.js, plotly</li>\n</ul>\n<p><span style=\"font-size: 20px;\"><span style=\"color: #1f497d;\"><strong>We are looking forward to your application!</strong></span></span></p>\n"}, {"id": 993524, "url": "https://remotive.io/remote-jobs/data/data-operations-manager-993524", "title": "Data Operations Manager", "company_name": "BenchSci", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-21T01:40:01", "candidate_required_location": "Anywhere", "salary": "", "description": "<div>BenchSci's vision is to help scientists bring novel medicine to patients 50% faster by 2025. We do this by empowering scientists to run more successful experiments with the world's most advanced, easy to use biomedical artificial intelligence software platform, thereby avoiding delays that slow the progress of medicine to clinical trials. Backed by F-Prime, Inovia, Golden Ventures, and Google's AI fund, Gradient Ventures, we provide an indispensable tool for more than 41,000 scientists that accelerates research at 15 top 20 pharmaceutical companies and over 4,300 leading academic centers. We're a CIX Top 10 Growth company, certified Great Place to Work\u00ae, and top-ranked company on Glassdoor.</div>\n<div>\u00a0</div>\n<div><span style=\"font-size: 16px;\">We are looking for a</span><strong style=\"font-size: 16px;\"> Data Operations Manager </strong><span style=\"font-size: 16px;\">to join our growing </span><strong style=\"font-size: 16px;\">R&amp;D </strong><span style=\"font-size: 16px;\">team! Reporting directly to the </span><strong style=\"font-size: 16px;\">Senior Operations Manager, R&amp;D</strong><span style=\"font-size: 16px;\">, you will guide the data generation process of data-focused projects in one of our cross-functional teams (CFT). </span><span style=\"font-size: 15px;\">You will work closely with stakeholders across the organization to ensure the successful completion of data projects.</span></div>\n<p><br><br></p>\n<div class=\"h3\">You will:</div>\n<ul>\n<li>Work with the project manager to ensure successful project execution and oversee the delivery of the data teams within the team</li>\n</ul>\n<ul>\n<li>Participate in all CFT planning meeting rituals providing updates to the CFT project management on the status and progress of data projects</li>\n</ul>\n<ul>\n<li>Focus on coordinating tasks from all teams contributing to data projects including R&amp;D (Science &amp; Engineering), Data Engineering, and Product &amp; Science teams and ensure continuous alignment</li>\n</ul>\n<ul>\n<li>Work with R&amp;D Leadership to document data project components for better estimating, risk assessment, and dependency/blocker identification</li>\n</ul>\n<ul>\n<li>Maintain communication on status and progress between CFT and Stakeholders in R&amp;D and Science teams through established processes</li>\n</ul>\n<ul>\n<li>Facilitate the OKR planning process between the CFT and Functional Teams</li>\n</ul>\n<ul>\n<li>Work to improve the efficiency in processes around data project planning and execution</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">You have:</div>\n<ul>\n<li>2+ years of experience in project management and/or operations that span across multiple domains of expertise</li>\n</ul>\n<ul>\n<li>Systems thinking approach to problem-solving</li>\n</ul>\n<ul>\n<li>Experience working in an agile environment with the ability to handle multiple, concurrent priority tasks with tight deadlines</li>\n</ul>\n<ul>\n<li>Experience with detailed project planning, establishing and maintaining realistic time estimates, risk identification and mitigation, issue tracking, and resolution planning</li>\n</ul>\n<ul>\n<li>Experience communicating risks and project outcomes with stakeholders</li>\n</ul>\n<ul>\n<li>Experience working with project management tools (eg. Jira, Monday, Smartsheets, etc.)</li>\n</ul>\n<ul>\n<li>Excellent written and verbal communication skills</li>\n</ul>\n<ul>\n<li>Educational background or working experience in a life sciences discipline</li>\n</ul>\n<ul>\n<li>An interest in working in a fast-paced and collaborative environment!</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">Our benefits and perks:</div>\n<ul>\n<li>An engaging remote-first culture that hires the best talent from around the world</li>\n</ul>\n<ul>\n<li>A great benefits package that includes BenchSci equity options</li>\n</ul>\n<ul>\n<li>Comprehensive health and dental benefits with an emphasis on mental health</li>\n</ul>\n<ul>\n<li>An annual Executive Health Assessment at Medcan for proactive health awareness</li>\n</ul>\n<ul>\n<li>Three weeks of vacation plus an additional day for every completed year</li>\n</ul>\n<ul>\n<li>Generous parental leave benefits with a top-up plan or paid time off options</li>\n</ul>\n<ul>\n<li>Additional time-off: Winter Holiday (Dec 25-Jan 1), Summer Holiday, your birthday, and more!</li>\n</ul>\n<ul>\n<li>An Oculus Quest 2 to connect with your team members in Virtual Reality</li>\n</ul>\n<ul>\n<li>An executive coach for managers to help them lead high-performing teams</li>\n</ul>\n<ul>\n<li>Complimentary Headspace account to support mental wellness and focus</li>\n</ul>\n<ul>\n<li>Complimentary genome sequencing from 23andMe to better understand your health through your DNA</li>\n</ul>\n<div><strong style=\"font-size: 18px;\">Our Culture:</strong></div>\n<div>We believe culture is critical to success and invest accordingly. We live and promote our FASTT values of focused, advancement with speed, tenacity, and transparency. We work hard to maintain an engaging, supportive environment where everyone can do their best work. To learn more, read our <a class=\"postings-link\" href=\"https://blog.benchsci.com/the-benchsci-culture-story-achieving-success-beyond-success\" rel=\"nofollow\">culture deck</a>.</div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 18px;\">Diversity, Equity and Inclusion:</strong></div>\n<div>We're committed to creating an inclusive environment where people from all backgrounds can thrive. We believe that improving diversity, equity and inclusion is our collective responsibility, and this belief guides our DEI journey. To learn more, read about our <a class=\"postings-link\" href=\"https://www.benchsci.com/diversity-equity-inclusion\" rel=\"nofollow\">DEI initiatives</a>.</div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 18px;\">Accessibility Accommodations:</strong></div>\n<div>BenchSci provides accessibility accommodations during the recruitment process. Should you require any accommodation, we will work with you to meet your needs.</div>\n<div>\u00a0</div>\n<div>#LI-Remote</div>\n"}, {"id": 993917, "url": "https://remotive.io/remote-jobs/data/business-data-analyst-993917", "title": "Business Data Analyst ", "company_name": "StructionSite", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-20T21:41:01", "candidate_required_location": "USA Only", "salary": "", "description": "<p>Construction is a $13 Trillion global industry, yet it\u2019s one of the least digitized. Fueled by increasing venture investment, our mission puts us at the forefront of a movement driven by former construction professionals looking for a better way to modernize how the world builds.</p>\n<p>\u00a0</p>\n<p>Our founders created StructionSite to remove the grey area from construction by giving builders smarter, easy-to-use tools that streamline site documentation and gather unbiased data.</p>\n<p>\u00a0</p>\n<p>Our custom AI-powered vision engine automatically organizes photos and videos by location, time, and date giving users the ability to keep a pulse on their project\u2019s data \u2013 helping them save time, stay on schedule, and protect profits.</p>\n<p>\u00a0</p>\n<p>The <strong>Business Data Analyst</strong> will deliver data by translating business needs into actionable insights, while operating within an analytics engineering framework - understanding how data flows from source (customer interaction, financial datapoint, etc.) to analysis and visualization in a BI system.</p>\n<p>\u00a0</p>\n<p>This person will also work closely with a Data Engineer/Scientist to close gaps in our data warehouse and ensure data completeness for our company. The Business Data Analyst will further accelerate our opportunity on how we leverage data at StructionSite.</p>\n<p>\u00a0</p>\n<p><strong>What You Will Be Doing:</strong></p>\n<ul>\n<li>\n<p>Work with stakeholders throughout the organization to identify opportunities for leveraging company data to drive business outcomes</p>\n</li>\n<li>\n<p>Assess gaps in completeness and accuracy of current data sources and work with engineers on closing those gaps</p>\n</li>\n<li>\n<p>Mine and analyze data from company databases to drive optimization and improvement of product development, marketing, and sales strategies</p>\n</li>\n<li>\n<p>Build graphs and dashboards in data visualization tools to enable self-service analytics</p>\n</li>\n<li>\n<p>Use statistical tools to interpret data sets, paying particular attention to trends and patterns that could be valuable for diagnostic and predictive analytics efforts.</p>\n</li>\n<li>\n<p>Conduct research and generate one-off reports with graphs and written narratives to support product or go-to-market decisions</p>\n</li>\n</ul>\n<p><br><strong>What You Have:</strong></p>\n<ul>\n<li>\n<p>Master's Degree in Business Analytics, Statistics, Mathematics, Computer Science, Economics, or other majors that involve statistical modeling and interpretation</p>\n</li>\n<li>\n<p>Strong written and verbal communication skills. You should know how to tell a story with data.</p>\n</li>\n<li>\n<p>Comfortable deconstructing complex and open-ended problems which may not yield a clear-cut solution.</p>\n</li>\n<li>\n<p>Experience with designing and building automated reporting dashboards with data visualization tools such as Tableau, Looker, Metabase, Mode, etc. for non-technical audiences.</p>\n</li>\n<li>\n<p>SQL knowledge is required, you should be able to push production level code.</p>\n</li>\n<li>\n<p>Proficiency with statistical analysis tools such as R or python is a plus.</p>\n</li>\n</ul>\n<p>\u00a0</p>\n<p><strong>Life @ StructionSite</strong></p>\n<p>StructionSite respects your whole life. Here are some of the ways we support our team:</p>\n<ul>\n<li>\n<p>Competitive salary</p>\n</li>\n<li>\n<p>Generous equity package</p>\n</li>\n<li>\n<p>Remote first team/Flexible Workspace</p>\n</li>\n<li>\n<p>Medical, Dental, Vision Benefits and 401k match</p>\n</li>\n<li>\n<p>Flexible Schedules</p>\n</li>\n<li>\n<p>Referral Bonuses</p>\n</li>\n<li>\n<p>Team events, jobsite visits, hackathons, etc.</p>\n</li>\n</ul>\n<p>StructionSite is a proud equal employment opportunity employer. We welcome everyone regardless of their race, color, religion, sex, national origin, age, disability, veteran status, or genetics, and we are dedicated to providing an inclusive, open, and dimensional work environment.</p>\n<p><br><br><br><br></p>\n<p>\u00a0</p>\n<p><br><br><br><br><br><br></p>\n"}, {"id": 993779, "url": "https://remotive.io/remote-jobs/data/analytics-engineer-993779", "title": "Analytics Engineer", "company_name": "Mediavine", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-19T21:41:26", "candidate_required_location": "USA Only", "salary": "", "description": "<p>Mediavine is seeking an Analytics Engineer to join our Engineering team. We are looking for someone who enjoys solving interesting problems and wants to work with a small team of talented engineers on a product used by thousands of publishers.</p>\n<div class=\"h3\">About Mediavine</div>\n<p>Mediavine is a fast-growing advertising management company representing over 8,000 websites in the food, lifestyle, DIY, and entertainment space. Founded by content creators, for content creators, Mediavine is a Top 20 Comscore property, exclusively reaching over 125 million monthly unique visitors. With best-in-class technology and a commitment to traffic quality and brand safety, we ensure optimal performance for our creators.</p>\n<div class=\"h3\">Mission &amp; Culture</div>\n<p>We help content creators build sustainable businesses. From educational tools and cutting-edge plugins to ad technology that maximizes earnings without slowing down your site, our motivation is ensuring your brand and business grow in every respect.</p>\n<p>We are striving to build an inclusive and diverse team of highly talented individuals that reflects the industries we serve and the world we live in. We are committed to creating a culture where everyone feels welcomed. We are looking for individuals that will challenge us to continuously evolve and make Mediavine the employer of choice for people of all backgrounds. We strongly encourage minorities and individuals from underrepresented groups in technology to apply for this position.</p>\n<p>Diversity and inclusion aren't platitudes to us; we take them seriously. Have a look at our team and read through our blog posts to learn more about our values and to discover if Mediavine is the place for you!</p>\n<div class=\"h3\">Position Title &amp; Overview</div>\n<p>The Data &amp; Analytics team consists of data analysts, data engineers and analytics engineers working to build the most effective platform and tools to help uncover opportunities and make decisions with data here at Mediavine. We partner with Product, Support, Ad Operations and other teams within the Engineering department to understand customer and product behavior, develop accurate predictors and build solutions that provide the best internal and external experience possible.</p>\n<p>The Analytics Engineer position bridges the gap between Data Engineer and Data Analysts working to make sure that the data we are bringing in is structured in the most efficient way to meet the needs of our consumers. They will own the transformation layer that standardizes business rules, defines data quality metrics and helps ensure the reliability of data for all teams. This position will be heavily involved in the decisions around tool selection and standards.</p>\n<p>Our current data engineering toolkit consists of custom Python etl, Ruby On Rails legacy pipelines, AWS infrastructure including Kinesis pipelines, Rundeck scheduling, dbt for transformation and Snowflake as our data warehouse platform. We are open to new tools and expect this position to play a role in the direction we take.</p>\n<p><strong>Essential Responsibilities</strong></p>\n<ul>\n<li>Centralize business logic into the transformation layer so that it occurs once and in one place when possible</li>\n<li>Manage the data access layer for business intelligence tools to ensure data is available, reliable and not duplicated</li>\n<li>Develop reporting environments for other teams that can be safely used and explored with little intervention from the Data &amp; Analytics team</li>\n<li>Define data quality rule sets, alerts and testing procedures</li>\n<li>Work with the analysts as a first line of investigation into data issues and pull in resources as needed to get to a resolution</li>\n<li>Reduce redundancy throughout the data stack by consolidating objects to reduce the management overhead</li>\n<li>Work with the business to educate them on data availability, meaning and usage to make them better able to service their own needs</li>\n<li>Identify gaps in the existing data and work with data engineers to fill them</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<p><strong>Location:</strong></p>\n<ul>\n<li>Must currently live in the United States.</li>\n</ul>\n<p><strong>You Have:</strong></p>\n<ul>\n<li>5+ years of experience in a data analyst or analytics engineering role</li>\n<li>Extremely strong SQL skills (CTEs, window functions, optimization)</li>\n<li>Experience with dbt as a transformation layer in a data stack</li>\n<li>Experience with at least two modern BI tools (Superset, Tableau, Looker, Mode, etc.)</li>\n<li>Comfortable working with multi-TB cloud data warehouses (Big Query, Snowflake, Redshift)</li>\n<li>Experience with web analysis such as creating data structures that support product funnels, user behavior, and decision path analysis</li>\n</ul>\n<p><strong>Nice to haves:</strong></p>\n<ul>\n<li>Experience with data science, machine learning, especially automated platforms like TensorFlow, SageMaker, etc.</li>\n<li>Experience with Google Analytics or other web traffic sources</li>\n<li>Knowledge of Ad Tech, Google Ad Manager and all of it\u2019s fun quirks (so fun)</li>\n<li>The ability to make your teammates laugh (it wouldn\u2019t hurt if you were fun to work with is what I\u2019m saying)</li>\n<li>Familiarity with event tracking systems (NewRelic, Snowplow, etc)</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<ul>\n<li>Remote work environment</li>\n<li>Travel opportunities (remember those!?)</li>\n<li>Comprehensive benefits including 401k, Health, Dental, and Vision insurance</li>\n<li>Learning allowance</li>\n<li>Generous Vacation/Time off policies</li>\n<li>Additional side benefits such as home-office upgrades, tuition reimbursement, paid gym memberships and wellness retreats, upgraded flights, cool swag and more</li>\n<li>Company match charitable donations</li>\n</ul>\n<p>Mediavine is an Equal Opportunity Employer</p>\n"}, {"id": 993781, "url": "https://remotive.io/remote-jobs/data/senior-data-engineer-993781", "title": "Senior Data Engineer", "company_name": "Mediavine", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-19T17:44:12", "candidate_required_location": "USA Only", "salary": "", "description": "<p>Mediavine is seeking a Senior Data Engineer to join our Engineering team. We are looking for someone who enjoys solving interesting problems and wants to work with a small team of talented engineers on a product used by thousands of publishers.</p>\n<div class=\"h3\">About Mediavine</div>\n<p>Mediavine is a fast-growing advertising management company representing over 8,000 websites in the food, lifestyle, DIY, and entertainment space. Founded by content creators, for content creators, Mediavine is a Top 20 Comscore property, exclusively reaching over 125 million monthly unique visitors. With best-in-class technology and a commitment to traffic quality and brand safety, we ensure optimal performance for our creators.</p>\n<div class=\"h3\">Mission &amp; Culture</div>\n<p>We help content creators build sustainable businesses. From educational tools and cutting-edge plugins to ad technology that maximizes earnings without slowing down your site, our motivation is ensuring your brand and business grow in every respect.</p>\n<p>We are striving to build an inclusive and diverse team of highly talented individuals that reflects the industries we serve and the world we live in. We are committed to creating a culture where everyone feels welcomed. We are looking for individuals that will challenge us to continuously evolve and make Mediavine the employer of choice for people of all backgrounds. We strongly encourage minorities and individuals from underrepresented groups in technology to apply for this position.</p>\n<p>Diversity and inclusion aren't platitudes to us; we take them seriously. Have a look at our team and read through our blog posts to learn more about our values and to discover if Mediavine is the place for you!</p>\n<p><strong>Position Title &amp; Overview</strong></p>\n<p>The Data &amp; Analytics team consists of data analysts, data engineers and analytics engineers working to build the most effective platform and tools to help uncover opportunities and make decisions with data here at Mediavine. We partner with Product, Support, Ad Operations and other teams within the Engineering department to understand behavior, develop accurate predictors and build solutions that provide the best internal and external experience possible.</p>\n<p>A Senior Data Engineer at Mediavine will help build and maintain our data infrastructure. Building scalable data pipelines, managing transformation processes, and ensuring data quality and security at all steps along the way. This will include writing and maintaining code in Python and SQL, developing on AWS, and selecting and using third-party tools like Rundeck, Metabase, and others to round out the environment. You will be responsible for informing and making decisions around tool selection and standards.</p>\n<p>Our current data engineering toolkit consists of custom Python etl, Ruby On Rails legacy pipelines, AWS infrastructure including Kinesis pipelines, Rundeck scheduling, dbt for transformation and Snowflake as our data warehouse platform. We are open to new tools and expect this position to play a major in the direction we take.</p>\n<p><strong>Essential Responsibilities</strong></p>\n<ul>\n<li>Create data pipelines that make data available for analytic and application use cases</li>\n<li>Develop self-healing, resilient processes that do not require constant care and feeding to run smoothly</li>\n<li>Create meaningful data quality notifications with clear actions for different interested parties including other internal teams and other members of the data and analytics team</li>\n<li>Drive the data engineering roadmap including leading projects through all phases</li>\n<li>Support data analysts and analytics engineers ability to meet the needs of the organization</li>\n<li>Lead code reviews, implementing standards, ensuring test coverage and recommending best practices to other members of the team</li>\n<li>Build or implement tooling around data quality, governance and lineage, mostly in the dbt framework but external to that as needed</li>\n<li>Provide next level support when data issues are discovered and communicated by the data analysts</li>\n<li>Work with data analysts and analytics engineers to standardize transformation logic in the dbt layer for consistency and ease of exploration by end users</li>\n<li>Enable analytics engineers and analysts by providing data modeling guidance, query optimization and aggregation advice</li>\n<li>Mentor more junior members of the team</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<p><strong>Location:</strong></p>\n<ul>\n<li>Must currently live in the United States.</li>\n</ul>\n<p><strong>You Have:</strong></p>\n<ul>\n<li>7+ years of experience in a data engineering role</li>\n<li>Strong Python skills (Understand tradeoffs, optimization, etc)</li>\n<li>Extremely strong SQL skills (CTEs, window functions, optimization)</li>\n<li>Structure data to enable internal and external facing analytics.</li>\n<li>Containerization experience (Docker, Kubernetes, etc.)</li>\n<li>Experience working with DevOps to deploy, scale and monitor data infrastructure</li>\n<li>Scheduler experience either traditional or DAG based</li>\n<li>Comfortable working with multi-TB cloud data warehouses (Big Query, Snowflake, Redshift)</li>\n<li>Experience with web analysis such as creating data structure that support product funnels, user behavior, and decision path analysis</li>\n</ul>\n<p><strong>Nice to haves:</strong></p>\n<ul>\n<li>Experience with data science, machine learning, especially automated platforms like TensorFlow, SageMaker, etc.</li>\n<li>Knowledge of Ad Tech, Google Ad Manager and all of it\u2019s fun quirks (so fun)</li>\n<li>The ability to make your teammates laugh (it wouldn\u2019t hurt if you were fun to work with is what I\u2019m saying)</li>\n<li>Familiarity with event tracking systems (NewRelic, Snowplow, etc)</li>\n<li>Experience with dbt</li>\n<li>Experience with one or more major BI tools (Tableau, Looker, PowerBI, etc.)</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<ul>\n<li>Remote work environment</li>\n<li>Travel opportunities (remember those!?)</li>\n<li>Comprehensive benefits including 401k, Health, Dental, and Vision insurance</li>\n<li>Learning allowance</li>\n<li>Generous Vacation/Time off policies</li>\n<li>Additional side benefits such as home-office upgrades, tuition reimbursement, paid gym memberships and wellness retreats, upgraded flights, cool swag and more</li>\n<li>Company match charitable donations</li>\n</ul>\n<p>Mediavine is an Equal Opportunity Employer</p>\n"}, {"id": 936313, "url": "https://remotive.io/remote-jobs/data/senior-data-analyst-she-he-they-936313", "title": "Senior Data Analyst (she/he/they)", "company_name": "Trafilea", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-18T17:41:21", "candidate_required_location": "Anywhere", "salary": "", "description": "<p><u><strong>About Trafilea</strong></u></p>\n<p><u><strong>\u00a0</strong></u></p>\n<p dir=\"ltr\">Trafilea is a global company that builds communities and transformative brands. We own the brands and take care of the entire customer journey, to deliver wow-worthy experiences that influence and empower millions of people globally.</p>\n<p dir=\"ltr\">Our culture is fast-paced and dynamic. We are data-driven enthusiasts, passionate about marketing, exponential technologies, and innovation.</p>\n<p dir=\"ltr\">We have over 300 hundred employees working around the world, connected by the same purpose and core values. Our support for this new way of working has led to being featured in Forbes and FlexJobs as one of the Top 25 Companies for Remote Workers.</p>\n<p dir=\"ltr\">We are looking for dynamic, dedicated, and committed individuals with a strong desire to grow, that can drive the brand forward on its truly exciting journey.</p>\n<p dir=\"ltr\">Do you want to know more about our Brands? <a href=\"https://shapermint.com/\" rel=\"nofollow\">Shapermint</a>,\u00a0<a href=\"https://truekind.com/\" rel=\"nofollow\">Truekind</a> &amp; <a href=\"https://empetua.com/\" rel=\"nofollow\">Empetua</a></p>\n<p><em>\u00a0</em></p>\n<p><em><strong>We're looking for a passionate and methodical Senior Data Analyst to Lead the Analytics division and team for the Data Science Division. Combines data, computational science, and technology to provide high-value insights into the business, and through the use of statistical analysis and data visualization techniques that enable enhanced business performance.</strong></em></p>\n<p dir=\"ltr\"><em><strong>Advising the business on the potential of data, leverage and synthesize large volumes and variety of data to enhance the business\u2019s understanding of individual population segments, propensities, outcomes, and decision points.</strong></em></p>\n<p dir=\"ltr\"><strong><u>\u00a0</u></strong></p>\n<p dir=\"ltr\"><strong><u>Expected outcomes &amp; responsibilities</u></strong><em><br></em></p>\n<p dir=\"ltr\">\u00a0</p>\n<ul>\n<li>Designs, implements, and evaluates experiments, A/B tests, AdHoc analyses, or forecasting to solve a business\u2019s most complex issues.</li>\n<li>Builds econometric and statistical KPIs for various problems including propensity, forecasting, pattern analysis, sampling, simulations, and so forth.</li>\n<li>Research about new hypotheses and how to develop an analytical solution to solve them, explain them and develop all the visualization needs to present it.</li>\n<li>Performs ad-hoc exploratory analysis tasks on SQL databases related to the business\u2019s strategies.</li>\n<li>Prepare reports and presentations for relevant stakeholders that will give insights for departmental as well as business-wide decision-making.</li>\n<li>Develop new approaches to understand the business\u2019s consumer trends and behaviors as well as approaches to solve complex business issues, for example, the optimization of product performance and gross profit.</li>\n<li>Responsible for identifying, claim data, and enabling analytical capability to query the data and address various business needs.</li>\n<li>Takes initiative to experiment with various analytical or statistical technics and tools with a vision of creating innovative data-driven insights for the business at the quickest pace possible.</li>\n</ul>\n<p>\u00a0</p>\n<ul>\n<li>Bachelor\u2019s degree in Computer Science, Engineering, Statistics, Economics, or quantitative focused study.</li>\n<li>Experience in marketing analytics and understanding KPIs from Tableau and Excel.</li>\n<li>Deep experience in data analysis and manipulation, both in SQL and NoSQL databases.</li>\n<li>Deep Experience working with SQL and Data Warehouse.</li>\n<li>Experience working with Python for Analytics.</li>\n<li>Highly analytical and quantitative, with strong attention to detail.</li>\n<li>Proactive in taking ownership of projects and issues.</li>\n<li>Capability to manage several projects and areas.</li>\n<li>Passionate about learning and implementing new data-related technologies in the market.</li>\n<li>Ability to communicate complex ideas effectively.</li>\n<li>Eager to take on new challenges and learn new things.</li>\n<li>Experience in marketing analytics or e-commerce analytics (desirable).</li>\n</ul>\n<p><strong><strong><u>\u00a0</u></strong></strong></p>\n<p dir=\"ltr\"><strong><u>What We Have to Offer</u></strong></p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Proximity doesn\u2019t influence productivity. As a globally distributed team, you can live and work wherever you want.</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">A rich experience including the opportunity to collaborate with world-class talents. Encouraging transparency and open communication to all.</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">A data-driven, dynamic, energetic work environment, full of talented, goal-oriented, and empathetic people working together to grow and develop both as professionals and human beings.</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">A safe space to be who you truly are. We embrace and support diversity, equity and work hard every day to keep becoming more inclusive.</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Openness to new ideas and initiatives: You can always join a squad, tribe, or committee, start new ones. Bring your hobbies and passions and transform them into projects!</p>\n</li>\n</ul>\n<p dir=\"ltr\">For more benefits please visit our <a href=\"https://www.trafilea.com/careers/\" rel=\"nofollow\">Trafilea web Site</a>.</p>\n<p dir=\"ltr\">Are you ready? Apply for this position today and join the fastest-growing startup in the world!</p>\n"}, {"id": 989088, "url": "https://remotive.io/remote-jobs/data/sr-data-analyst-989088", "title": "Sr. Data Analyst", "company_name": "Ipro", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-17T17:41:37", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>IPRO.</strong> Better healthcare, realized.\u00a0That\u2019s our vision.\u00a0Across nearly 100 state and federal programs in 34 states, IPRO makes creative use of data science, clinical expertise, and emerging technology solutions to make the healthcare system work better.\u00a0We\u2019re a mission-driven, not-for-profit organization committed to delighting our customers and developing our employees.</p>\n<p>\u00a0</p>\n<p><strong><u>GENERAL RESPONSIBILITIES</u></strong><strong>:</strong></p>\n<p><strong>\u00a0</strong></p>\n<p>You will be part of a team that improves the quality of care delivered in a variety of settings, including hospitals, outpatient clinics, nursing homes, ESRD centers, and managed care plans.\u00a0 Your regular work will include collecting and reviewing data, developing analytic approaches, producing reports and dashboards, conducting root-cause analyses, and summarizing information for clients.\u00a0 You will also be involved in internal and client projects that leverage advanced analytic approaches, including regression analysis, ROI measurement, predictive modeling, machine learning, and more.\u00a0 This role may also periodically conduct onsite analytic and technical reviews, submit formal assessments to state authorities, and present data-driven recommendations to client leaders.\u00a0You\u2019ll also enjoy the flexibility to telecommute from anywhere within the US as you take on some tough challenges. Duties include but are not limited to:\u00a0</p>\n<ul>\n<li>Helps business users create optimal business requirements by exploring data and analytic alternatives and guiding users to the most cost-effective and efficient approach to meeting their needs. Translates internal/external client business requirements into actionable instructions for meeting client needs.</li>\n<li>Designs analytics (reports, dashboards, models) to respond to very complex requests. Develops advanced quantitative approaches (drawing on a range of methodologies) to address client needs.</li>\n<li>Performs strategic data mining and research to identify opportunities for improvement and otherwise support business needs.</li>\n<li>Conducts complex statistical analyses (e.g., regression analysis, predictive modeling).</li>\n<li>Ensures accuracy, data integrity, and face validity of all work. Reviews work of more junior analysts.</li>\n<li>Writes reports with charts and graphs; presents to internal and client leadership; and summarizes findings and recommendations for technical/clinical and nontechnical/ nonclinical audiences, as appropriate.</li>\n<li>Creates and maintains databases to support analytic outputs. Collaborates with centralized data management resources.</li>\n<li>Ensures all analyses use high-quality data. Develops strong understanding of data sources and works with IPRO and client data management staff to ensure complete, accurate, and timely data.\u00a0 Assists more junior data analysts in managing data quality.</li>\n<li>Supports continuous quality improvement. Contributes regularly to improving data and analytics sophistication and efficiency within the department and across the IPRO enterprise.</li>\n<li>Creates documentation (such as code detail, report specifications, narrative backup, and metadata) for all outputs. Reviews documentation produced by more junior analysts.</li>\n<li>Produces all agreed upon deliverables on or ahead of schedule.</li>\n<li>Accepts ownership of large parts of department or corporate projects.</li>\n<li>Trains and mentors more junior analysts.\u00a0</li>\n</ul>\n<p>\u00a0</p>\n<p><strong><u>QUALIFICATIONS: </u></strong></p>\n<ul>\n<li>Demonstrated exceptional healthcare analytics skills\u2014ideally in the health care quality measurement arena. HEDIS/CAHPS and financial/utilization measurement a plus.\u00a0</li>\n<li>Experience with advanced analytic techniques (e.g., complex trend and benchmark comparisons, data mining, complex visualizations) and standard statistical ability (e.g., t-tests, control charting, regression analysis, forecasting).</li>\n<li>Strong proficiency and experience with analytic tools, such as\n<ul>\n<li>relational database concepts/query tools (e.g., SQL, Metabase, MS Access)</li>\n<li>statistical software (e.g., SAS, SPSS, Phyton, R)</li>\n<li>BI Visualization Tools (e.g., Tableau, MS Excel)</li>\n<li>Presentation tools (e.g., MS Word, MS PowerPoint)</li>\n</ul>\n</li>\n<li>Experience with several types of healthcare data (e.g., payer claims/membership/provider, lab, EMR, social determinants, patient-self reported data).</li>\n<li>Technical expertise\u00a0regarding\u00a0data models, database design development, data mining and segmentation techniques.</li>\n<li>Ability to communicate complex concepts orally and in writing to technical, leadership, and lay audiences using\n<ul>\n<li>Static tables/graphs and interactive dashboards</li>\n<li>Written reports that clearly describe methods, findings, and recommendations in language appropriate for the audience</li>\n<li>Presentations that are well crafted and articulately presented</li>\n</ul>\n</li>\n<li>Solid understanding of the US healthcare system, and in particular managed care and state Medicaid, Child Health Plus, and related programs\u2014including the types of data generated and how they are used for analytics</li>\n<li>Ability to travel up to 15% of the time</li>\n</ul>\n<p>\u00a0</p>\n<p><strong><u>EDUCATION &amp; EXPERIENCE</u></strong><strong>:</strong></p>\n<ul>\n<li>Bachelor's Degree required; Master's Degree preferred</li>\n<li>4 years of experience doing healthcare analytics work; time spent in a Master\u2019s or PhD program can be counted as experience</li>\n</ul>\n<p>IPRO offers competitive salaries, comprehensive health and dental coverage.</p>\n<p>IPRO is an Affirmative Action/Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or protected veteran status.</p>\n"}, {"id": 997712, "url": "https://remotive.io/remote-jobs/data/data-engineer-h-f-997712", "title": "Data Engineer H/F", "company_name": "KMTX", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-17T15:20:07", "candidate_required_location": "Europe and North Africa", "salary": "60/80k\u20ac", "description": "<section class=\"pt-20 pb-12 block-px company-links\">\n<div class=\"mx-auto max-w-[750px] prose font-company-body overflow-hidden\">\n<p class=\"text-center\"><em>On-site, partially remote\u00a0or full-remote - 60/80k\u20ac + benefits</em></p>\n<p class=\"text-center\"><em>We consider diversity to be\u00a0a true asset and are happy to learn more\u00a0about all candidates!</em></p>\n<p class=\"text-center\">\u00a0</p>\n<div class=\"h3\">Our mission</div>\n<p>We are KMTX, a fast-growing AdTech company building the ad platform of the open\u00a0web. We aim to build\u00a0the main advertising platform of the Open Web, making it simple for anyone to run effective campaigns online within this $200B market. We\u00a0believe this is the only way to\u00a0preserve and improve\u00a0an\u00a0open and fair internet.</p>\n<div class=\"h4\">The problem we\u2019re working on</div>\n<p>Advertising on the open web\u00a0is a mess of\u00a0unnecessary complexity, opacity, low respect for user privacy, and poor performances for advertisers and publishers. This is what allows walled gardens (Google and\u00a0Facebook) to dominate the online advertising market: as their advertising platforms are\u00a0simple and efficient. A simple &amp; efficient ad platform for the open web\u00a0is necessary to promote free access to information outside walled gardens and\u00a0fight their duopoly.</p>\n<div class=\"h4\">Our solution and achievements</div>\n<p>Since 2017, we\u2019ve been\u00a0working on the most difficult\u00a0part of creating the ad platform of the open web. A set of\u00a0automated tools and technologies to buy advertising in real-time and\u00a0deliver strong performance\u00a0for advertisers.</p>\n<p>We\u2019ve proved that our approach works with over\u00a0<strong>200 brands</strong>\u00a0running\u00a0more than\u00a0<strong>1500 campaigns</strong>\u00a0as we've\u00a0consistently beaten every advertising platform on the market in performance. That's why we've quickly\u00a0grown\u00a0to\u00a0<strong>8 figures in\u00a0revenue</strong>.</p>\n<p>We are now building and deploying a self-serve platform that\u00a0allows advertisers to launch campaigns in less than 5 minutes on any digital\u00a0inventory (Web, Apps, connected\u00a0TV, ...) to\u00a0deliver results for their brand.\u00a0This\u00a0<strong>simple and efficient</strong>\u00a0platform will soon\u00a0be available for advertisers across\u00a0<strong>Europe and North America</strong>.</p>\n<div class=\"h4\">Who we are</div>\n<p>KMTX was founded in 2017 by two serial tech entrepreneurs: Franck Tetzlaff (co-founder of Doctolib) and Arthur Querou (co-founder of MotionLead acquired by Adikteev).</p>\n<p><strong>We\u2019ve raised $3m</strong>\u00a0to date and plan to raise another significant round in the coming months.</p>\n<p>We\u2019re obsessed with\u00a0<strong>meaningful, powerful tech\u00a0which simplifies</strong>\u00a0the work of\u00a0our users.</p>\n<p>We're not afraid to\u00a0<strong>challenge\u00a0the status quo!</strong></p>\n<p>We believe that small increments don't drive change. Anything we do must be<strong>\u00a0better</strong>\u00a0than what existed before.</p>\n<div class=\"h4\">Working at KMTX</div>\n<p>We hire people whom we admire.\u00a0Forward thinkers, who challenge the status quo, get out of their comfort zone, are not afraid to fail, have a high level of self-awareness and expectation while parking their ego at the door.</p>\n<p>We believe that work shouldn't be \u201cjust a job\u201d, but\u00a0<strong>an opportunity to grow</strong>. To perform at their best, our people should be happy and challenged. We want our people to evolve, learn, and grow in a pleasurable work environment.</p>\n<p>We care a lot about\u00a0<strong>autonomy and trust, and\u00a0</strong>we lead by example by being very flexible on work hours and projects you choose to spend your time on. We take pride in and encourage our employees to take\u00a0initiative.</p>\n<p>We are as transparent as possible on what\u2019s going on within the business\u00a0and everyone, at every level,\u00a0is always accessible.\u00a0<strong>There are n</strong><strong>o hierarchy blocks at KMTX.</strong></p>\n<p>Finally, we provide a suite of benefits and perks which\u00a0we believe are meaningful enough\u00a0to\u00a0<strong>make the lives of our employees better</strong>.</p>\n<p>\u00a0</p>\n<div class=\"h3\">Job description</div>\n<p>Within a team of 3 Data Engineers, including a very senior Lead (whom you would be able to keep improving\u00a0from), we are expecting you to :</p>\n<ul>\n<li>Help us build\u00a0a scalable and robust product</li>\n<li>Give our users access to our bidding stack through a self-serve platform, allowing them to advertise on the open web and fight walled gardens</li>\n<li>Participate to build\u00a0long-term roadmaps and architectures to scale ML algorithms</li>\n<li>Industrialize live ML model production usage (~100k predictions per second)</li>\n<li>Industrialize and automate ML model training on billions of data points</li>\n<li>Integrate ML models and deploy data related services on client-facing live environments</li>\n</ul>\n<div class=\"h3\">Who you are</div>\n<ul>\n<li>Result-oriented, you want to have an impact on the business</li>\n<li>Fast learner, you quickly understand the key concepts on new topics</li>\n<li>Curious, you want to stay up-to-date with emerging technologies</li>\n<li>Able\u00a0to work in a very fast-paced and continuously changing environment</li>\n</ul>\n<div class=\"h3\">Expected Skills</div>\n<ul>\n<li>Experienced in working with product owners to understand and implement business requirements</li>\n<li>You know how to ship maintainable, quality high-performance code</li>\n<li>Expert in Python</li>\n<li>Experienced with large-scale data processing solutions (Scala, Spark)</li>\n<li>Experienced in design and optimization of databases (SQL and NoSQL)</li>\n<li>Experienced in scheduling solutions (Airflow) and Cloud platforms (AWS)</li>\n</ul>\n<div class=\"h4\">Expected Experience</div>\n<ul>\n<li>3+ years of Data Engineering</li>\n<li>You have already designed and implemented large-scale data processing pipelines</li>\n<li>A first experience\u00a0working with Data Scientists is a plus</li>\n<li>A first\u00a0experience in an AdTech/MarTech company is a plus</li>\n</ul>\n<div class=\"h3\">Benefits</div>\n<ul>\n<li>A sane work environment built on trust, delivery, and mentoring</li>\n<li>Attractive salary and remote-friendly</li>\n<li>Dedicated conference and training budget</li>\n<li>Central Paris office</li>\n<li>Fully equipped workstation</li>\n<li>Restaurant Tickets (Swile)</li>\n<li>Health Insurance (Alan)</li>\n<li>Gym subscription (Gymlib)</li>\n<li>Regular team-building events</li>\n<li>Annual company retreat</li>\n<li>Partnership with childcare centers</li>\n</ul>\n<div class=\"h3\">Interview Process</div>\n<ul>\n<li>Phone qualification\u00a0</li>\n<li>Tech interview</li>\n<li>Team fit interview</li>\n<li>VP interview + chat with our cofounder</li>\n<li>Offer!</li>\n</ul>\n</div>\n</section>\n", "company_logo_url": "https://remotive.io/job/997712/logo"}, {"id": 986397, "url": "https://remotive.io/remote-jobs/data/data-engineer-986397", "title": "Data Engineer", "company_name": "Arex", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-16T13:40:20", "candidate_required_location": "Spain", "salary": "", "description": "<p>AREX is a data-driven FinTech that offers SMEs (Small and medium enterprises) an innovative way to sell invoices. Automation allows an SME to receive cash payment from sold invoices as early as within the same day.</p>\n<p>Our first product is an automated receivables exchange platform where invoices are converted into a tradable asset class called Exchange Traded Receivables (ETRs). ETRs are then sold on an open market where a single ETR can be purchased by one or multiple investors using automated trading bots.</p>\n<p>Leveraging cutting-edge technology, AREX offers an easy-to-use, cost-effective service, which is integrated with accounting systems, facilitating the work of accountants and empowering SMEs to achieve their goals.</p>\n<p><strong>What will you do</strong></p>\n<ul>\n<li>Collaborate to build and scale our core systems and Marketplace.</li>\n</ul>\n<ul>\n<li>Maintain existing analytical and big data related software using SQL, Python, Django, Kubernetes / AWS EKS</li>\n</ul>\n<ul>\n<li>Build tests for reporting system &amp; data warehouse</li>\n</ul>\n<ul>\n<li>Work on AWS ecosystem (RDS, Lambda, IAM, EC2, RDS, DMS, S3, CloudWatch, Athena) to answer the requirements by data consumers in the company and external customers as well</li>\n</ul>\n<ul>\n<li>Help creating the data warehouse from the scratch and pipelines (Adopting columnar databases, ETL tools, scheduling and transformation tools like Airflow, EMR, message queues &amp; real-time data streaming tools like SQS, SNS, Kinesis, Snowflake, Google BigQuery, etc)</li>\n</ul>\n<ul>\n<li>Help to keep up an Agile environment, focused in delivery to meet our customers expectations.</li>\n</ul>\n<ul>\n<li>Design simple solutions to complex business problems, ensuring availability and performance.</li>\n</ul>\n<ul>\n<li>Improve the Software Development Life Cycle (SDLC), with automation at heart, boosting continuous integration and continuous delivery (CI/CD) practices and tools.</li>\n</ul>\n<p><strong>You will love this job if you are</strong></p>\n<ul>\n<li>Passionate about implementing new solutions and also do reverse engineering for enhancing the existing landscape</li>\n</ul>\n<ul>\n<li>A programmer with experience in software engineering professional practices, like design patterns, SOLID principles, clean code and Domain Driven Design (DDD)</li>\n</ul>\n<ul>\n<li>Keen to tackle the challenges of distributed architectures based on microservices.</li>\n</ul>\n<ul>\n<li>Research and experiment with new technologies that are the best fit for the problem you are aiming to solve. We are a startup, we aim to use the right tool to do the job.</li>\n</ul>\n<ul>\n<li>Excited to have the opportunity to improve your code quality and problem solving skills on a daily basis.</li>\n</ul>\n<p><strong>About the hiring process</strong></p>\n<p>We are keen to explore your resume and, if you would like to, a cover letter with some of the things that drive you, professionally and personally as well. Let us know what makes you excited regarding your future role as a Data Engineer at Arex!</p>\n<p>If it seems that we are a good fit for each other, we will set a call! The goal is to explain more details related to the team, tech stack, the duties of the role you are applying for and, more than anything else, get the chance to hear about your trajectory. This should take half an hour.</p>\n<p>Next we will share a technical challenge that is expected to be completed within one (1) week. You will get a thoughtful description of the expectations in terms of tech deliverables and the way those will be submitted.</p>\n<p>We\u2019ll let you know how things went within a week! If it still seems like a good fit all around, we\u2019ll schedule a one hour meeting with two of your peers to deep dive into the solution, so you will be able to explain what was achieved, the techniques you applied and trade-offs that were made.</p>\n<p>Last but not least, you will get a call from one of our product savvy teammates for a half an hour conversation regarding communication, collaboration and customer focused design techniques.</p>\n<p>At this point, you will get an offer letter! If not, we will let you know at any stage of the process, so you aren\u2019t left hanging.</p>\n<p>Not sure if you\u2019d be the right fit? Apply anyway! We\u2019d love to know more about you and have an open conversation in respect to how we can grow together.</p>\n<p><strong>More on this opportunity</strong></p>\n<p>At AREX Markets we celebrate diversity and are promoting an inclusive environment in which our team members from all different backgrounds, ages, genders or sexual orientations feel equally appreciated. In order to achieve this, we are committed to shaping a hiring process that provides everyone with an equal opportunity to get hired.</p>\n<p>We strive to build a community where everybody is represented, and we make conscious choices to support inclusion and equal opportunities throughout our journey, from the recruitment process to career progression. We therefore actively encourage women to apply for this position, and in general people of different backgrounds, experiences, abilities and perspectives to join the team. We are an open and supportive place to work.</p>\n<p>At AREX Markets we are fully remote and flexible, in consequence we are providing the fluidity and tools, including home office equipment, to help you do the job. Our HQ is in Barcelona, Spain, however we are a distributed organisation which keeps a mixed and elastic approach in terms of working on site and remotely.</p>\n<p>Besides a competitive annual salary and remote work, other perks are:</p>\n<ul>\n<li>A MacBook Pro</li>\n<li>Equity/Stock options plan</li>\n<li>Private insurance paid by the company</li>\n<li>Home office equipment budget</li>\n<li>Training budget</li>\n<li>Tax relief plan for meals, kindergarten and public transportation (Retribuci\u00f3n flexible)</li>\n</ul>\n"}, {"id": 987362, "url": "https://remotive.io/remote-jobs/data/senior-data-engineer-987362", "title": "Senior Data Engineer", "company_name": "Footasylum", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-16T13:40:16", "candidate_required_location": "UK Only", "salary": "", "description": "<p><strong>We\u2019re looking for a data engineer to join our Data Engineering team. We are offering flexible working from 28hrs (minimum) to 40 hours (maximum) per week. Remote working also available.</strong></p>\n<p>The data tech stack in Footasylum has evolved significantly over the last year, giving us lots of opportunity to use data to better serve our customers and colleagues. We are growing our data team to enable us to unlock more value from the technology we have invested in.</p>\n<p>We are looking for a Data Engineer to support the growth of the Data Engineering function; to mentor junior members of the team and help build effective practices that drive a culture of technical excellence and continuous improvement.</p>\n<p>This is a very exciting opportunity for someone who wants to be part of a growing team, develop the data engineering community of practice, define data standards across the organisation and be part of a team that\u2019s driving the second phase of Footasylum\u2019s Data Strategy, including maturing a data science function. </p>\n<p>\u00a0</p>\n<div class=\"h3\">\u00a0</div>\n<div class=\"h3\">What will you do?</div>\n<ul>\n<li>Influence and contribute towards the next phase of our data strategy.</li>\n<li>Deliver the engineering roadmap and champion data engineering across the business.</li>\n<li>Establish the engineering roadmap and champion data engineering across the business and throughout the wider community</li>\n<li>Empower junior engineers and drive standard methodologies across different data technologies, finding new ways to solve emerging problems.</li>\n<li>Be an expert for data solutions, overseeing data engineering delivery effort across multiple product teams and projects.</li>\n<li>Create a learning culture by coaching and mentoring junior engineers to make sound technical decisions and help build effective engineering practices, stabilising and optimising the data platform.</li>\n<li>Support the development of the first Data Engineering community of practice.</li>\n<li>Be an advocate for standard methodologies and strong CI /CD principles, govern engineering standards and policies across the business</li>\n<li>Advocate working in the open by demonstrating your work; use creative ways to bring to life the value of the Data Engineering team</li>\n<li>Drive a data driven culture, ensuring data is at the forefront of decision making across product teams and the business.</li>\n<li>Work with the business and data team to establish a self-service data culture</li>\n</ul>\n<div class=\"h3\">This is an exciting role for an experienced Data Engineer who has;</div>\n<ul>\n<li>5 years+ working in Data Engineering function</li>\n<li>Databricks, Data Factory, Azure SQL, Azure SQL DW</li>\n<li>Delivering enterprise scale data solutions, infrastructure and architecture.</li>\n<li>Managing and reducing cost in the cloud by using best practice techniques.</li>\n<li>Managing multiple priorities in a fast paced environment alongside evolving the data tech stack and practices.</li>\n<li>Role modelling agile development practices - DevOps, CI, CD, TDD.</li>\n<li>Knowledge of emerging technologies and how they can be used to solve modern business problems.</li>\n</ul>\n<p>The ideal candidate will have experience of working in a retail environment using agile methodologies with operational targets crossing multiple departments, although this is not essential.</p>\n<p>\u00a0</p>\n<div class=\"h3\">Why Footasylum?</div>\n<p>We have been going through a digital transformation, changing how we deliver value to our business. A big part of this change is fostering a culture of being open and honest, collaborating, having fun and enabling psychological safety.</p>\n<p>We want to create a place for teams to do their best work, and you will have the opportunity to influence our decisions, help define standards across the teams and contribute to a healthy and happy working environment.</p>\n<div class=\"h3\">The Data Team</div>\n<p>The team and tech stack have evolved significantly over the last year and we now see the Data Engineering function as an opportunity to contribute towards a forward thinking IT department, collaborating with our stakeholders, and thus allowing the data engineers to focus on working closely with the multi-disciplinary teams and bringing in new data sources.</p>\n<p>The objective of the data team is to empower the business by using data over opinions and to create efficiencies across the supply chain using machine learning. The data team is an enabling team and as such it is important to note that we are an important function for both the tech teams and the business. By creating robust solutions that allows us to understand data from our multi-disciplinary teams through either event based data in our data lake or bringing in other datasets, we can create meaningful insights.</p>\n<p>The data team have made incredible progress to complete a migration from a traditional on-premise data warehouse to a data lake hosted in Azure. They use Data Factory to create pipelines to push data into the Data Lake, Synapse and SQL DB\u2019s to build the reporting cubes and streaming analytics to provide real-time sales and stores dashboards to the business. </p>\n<div class=\"h3\">Salary &amp; Benefits</div>\n<p>We are offering a salary up to \u00a360,000 (full time) for the right person, which we assess based on your own experiences, skills and against the principles of our department and our ways of working. You\u2019ll also get access to our \u2018FA Presents\u2019 company benefits platform, 25 days holiday and pension as standard, and use of our training budget to help you develop your skills. </p>\n<div class=\"h3\">Diversity</div>\n<p>We recognise and value the importance of diversity to help make sure we have lots of different perspectives when we are building products and services. We know that this will help us build useful and accessible things which our customers will love. This is great news for our business. Diversity for us is also, importantly, about building happy teams full of people that want to learn and want to be inspired by each other and our different experiences and backgrounds. </p>\n<div class=\"h3\">Recruitment process\u202f</div>\n<p>We review applications on an individual basis, and if we feel you would be a good fit you\u2019ll meet with a few members of the Footasylum team for an informal chat about the role over a video call, and to see if we\u2019re a good fit for you.</p>\n<p>With the COVID-19 situation our teams are all working remotely, adjusting to this new way of working as best we can - and as such we\u2019ll help make the interview process as clear and stress-free as possible, giving you the same opportunity as if we were meeting face to face.</p>\n<p>Primarily the role will be remote and while there is no intention for the team to go back to full time office work any time soon, this role will require occasional visiting to sites such head office based in Manchester and Rochdale.</p>\n"}, {"id": 993987, "url": "https://remotive.io/remote-jobs/data/senior-data-engineer-mlops-993987", "title": "(Senior) Data Engineer/MLOps", "company_name": "Finiata", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-15T12:44:38", "candidate_required_location": "Europe: selected countries RO/IT/PL/PT/DE", "salary": "", "description": "<div class=\"h5\" style=\"box-sizing: inherit; margin-bottom: 1.6rem; font-size: 1.125rem; font-weight: bold; line-height: 1.35; font-family: 'Mark Pro', Helvetica, Arial, sans-serif; color: #303037; outline: none !important;\">YOUR MISSION</div>\n<p style=\"box-sizing: inherit; margin-bottom: 1.25rem; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">Machine Learning (ML) is revolutionizing the way of doing business at a global scale. In business lending, Finiata takes the technological forefront by developing proprietary technology that allows us to take accurate decisions in a fully data driven fashion. YOU will contribute to further develop the in-house all-data-things technology by engineering and productizing novel pipelines and ML models.</p>\n<p class=\"nitro-offscreen\" style=\"box-sizing: inherit; margin-bottom: 1.25rem; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\"><span style=\"box-sizing: inherit; font-weight: bolder; outline: none !important;\">Note:</span>\u00a0This position is fully remote as long as you are legally based in Germany, Poland, Portugal, Italy or Romania. You may be required to travel for business purposes (e.g.: participation in team building activities, professional workshops) up to 10% of the time.</p>\n<p class=\"nitro-offscreen\" style=\"box-sizing: inherit; margin-bottom: 1.25rem; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">You will:</p>\n<ul class=\"nitro-offscreen\" style=\"box-sizing: inherit; padding-left: 1.5em; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">\n<li style=\"box-sizing: inherit; outline: none !important;\">Work closely with Data Scientists, Backend Engineers, Quality Engineers and DevOps to operationalize proprietary machine learning technology for different problems</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Design and maintain scalable ETL and MLOps infrastructure usable in multiple scenarios and applications (e.g.: data science, advanced analytics)</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Design and develop health and performance monitoring tools (MLOps) of data pipelines and the \u00a0machine learning services in production</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Design and improve heterogenous, asynchronous and high-performance large-data processing pipelines from/to multiple sources/destinations</li>\n</ul>\n<ul class=\"nitro-offscreen\" style=\"box-sizing: inherit; padding-left: 1.5em; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">\n<li style=\"box-sizing: inherit; outline: none !important;\">Operationalize innovative, data-intensive, end-to-end machine-learning(ML)-based decision engines</li>\n</ul>\n<div class=\"h5\" style=\"box-sizing: inherit; margin-top: 3.5rem; margin-bottom: 1.6rem; font-size: 1.125rem; font-weight: bold; line-height: 1.35; font-family: 'Mark Pro', Helvetica, Arial, sans-serif; color: #303037; outline: none !important;\">YOUR PROFILE</div>\n<ul class=\"nitro-offscreen\" style=\"box-sizing: inherit; padding-left: 1.5em; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">\n<li style=\"box-sizing: inherit; outline: none !important;\">Highly motivated with excellent communication and strong interpersonal skills</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">In-depth knowledge and professional working experience with software engineering, ETL pipelines and setting up machine learning workflows</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Proficiency in Python</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Experience in implementing and deploying REST microservices and Kafka messaging queues in AWS cloud ecosystem</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Basic understanding of data science project lifecycles and commonly associated RDBMS/NoSQL technologies</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Fluent written and verbal communication in English</li>\n</ul>\n<p>\u00a0</p>\n<p class=\"nitro-offscreen\" style=\"box-sizing: inherit; margin-bottom: 1.25rem; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">As a plus:</p>\n<ul class=\"nitro-offscreen\" style=\"box-sizing: inherit; padding-left: 1.5em; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">\n<li style=\"box-sizing: inherit; outline: none !important;\">2+ years of experience in deploying and maintaining in production data pipelines working at scale which are fuelling and/or being fueled by machine learning models in production</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Basic understanding of machine learning product lifecycle and the commonly associated components (MLOps): Experimental Environment (e.g.: Python scikit learn, Jupyter Notebook) Workflow management (e.g.: MLFlow), Feature Stores (e.g.: Feast), DataOps/Pipelines (e.g.: Kafka), Model Deployment (e.g.: Terraform), Testing, Serving (e.g.: Docker, Flask). and Monitoring (e.g.: Datadog), Model Repository (e.g.: DVC) *</li>\n</ul>\n<p>\u00a0</p>\n<p class=\"nitro-offscreen\" style=\"box-sizing: inherit; margin-bottom: 1.25rem; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">*\u00a0<em style=\"box-sizing: inherit; outline: none !important;\">List of technologies/methodologies is for illustrative purposes. You are not expected to have experience in each single one of these technologies/methodologies.\u00a0<span style=\"box-sizing: inherit; font-weight: bolder; outline: none !important;\">We don\u2019t believe in super-heroes but rather in super-teams\u00a0</span></em><span style=\"box-sizing: inherit; font-weight: bolder; outline: none !important;\">\ud83d\ude42</span></p>\n<div class=\"h5\" style=\"box-sizing: inherit; margin-top: 3.5rem; margin-bottom: 1.6rem; font-size: 1.125rem; font-weight: bold; line-height: 1.35; font-family: 'Mark Pro', Helvetica, Arial, sans-serif; color: #303037; outline: none !important;\">WHY US?</div>\n<ul class=\"nitro-offscreen\" style=\"box-sizing: inherit; padding-left: 1.5em; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">\n<li style=\"box-sizing: inherit; outline: none !important;\">Culture of trust, constructive feedback and self-organization, agile mindset, regular face-to-face team building events and regular knowledge sharing (E.g.: through tech talks , including invited keynotes as well)</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Be paid a high competitive compensation (at Central European standards) that recognizes your talent \u2013 without excuses, vouchers or other shortcuts. Just a fair salary for YOU</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Get to make a real impact on thousands of small businesses every day, contributing for more equal and inclusive economy around the globe</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Work with the best and learn from other competent and brilliant people</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Get access to our Internal Tech Academy \u2013 where the company invests on your continuous training and professional growth (individual growth plan, internal top-flight coaches, paid conferences/courses/learning materials, dedicated working time for learning purposes)</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Be supported to grow and take leadership from day one</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Enjoy 24 days of paid holidays</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Benefit from flexible working hours and additional Company Holidays on 24th and 31st December</li>\n<li style=\"box-sizing: inherit; outline: none !important;\">Possibility of participating in our company equity program (senior level-above)</li>\n</ul>\n<p>\u00a0</p>\n<p class=\"nitro-offscreen\" style=\"box-sizing: inherit; margin-bottom: 1.25rem; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">Check out our\u00a0<a href=\"https://stackshare.io/companies/finiata-gmbh\" rel=\"nofollow\" style=\"box-sizing: inherit; color: #313896; text-decoration: underline; outline: none !important;\">StackShare</a>.</p>\n<p class=\"nitro-offscreen\" style=\"box-sizing: inherit; margin-bottom: 1.25rem; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">Check out our\u00a0<a href=\"https://finiata.dev/\" rel=\"nofollow\" style=\"box-sizing: inherit; color: #313896; text-decoration: underline; outline: none !important;\">blog</a>.</p>\n<p class=\"nitro-offscreen\" style=\"box-sizing: inherit; margin-bottom: 1.25rem; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">\u00a0</p>\n<div class=\"h5\" style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; font-family: 'Source Sans Pro', sans-serif; font-weight: 500; line-height: 1.2; color: #313896; font-size: 18px; text-transform: uppercase; background-color: #ffffff;\"><strong><span style=\"color: #000000;\">ABOUT US</span></strong></div>\n<p><span style=\"font-size: 11pt; background-color: #ffffff; color: #212529; font-family: 'Source Sans Pro', sans-serif;\">Finiata is a technology provider that enables small businesses to focus on what matters most: their business. As a data-first organisation, we wake up everyday to challenge the established practices in the B2B Fintech landscape. We do it by building cutting-edge AI technology in-house that enables us to personalise profitable lending offers at scale and in real-time.\u00a0</span></p>\n<div class=\"detail-block-description\" style=\"box-sizing: border-box; color: #212529; font-family: 'Source Sans Pro', sans-serif; font-size: 16px; background-color: #ffffff;\">\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; line-height: 1.38;\"><span style=\"box-sizing: border-box; font-size: 11pt;\">Our direct-to-market Finiata app enables businesses to have working-capital approved in less than 7 minutes. Our lending-as-a-service platform allows online marketplaces, payment providers and any other product company focused on solving small business\u2019 needs \u00a0to underwrite customers and solve the working-capital problem with little-to-no technological background or lending expertise. Ultimately, we strongly believe in solving our customers\u2019 challenges regardless of their geographical footprint, business model, product channels or industrial vertical through extreme data-driven customer centricity.</span></p>\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; line-height: 1.38;\"><span style=\"box-sizing: border-box; font-size: 11pt;\">Finiata was founded in 2016 and is funded by top European investors. Our team is filled with curious people who want to learn while having fun and consists of more than 50+ talents from 20+ nations located in three offices in Germany and Poland, Ukraine, as well as globally (remote). We appreciate the power of diversity and share a passion for product development, technology and creating exceptional user experiences that have a real impact on our customers\u2019 lives. Join a fast-growing company of smart and ambitious people to support more than 1 million small businesses over the next 5 years!</span></p>\n</div>\n<p class=\"nitro-offscreen\" style=\"box-sizing: inherit; margin-bottom: 1.25rem; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">\u00a0</p>\n", "company_logo_url": "https://remotive.io/job/993987/logo"}, {"id": 993986, "url": "https://remotive.io/remote-jobs/data/senior-data-scientist-993986", "title": "(Senior) Data Scientist", "company_name": "Finiata", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-15T12:40:45", "candidate_required_location": "Europe: selected countries RO/IT/PL/PT/DE", "salary": "", "description": "<p style=\"box-sizing: inherit; margin-bottom: 1.25rem; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Machine Learning (ML) is revolutionizing the way of doing business at a global scale. In business lending, Finiata takes the technological forefront by developing proprietary technology that allows us to take accurate decisions in a fully data driven fashion. YOU will contribute to further develop the in-house all-data-things technology by engineering and productizing novel pipelines and ML models.</span></p>\n<p style=\"box-sizing: inherit; margin-bottom: 1.25rem; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Note:\u00a0</span><span style=\"box-sizing: inherit; outline: none !important;\">This position is fully remote as long as you are legally based in Germany, Poland, Portugal, Italy and Romania. You may be required to travel for business purposes (e.g.: participation in team building activities, professional workshops) up to 10% of the time.</span></p>\n<div class=\"h5\" style=\"box-sizing: inherit; margin-top: 3.5rem; margin-bottom: 1.6rem; font-size: 1.125rem; font-weight: bold; line-height: 1.35; font-family: 'Mark Pro', Helvetica, Arial, sans-serif; color: #303037; outline: none !important;\"><span style=\"box-sizing: inherit; font-weight: bolder; outline: none !important;\">YOUR MISSION</span></div>\n<ul class=\"nitro-offscreen\" style=\"box-sizing: inherit; padding-left: 1.5em; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Apply data science in areas like credit risk modeling, affordability and pricing, KPI forecasting,\u00a0 automated model evaluation (AutoML), causality and model interpretability (XAI)</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Define the new state-of-the-art for machine learning engineering in the financial services for SMEs, going beyond the established status quo;</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Develop machine learning expertise beyond basic supervised and unsupervised learning, mentor and be mentored\u00a0 by other team members</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Prototype and subsequently operationalize innovative, data-intensive, end-to-end machine-learning-based decision engines, following the latest best practices on MLOps</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Demonstrate your leadership skills and manage a Machine Learning based project or product, which you will define through frequent interactions with experienced financial-services professionals</span></li>\n</ul>\n<p>\u00a0</p>\n<div class=\"h5\" style=\"box-sizing: inherit; margin-top: 3.5rem; margin-bottom: 1.6rem; font-size: 1.125rem; font-weight: bold; line-height: 1.35; font-family: 'Mark Pro', Helvetica, Arial, sans-serif; color: #303037; outline: none !important;\"><span style=\"box-sizing: inherit; font-weight: bolder; outline: none !important;\">YOUR PROFILE</span></div>\n<ul class=\"nitro-offscreen\" style=\"box-sizing: inherit; padding-left: 1.5em; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Highly motivated with excellent communication and strong interpersonal skills</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">M.Sc or PhD in a quantitative field and/or working experience as a Data Scientist or Machine Learning Engineer</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Proficiency in Python with ability to translate ideas into prototypes and prototypes into production</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Experience with working on Machine Learning projects to learn from structured data, as well as, deep knowledge on statistics</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Fluent written and verbal communication in English</span></li>\n</ul>\n<p>\u00a0</p>\n<p class=\"nitro-offscreen\" style=\"box-sizing: inherit; margin-bottom: 1.25rem; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Bonus:</span></p>\n<ul class=\"nitro-offscreen\" style=\"box-sizing: inherit; padding-left: 1.5em; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Deep knowledge of the theory and expertise on the application of Machine Learning</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">PhD in Machine Learning and/or data mining fundamental topics and/or non-trivial applications of ML/DM foundations</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Solid Python and software engineering skills, including best practices like CI/CD and Git</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Top tier academic track on ML/DM conferences (e.g.: KDD, NeurIPS, ICML, AAAI, ECML/PKDD)</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Proven experience in contributing to machine learning engineering teams in industry (2+ yrs.)</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Experience on MLOps in modern cloud systems (preferentially, AWS)</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Experience with Agile philosophies (e.g.: Scrum, Scrumban, Kanban, XP) and project management tools (e.g.: JIRA) *</span></li>\n</ul>\n<p>\u00a0</p>\n<p class=\"nitro-offscreen\" style=\"box-sizing: inherit; margin-bottom: 1.25rem; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\"><em><span style=\"box-sizing: inherit; outline: none !important;\">* List of technologies/methodologies is for illustrative purposes. You are not expected to have experience in each single one of these technologies/methodologies. We don\u2019t believe in super-heroes but rather in super-teams \ud83d\ude42</span></em></p>\n<div class=\"h5\" style=\"box-sizing: inherit; margin-top: 3.5rem; margin-bottom: 1.6rem; font-size: 1.125rem; font-weight: bold; line-height: 1.35; font-family: 'Mark Pro', Helvetica, Arial, sans-serif; color: #303037; outline: none !important;\"><span style=\"box-sizing: inherit; font-weight: bolder; outline: none !important;\">WHY US?</span></div>\n<ul class=\"nitro-offscreen\" style=\"box-sizing: inherit; padding-left: 1.5em; color: #303037; font-family: 'Source Sans Pro', sans-serif; font-size: 18px; outline: none !important;\">\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Culture of trust, constructive feedback and self-organization, agile mindset, regular face-to-face team building events and regular knowledge sharing (E.g.: through tech talks , including invited keynotes as well)</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Be paid a high competitive compensation (at Central European standards) that recognizes your talent \u2013 without excuses, vouchers or other shortcuts. Just a fair salary for YOU</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Get to make a real impact on thousands of small businesses every day, contributing for more equal and inclusive economy around the globe</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Work with the best and learn from other competent and brilliant people</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Get access to our Internal Tech Academy \u2013 where the company invests on your continuous training and professional growth (individual growth plan, internal top-flight coaches, paid conferences/courses/learning materials, dedicated working time for learning purposes)</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Be supported to grow and take leadership from day one</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Enjoy 24 days of paid holidays</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Benefit from flexible working hours and additional Company Holidays on 24th and 31st December</span></li>\n<li style=\"box-sizing: inherit; outline: none !important;\"><span style=\"box-sizing: inherit; outline: none !important;\">Possibility of participating in our company equity program (senior level-above)</span></li>\n</ul>\n<p>\u00a0</p>\n<div class=\"h5\" style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 20px; font-family: 'Source Sans Pro', sans-serif; font-weight: 500; line-height: 1.2; color: #313896; font-size: 18px; text-transform: uppercase; background-color: #ffffff;\"><strong><span style=\"color: #000000;\">ABOUT US</span></strong></div>\n<p><span style=\"font-size: 11pt; background-color: #ffffff; color: #212529; font-family: 'Source Sans Pro', sans-serif;\">Finiata is a technology provider that enables small businesses to focus on what matters most: their business. As a data-first organisation, we wake up everyday to challenge the established practices in the B2B Fintech landscape. We do it by building cutting-edge AI technology in-house that enables us to personalise profitable lending offers at scale and in real-time.\u00a0</span></p>\n<div class=\"detail-block-description\" style=\"box-sizing: border-box; color: #212529; font-family: 'Source Sans Pro', sans-serif; font-size: 16px; background-color: #ffffff;\">\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; line-height: 1.38;\"><span style=\"box-sizing: border-box; font-size: 11pt;\">Our direct-to-market Finiata app enables businesses to have working-capital approved in less than 7 minutes. Our lending-as-a-service platform allows online marketplaces, payment providers and any other product company focused on solving small business\u2019 needs \u00a0to underwrite customers and solve the working-capital problem with little-to-no technological background or lending expertise. Ultimately, we strongly believe in solving our customers\u2019 challenges regardless of their geographical footprint, business model, product channels or industrial vertical through extreme data-driven customer centricity.</span></p>\n<p style=\"box-sizing: border-box; margin-top: 0px; margin-bottom: 1rem; line-height: 1.38;\"><span style=\"box-sizing: border-box; font-size: 11pt;\">Finiata was founded in 2016 and is funded by top European investors. Our team is filled with curious people who want to learn while having fun and consists of more than 50+ talents from 20+ nations located in three offices in Germany and Poland, Ukraine, as well as globally (remote). We appreciate the power of diversity and share a passion for product development, technology and creating exceptional user experiences that have a real impact on our customers\u2019 lives. Join a fast-growing company of smart and ambitious people to support more than 1 million small businesses over the next 5 years!</span></p>\n</div>\n", "company_logo_url": "https://remotive.io/job/993986/logo"}, {"id": 988948, "url": "https://remotive.io/remote-jobs/data/data-scientist-power-platform-developer-mid-level-faa-988948", "title": "Data Scientist / Power Platform Developer, Mid-level - FAA ", "company_name": "Cobec", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-15T09:45:13", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>Position:\u00a0 <strong>Data Scientist / Power Platform Developer, Mid-level - FAA</strong></strong><strong>\u00a0</strong></p>\n<p>\u00a0</p>\n<p><strong>Function: </strong>Data Science</p>\n<p>\u00a0</p>\n<p><strong>Location: </strong>Remote</p>\n<p><strong>\u00a0</strong></p>\n<p><strong>Remote Work Option:</strong> Yes</p>\n<p>\u00a0</p>\n<p><strong>Culture </strong></p>\n<p>Cobec is consistently breaking the current mold for delivering services to our government clients. What does that mean? That means believing in a \u201cpeople first\u201d mentality, building high performance teams and empowering people to make informed decisions without going through a large bureaucratic system. Cobec values the well-being of employees and bestows tremendous trust in those people to negotiate work and non-work obligations. Cobec is where someone can bring their whole self to work and be themselves, never having to compromise their authenticity just to fit in. Lastly, we believe in the work we do, the goals and missions of our customers and the interpersonal relationships we have with clients, stakeholders and our people.</p>\n<p><strong>\u00a0</strong></p>\n<p><strong>Values and Expectations </strong></p>\n<p>The successful candidate for this role embodies the same values as Cobec. We realize experience is important, however; Cobec believes a person\u2019s abilities and skills that align with our values (Relationships, Leadership, Passion, Accountability, Integrity, Innovation, Quality, Teamwork, Diversity, Commitment, &amp; Respect) are the most important drivers for success in this role.</p>\n<p>In addition to exhibiting our values, a successful candidate for this role is expected to be a high performer, organized, dynamic, and have a positive attitude.</p>\n<p>\u00a0</p>\n<p><strong>Job Summary</strong></p>\n<p>\u00a0</p>\n<p>This position will apply advanced analytical and mathematical techniques to solve complex decision problems.\u00a0 Candidate will use high performance computing, big data analytics and data visualization tools and techniques to assist in making acquisition decision and to maximize operational effectiveness and efficiency.</p>\n<p><strong>\u00a0</strong></p>\n<p><strong>Years of Relevant Experience</strong></p>\n<p>\u00a0</p>\n<p>The position requires 2 - 7 equivalent years of experience in operations research, modeling and simulation, or technical analysis. Specific experience with the Federal Aviation Administration (FAA) or the Aviation Industry is desired.\u00a0</p>\n<p>\u00a0</p>\n<p><strong>Essential Job Functions</strong></p>\n<p>\u00a0</p>\n<ul>\n<li>Individual will support model and simulation development to provide quantitative analyses, cost-benefit and economic analyses to support the Federal Aviation Administration Program Acquisition and Operational Systems Evaluation.</li>\n<li>Individual will have experience in data collection, data normalization techniques, statistical analysis, performance metrics development and tracking and other mathematical/operations research techniques and methods.</li>\n<li>Individuals will also support process and policy improvement for operations research and modeling guidelines, including research and assessment of operations research tools.</li>\n<li>Individuals will be required to contribute effectively to working groups through oral and written communication and cooperative working relationships</li>\n<li>Individuals will support the develop of custom visualizations</li>\n</ul>\n<p>\u00a0</p>\n<p>\u00a0</p>\n<p>\u00a0</p>\n<p><strong>Education Requirements</strong></p>\n<p>Bachelor\u2019s degree required, preferably in Engineering, Mathematics, Operations Research, Physics, Economics, or similar.</p>\n<p>\u00a0</p>\n<p>Master\u2019s degree is a plus</p>\n<p>\u00a0</p>\n<p><strong>Skills Requirements</strong></p>\n<ul>\n<li>2+ years of experience with Microsoft Power Platform based development and in the use of Microsoft 365 components, including SharePoint, Teams and Power Automate, including Power Apps and Power Automate</li>\n<li>2+ years of experience with development using one of the following two design patterns, including Canvas App with Power Automate and SharePoint Online List or Microsoft List or Power Portal with Model Driven App and Dataverse</li>\n<li>3+ years of experience with conducting and participating in design reviews and code reviews</li>\n<li>3+ years of experience with developing and reviewing SDLC work products and artifacts</li>\n<li>Experience with using Agile development methods and processes</li>\n<li>Ability to analyze time and effort estimation of design and development work to support sprint planning</li>\n<li>Experience with SQL/Database Management is desired</li>\n<li>Experience with MATLAB, SAS, Python, Java/C++/VBA and MS Office Products is desired</li>\n<li>Experience with and data visualization tools such Shiny, Tableau, Cold Fusion is desired</li>\n</ul>\n<p>\u00a0</p>\n<p>\u00a0</p>\n<p><strong>Security Requirements</strong></p>\n<p>Must be a US citizen or a legal resident for three of the past five years</p>\n<p>Must meet eligibility requirements for a US Public Trust security clearance</p>\n<p>\u00a0</p>\n<p><strong>Travel</strong></p>\n<p>Occasional travel required as needed by client/s and/or company</p>\n<p>\u00a0</p>\n<p><strong>EEO</strong></p>\n<p>Cobec Consulting, Inc. is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, sex, age, sexual orientation, gender identity, national origin, disability, veteran status or any other status protected by federal, state and local law.</p>\n<p><a href=\"https://www.eeoc.gov/sites/default/files/migrated_files/employers/eeoc_self_print_poster.pdf\" rel=\"nofollow\"><strong>EEO is the Law</strong></a></p>"}, {"id": 987090, "url": "https://remotive.io/remote-jobs/data/data-engineer-entry-level-987090", "title": "Data Engineer - Entry Level", "company_name": "Mercury Data Science", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-14T21:44:19", "candidate_required_location": "USA Only", "salary": "", "description": "<br><br><div class=\"h3\">Company Description</div><p><strong>Our focus </strong>is to help Biotech/BioPharma, MedTech, Digital Health, Healthcare, Insurance, and Tech organizations accelerate innovation, enable data-driven decisions, and create AI/ML applications. We leverage AI to solve today\u2019s hardest challenges. We are driven to make the world a better place by providing consulting services and building applications to improve outcomes and help our clients stay ahead of the competition.</p><p><strong>Our team </strong>is composed of creative and results-focused individuals who excel at solving real-world problems. Our diverse backgrounds bring technology and expertise from various disciplines including neuroscience, physics, engineering, computational biology, genomics, mathematics, and computer science.\u00a0</p><p><strong>Our culture </strong>is vibrant, connected, rooted in our core values statement that:<br>Our work matters. Our clients are partners. Our work is our reputation. We own our choices. We are always learning. We support and challenge each other.</p><p><em>This role is eligible for flexible hours and remote work.</em></p><br><br><div class=\"h3\">Job Description</div><p>We are looking for recent or soon-to-be graduates in the STEM space or those who are exceptionally talented in the software space regardless of education. If you love to code, are open to a challenge, and are willing to work to be the best in the field, then this is the job for you.\u00a0</p><p>Depending on your experience you could either work as a Data, ML, or Software Engineer working on client engagements or on internal product development. You will be exposed to cutting and bleeding-edge technology - and may be involved in building it too!\u00a0<br><br>We are a predominantly Python/Javascript shop, but there will also be exposure to Go, R, Java/Scala, C/C++, and much more. You will become, if you aren\u2019t already, a trained cloud guru, knowledgeable in not only the cloud vendor stacks but also in cloud-native stacks.</p><p>You\u2019ll come in with your current skills and over your tenure and progression upward here you will become an expert in software engineering, data engineer, machine learning engineering, DevOps engineering, and much more.\u00a0</p><p>If you are more experienced and think that you may fit a higher grade, then send in your resume anyhow, we are always on the lookout for exceptional engineers.</p><br><br><div class=\"h3\">Qualifications</div><ul><li>Entry\u00a0to\u00a0intermediate coding skills in Python or javascript</li><li>Experience with version control</li><li>Experience building a solution in code (school work, personal projects, etc)</li><li>Know what the Cloud is and basic around using the cloud</li><li>Familiarity with Infrastructure-as-Code</li><li>A STEM Degree or similar experience<br>\u00a0</li></ul><p><strong>Tools We Love</strong></p><ul><li>Programming Languages: Python, Javascript, Scala, C++, Matlab</li><li>DevOps: Terraform, Docker, Kuberentes, git, Jenkins, and related toolsets</li><li>ML Workflow Tooling: Sagemaker, MLFlow, Kubeflow, DVC, Argo+Polyaxon+Seldon, Argo</li><li>Data Processing: dbt, python+pandas, AWS Glue (Jobs), Spark/pySpark, Fivetran, Matillion, Dask</li><li>Data Warehousing/Lakes: Redshift, Snowflake, BigQuery, Synapse, Athena, S3/gcs/ADLS</li></ul><br><br><div class=\"h3\">Additional Information</div><p><strong>Skill Level</strong><br>1-2 years experience/relative skills</p>"}, {"id": 988414, "url": "https://remotive.io/remote-jobs/data/analytics-strategist-988414", "title": "Analytics Strategist", "company_name": "Ffwagency", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-14T09:39:32", "candidate_required_location": "USA Only", "salary": "", "description": "<div class=\"h4\"><strong>About FFW</strong></div>\n<p>For over\u00a020 years, FFW has provided significant digital experiences to the world\u2019s largest brands many within the Fortune 50 in finance, power, media, healthcare, and pharmaceuticals. FFW is a team of more than 400 people across 11 countries and growing fast. Not only do we work with large organizations, but we have a diverse portfolio across various verticals working on a variety of mission-critical digital solutions.</p>\n<div class=\"h4\"><strong>About the Position</strong></div>\n<p>We are looking for an<em>\u00a0analytics strategist</em> to join our <em>Insights &amp; Optimization</em> team. This full-time position can be remote, anywhere in the US, with occasional travel required. This role will focus predominantly on web analytics strategy and analytics solution design; we are <em>not</em> currently looking for applicants seeking a data scientist position.</p>\n<div class=\"h4\"><strong>The ideal candidate has</strong></div>\n<ul>\n<li>A passion for using data to tell stories, surface insights, and inform decisions</li>\n<li>Expert-level knowledge of digital analytics and tag management concepts</li>\n<li>The ability to conduct an insightful analysis of digital data to help clients answer key business questions</li>\n<li>4+ years of hands-on experience in analytics strategy and execution</li>\n<li>Expert knowledge of Google Analytics and/or Adobe Analytics</li>\n<li>Solid understanding of web fundamentals and SEO best practices</li>\n<li>Experience working at a digital agency or ad agency<br><br></li>\n</ul>\n<div class=\"h4\"><strong>Key Responsibilities</strong></div>\n<ul>\n<li>Conduct analytics audits of digital properties as part of project discovery</li>\n<li>Lead stakeholder discussions and help clients to translate business objectives into website KPIs and goals</li>\n<li>Produce analytics measurement plans for all types of digital properties \u2013 from single-page applications to large multi-site platforms</li>\n<li>Define analytics strategy and approach for client projects</li>\n<li>Train clients on how to access and leverage their data to make informed decisions</li>\n<li>Work with our Experience Design team to align measurement needs to UX strategy and provide data analysis support for user research and optimization activities</li>\n<li>Work with our Solutions Consulting team to advise on data and analytics technology topics</li>\n<li>Work with our Development team to hand-off measurement requirements for technical implementation</li>\n</ul>\n<div class=\"h4\"><strong>Required Skills</strong></div>\n<ul>\n<li>Excellent written and verbal communication skills and ability to succinctly summarize key findings</li>\n<li>Organize, transform, and connect raw data using spreadsheets and custom formulas</li>\n<li>Define and configure custom dimensions, metrics, variables, segments, and reports.</li>\n<li>Design analytics solutions for conversion tracking including the set-up of goals, funnels, and event tracking</li>\n<li>Produce custom reports, configure views, and perform ad hoc analysis of analytics data</li>\n<li>Build custom dashboards and reports using Google Data Studio, Tableau, Domo, or similar tools.</li>\n<li>Configure common types of tags in a tag management system such as Google Tag Manager, Tealium, or Adobe Launch.</li>\n<li>Conduct an SEO audit by using site crawl data to score and benchmark a site based on industry standards and best practices</li>\n</ul>\n<div class=\"h4\"><strong>Nice to Have</strong></div>\n<ul>\n<li>An analytics certification such as Google Analytics IQ, DAA Web Analyst, Adobe Certified Expert, or similar</li>\n<li>Experience working with Consent Management Platforms (CMP) such as OneTrust, Cookiebot, TrustArc, or similar</li>\n<li>Experience planning and conducting A/B tests and interpreting experiment results using platforms such as Optimizely, Google Optimize, VWO, or similar</li>\n<li>Experience with heat-mapping and/or session recording platforms such as Hotjar, FullStory, or similar</li>\n<li>Experience with analytics for data-driven personalization use cases</li>\n<li>Familiarity with Customer Data Platforms (CDP) such as Segment</li>\n<li>Experience with analytics and reporting from email marketing and/or marketing automation platforms such as Marketo, Salesforce Marketing Cloud, or similar.</li>\n<li>Experience implementing analytics for native mobile apps and/or offline applications</li>\n</ul>\n"}, {"id": 988767, "url": "https://remotive.io/remote-jobs/data/data-analyst-988767", "title": "Data Analyst", "company_name": "Citymapper", "category": "Data", "tags": [], "job_type": "contract", "publication_date": "2021-11-13T21:40:02", "candidate_required_location": "South Korea", "salary": "", "description": "<p>Your work makes the difference between a user seeing a bus drive away or reaching it just in time. We feel a great sense of responsibility at Citymapper. Millions of users around the world trust our green app to be on time for work, a job interview or a date.<br><br></p>\n<p>As one of our Data Analysts for South Korea you will build the timetable data that powers the Citymapper app in Seoul. You'll use secret magic (and our internal tools) to transform often messy transit schedules into shiny and reliable user information whilst building, validating, and shipping data directly to users on a daily basis.</p>\n<p><br>Working with our engineers to improve tools and automate tasks, you'll manage data in a range of cities across different formats.</p>\n<p><br><strong>This role is designed for contractors based in South Korea - you must hold either permanent residency in Korea, or have a working visa with at least 2 years remaining for your application to be considered. </strong><br><br>We are a diverse team of transport enthusiasts from all around the world with extensive language skills, who are not afraid to get our hands dirty with transit data. Join us for the ride!</p>\n<p><em>We love languages here at Citymapper, but for the purposes of this role,<strong> please submit your application in English.</strong></em></p>\n<p><strong>Requirements</strong></p>\n<p>The position is open to applicants with all levels of experience as we'll teach you the technical skills to succeed. You'll need:</p>\n<ul>\n<li>A true passion for public transport and cities, good understanding of how public transport networks operate.</li>\n<li>A technical mindset, comfortable dealing with data, willingness to learn new data skills.</li>\n<li>A hands-on, proactive, practical, pragmatic attitude.</li>\n<li>An exceptional attention to detail with good organisational skills.</li>\n<li>Some familiarity with common transit data formats or data-wrangling is a plus (GTFS, TransXChange, Siri, Hafas, JSON, XML etc)</li>\n<li>Korean language skills a must-have!</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<ul>\n<li>Contractor position in a remote-first team.</li>\n<li>Working on something interesting and meaningful - helping to make cities usable.</li>\n<li>Working with a not-too-big, diverse engineering team.</li>\n<li>Arcane public transport knowledge with which to dazzle your friends.</li>\n</ul>\n<p>\u00a0</p>\n<p>\u00a0</p>\n<p><em>We believe that diverse teams are the best teams and we're proud to be an equal opportunities employer. We welcome and will consider all applications regardless of age, disability, gender re-assignment, marriage, pregnancy, maternity, race or nationality, religion or belief, sex and sexual orientation (and any other status protected by applicable law)</em></p>\n<p>\u00a0</p>\n<p><img alt=\"\" src=\"https://workablehr.s3.amazonaws.com/uploads/photos/3358/c36eaf155aeb5ce49acd46166642968a.png\" title=\"\"></p>\n"}, {"id": 988769, "url": "https://remotive.io/remote-jobs/data/regional-data-manager-988769", "title": "Regional Data Manager", "company_name": "Citymapper", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-13T05:40:31", "candidate_required_location": "Anywhere", "salary": "", "description": "<p>At Citymapper, we've taken on some of the most complex cities in the world and made them easier to navigate. We're obsessed with making cities less complicated for everyone, everywhere, and as we embark upon even more cities, we're looking for exceptional managers to join our data operations team and help build the very best data for public transport and micro-mobility globally.<br><br>We are hiring for this role in London but are open to considering remote positions based around the world.</p>\n<p>\u00a0</p>\n<p>In this role you will:</p>\n<ul>\n<li>Manage a small team of local/remote Data Analysts day to day on the ground in key locations, ensuring the highest data quality for all regions</li>\n<li>Report to the operational team leadership and drive data quality metrics for a set of countries</li>\n<li>Scope, lead and manage data driven projects. Providing technical assistance and input</li>\n<li>Develop relationships with transport providers and local authorities throughout the regions you are responsible for</li>\n<li>Oversee the development and launch of our consumer product in new locations</li>\n<li>Provide us with essential analysis, research and insight on key regions</li>\n</ul>\n<p>We are recruiting Regional Managers for North America, West Europe, East Europe primarily.</p>\n<p><strong>Requirements</strong></p>\n<ul>\n<li>4-7 years\u2019 technical and/or operational management or team lead experience in a fast-paced, product-oriented company</li>\n<li>Experience working with volume data, being part of technical projects and working with data tools</li>\n<li>Entrepreneurial attitude and strong commercial and business acumen grown from high growth, hands on, and data-driven environments</li>\n<li>Excellent problem-solving skills; you need to be naturally curious and enjoy identifying and delivering solutions to complex problems</li>\n<li>Fluency in English is a must (other languages considered a huge plus)</li>\n<li>Comfortable in a remote-first team</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<ul>\n<li>Flexible, remote-first team</li>\n<li>Working on something interesting and meaningful - helping to make cities usable</li>\n<li>Working with a not-too-big, diverse data team</li>\n<li>Arcane transit knowledge with which to dazzle your friends</li>\n</ul>\n<p>\u00a0</p>\n<p><em>We believe that diverse teams are the best teams and we're proud to be an equal opportunities employer. We welcome and will consider all applications regardless of age, disability, gender re-assignment, marriage, pregnancy, maternity, race or nationality, religion or belief, sex and sexual orientation (and any other status protected by applicable law).</em></p>\n"}, {"id": 987579, "url": "https://remotive.io/remote-jobs/data/senior-data-scientist-987579", "title": "Senior Data Scientist", "company_name": "User Interviews", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-13T01:41:24", "candidate_required_location": "USA Only", "salary": "", "description": "<div><strong style=\"font-size: 18px;\">About User Interviews</strong></div>\n<div>At User Interviews, we believe that the best companies in the world consistently deliver products and experiences that their customers love. We also believe that the only way to consistently build those products and experiences is to talk to your customers. Watch what they do. Understand why they do what they do. Figure out why they do things that seem irrational. And once you\u2019ve done that once, do it again. Start having constant conversations. In short, make customers your #1 priority through user research.\u00a0\u00a0</div>\n<div>\u00a0</div>\n<div>That\u2019s why we exist. We help teams set up those conversations, allowing them to discover and embrace user insights. We currently do that by making it fast and easy to talk to customers, or potential customers, to help with product, design, or marketing decisions. We work with hundreds of companies every month, including user-centric organizations like Atlassian, Amazon, and Spotify.</div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 18px;\">About the Role\u00a0</strong></div>\n<div>The mission of the Analytics team at User Interviews is to own all of the company\u2019s data and to analyze it in ways that help us make better decisions. We work with every team, including Product, Marketing, Sales, Operations, and executives, across diverse data sets. As a Senior Data Scientist, you\u2019ll be involved throughout projects, from planning to building, to assessing.\u00a0</div>\n<p><br><br></p>\n<div class=\"h3\">Responsibilities</div>\n<ul>\n<li>Use analytical skills to create and test hypotheses, and visualization/presentation skills to communicate results to your stakeholders.</li>\n</ul>\n<ul>\n<li>Help people across the company use information to make the best decisions possible.\u00a0</li>\n</ul>\n<ul>\n<li>Work with large data sets across multiple problem areas. This includes vetting new datasets as they come in and developing deep intuition about how all of our data fits together.\u00a0</li>\n</ul>\n<ul>\n<li>Own your team's experimentation and modeling.</li>\n</ul>\n<ul>\n<li>Focus on automating reporting tools and dashboards so that we can spend more time on the most complex problems.\u00a0</li>\n</ul>\n<ul>\n<li>Work with other Analytics teammates, including Data Engineering, to level up our skills and knowledge.</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">Some sample projects that the Analytics team has helped with</div>\n<ul>\n<li>How can we improve customer retention?\u00a0</li>\n</ul>\n<ul>\n<li>What should the Product team build next? Once it\u2019s built, how does it perform?\u00a0</li>\n</ul>\n<ul>\n<li>How much should we charge for our subscription offering?</li>\n</ul>\n<ul>\n<li>What happens when we move a company to a subscription?\u00a0</li>\n</ul>\n<ul>\n<li>What defines success for the Operations team?\u00a0</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">Qualifications</div>\n<ul>\n<li>Fluency in SQL, and proficiency in either R or Python</li>\n</ul>\n<ul>\n<li>Knowledge of statistics and other data analysis methods</li>\n</ul>\n<ul>\n<li>Experience working with large, complex datasets, preferably at a software company</li>\n</ul>\n<ul>\n<li>Ability to verify, analyze, and present data in ways that other stakeholders can internalize</li>\n</ul>\n<ul>\n<li>\u00a0</li>\n</ul>\n<ul>\n<li><strong>Nice to Have\u2019s:</strong></li>\n</ul>\n<ul>\n<li>Bachelor\u2019s or Master\u2019s in a quantitative field (e.g. Statistics, Mathematics, or Economics); professional experience in Data Science can be a replacement</li>\n</ul>\n<ul>\n<li>Experience working with engineering to build good data infrastructure</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">Benefits</div>\n<ul>\n<li>100% premium covered medical + dental employee coverage</li>\n</ul>\n<ul>\n<li>Annual membership to <strong>One Medical Group</strong></li>\n</ul>\n<ul>\n<li>401k + employer contribution</li>\n</ul>\n<ul>\n<li>4 weeks of PTO to start + accrue an additional day per year of employment</li>\n</ul>\n<ul>\n<li>Unlimited wellness days - Sick? Doctors appointment? Mental health day? We\u2019ve got you covered.</li>\n</ul>\n<ul>\n<li>Flexible, paid parental leave</li>\n</ul>\n<ul>\n<li>Stock options for every employee</li>\n</ul>\n<ul>\n<li>$250 Office setup budget</li>\n</ul>\n<ul>\n<li>Annual learning &amp; development stipend</li>\n</ul>\n<ul>\n<li>Performance-based incentive plans</li>\n</ul>\n<ul>\n<li>Awards for 360-degree recognition, work anniversaries, &amp; birthdays</li>\n</ul>\n<ul>\n<li>1-2 team retreats per year (virtual and in-person options)</li>\n</ul>\n<div><span style=\"font-size: 11pt;\">User Interviews is a\u00a0</span><strong style=\"font-size: 11pt;\">fully remote\u00a0</strong><span style=\"font-size: 11pt;\">team (even in the before times). We are proactive about staying connected to one another despite not sharing the same physical space. Remote culture is real and we care about it\u2014a lot.\u00a0</span></div>\n<div>\u00a0</div>\n<div><span style=\"font-size: 11pt;\">We\u2019re a team of doers. You\u2019ll be fully supported by your manager and team, but there won\u2019t be anyone peering over your shoulder. You\u2019ll be expected and trusted to take ownership of your work, and to communicate clearly and transparently with your distributed teammates.\u00a0</span></div>\n<div>\u00a0</div>\n<div><span style=\"font-size: 11pt;\">On a related note, we\u2019re very pro-feedback. From our users, of course. But also from each other. From individual contributors right up to the CEO, this is a team that is genuinely committed to continuous improvement.\u00a0</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11pt;\">We embrace what makes you, you!</strong></div>\n<div>\u00a0</div>\n<div><span style=\"font-size: 11pt;\">We are committed to accessibility, equity, diversity, and inclusion. We build products for and welcome participants, researchers, and employees from a diverse set of backgrounds. These backgrounds include\u2014but are not limited to\u2014varied socioeconomic status, gender identity or expression, sexual orientation, religion, race, ethnicity, age, neurodivergence, disability, and citizenship.</span></div>\n<div><span style=\"font-size: 11pt;\">\u00a0</span></div>\n<div><span style=\"font-size: 11pt;\">As we grow, we are aware that this work is continuous. We will not settle for how things are, but rather strive for how they could be.</span>\u00a0</div>\n"}, {"id": 985577, "url": "https://remotive.io/remote-jobs/data/bp-data-engineer-985577", "title": "BP - Data Engineer", "company_name": "Datamine", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-12T09:42:08", "candidate_required_location": "New Zealand", "salary": "", "description": "<p>We have an exciting opportunity for a senior data engineer contractor to join a leading organisation with a growing appetite for data. This is an initial 3-month contract, however they have people needs well into 2022, so there is opportunity for further contract work. We are looking for a candidate who is happy to work from home as this contract will be 100% remote. You will work for a supportive and flexible organisation who values and looks after their people with a manager who is always keen to support contractors and make them feel part of the team. This is a well-established team but a new role, they seek a senior who can take on project work and responsibility, work independently, and engage stakeholders. This is a complex organisation and this role will work with data stakeholders throughout the organisation.</p>\n<p>This role is consultative in its nature, it is\u00a0technical and hands on with data and technologies, but also will be involved with analytics teams and other key stakeholders. You will be working in solutions design and end-to-end development. They are an Azure environment, but comfortable hiring a data engineer with either Azure or AWS skills and ideally both.</p>\n<p>Your success in this role will depend as much on your personality as it will on your technical skills, we\u00a0are looking for a candidate with\u00a0a desire to contribute to a team and make an impact on the organisation, a driven and adaptable person will fit well in this team. This is not your typical development position but someone with the ability to work with stakeholders to educate and achieve outcomes. From a technical perspective we are looking for someone with good Azure Data toolkit experience including working with Data Factory, SQL, and SSIS; AWS skills are also suitable. You will be involved in solution design through to end-to-end engineering, in this agile environment.</p>\n<p>This is an excellent organisation to work for which offers a lot of benefits and opportunity. You will be working for a leading organisation and employer.</p>\n<p>If you are interested in finding out more about this role simply hit the \u201capply now\u201d button and send us your CV. Alternatively you can email\u00a0jesse@augmentx.nz\u00a0for more information. Check out www.augmentx.nz and follow us on Linkedin for the latest information on our jobs and what we are up to.</p>\n"}, {"id": 984702, "url": "https://remotive.io/remote-jobs/data/data-scientist-984702", "title": "Data Scientist", "company_name": "SkillUp Coalition", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-11T21:41:10", "candidate_required_location": "USA Only", "salary": "", "description": "<br><br><div class=\"h3\">Company Description</div><p>Founded in 2020, SkillUp Coalition is a 501(c)(3) nonprofit dedicated to helping millions of frontline workers obtain in-demand jobs in high-growth industries.\u00a0 The Coalition is composed of over 60 training and education providers, employers, tech firms and philanthropies, which enables partners to share best practices, collaborate on shared challenges, and participate in public engagement campaigns that help displaced workers begin a prosperous new stage in their careers.</p><p>\u00a0</p><p>SkillUp gives frontline workers the opportunity to build new skills that are suited to in-demand jobs with promising career paths.\u00a0 Since its July 2020 launch, nearly 500,000 workers have visited our curated platform at SkillUp.org, which provides access to three services:</p><p>\u00a0</p><ul><li><p>Career Navigation \u2014 Our tools and resources guide frontline workers in choosing a career path that aligns with the economy of the future (partners include Guild Education, Inside Track)</p></li><li><p>Training Programs \u2014 We help learners find programs that match their career goals and provide funding options to help them cover tuition costs (partners include Generation, edX, YearUp)</p></li><li><p>Job Opportunities \u2014 We connect workers to open roles or earn-and-learn pathways that match workers\u2019 career aspirations (partners include Walmart, Coolsys, Paschall Trucklines)</p></li></ul><p>\u00a0</p><p>All positions at SkillUp are remote, enabling team members to work from anywhere in the US.\u00a0 With such an important mission, we take our work seriously, but we don\u2019t take ourselves seriously.\u00a0 We are building a diverse team from all types of backgrounds, so if you feel like you have the ability to perform the responsibilities of the following job description, please consider applying!</p><br><br><div class=\"h3\">Job Description</div><p>SkillUp seeks a curious, creative, dynamic, and passionate Data Scientist who will be responsible for providing the Leadership Team with the analytics, dashboards, and reports across the organization, including Product, Marketing, Partnerships, and Fundraising.\u00a0</p><p>\u00a0</p><p>This role is a remote, full-time opportunity.</p><p>\u00a0</p><p>In this position you will:</p><ul><li><p>Use your skills to explore and identify trends related to productivity of product offerings and site assets.\u00a0</p></li><li><p>Draw actionable insights from various datasets through effective data visualizations and storytelling</p></li><li><p>Conduct analysis that includes data gathering and requirements specification, processing, analysis, ongoing deliverables, and presentations.</p></li><li><p>Deep dive into marketing analytics to gauge success for awareness and customer acquisition\u00a0 campaigns</p></li><li><p>Deep dive into Google analytics, adoption, and relevance of SkillUp websites</p></li><li><p>Identify, secure and overlay existing 3rd party data sources (e.g., equifax) to augment the information available to SkillUp.\u00a0</p></li><li><p>Conduct ad-hoc analyses exploring topics of interest to SkillUp and our funders.</p></li><li><p>Interact cross-functionally, making recommendations at multiple levels of stakeholders.</p></li><li><p>Research and develop analysis, forecasting, and optimization methods to improve the quality of SkillUp\u2019s internal and external practices and services.</p></li><li><p>Compare analytics across different geographic regions to determine most effective marketing and product tactics to reach audience</p></li><li><p>Enhance data collection efforts to capture and report on user feedback, training outcomes, and employment outcomes</p></li><li><p>Prepare infographics to visually present key findings to internal and external partners</p></li><li><p>Analyzing labor market data to determine best career paths for most economic mobility</p></li></ul><br><br><div class=\"h3\">Qualifications</div><ul><li><p>2+ years experience in Data Science roles or similar research activities</p></li><li><p>Have deep statistical knowledge, utilizing in A/B testing, analyzing observational data, modeling, and other statistical concepts</p></li><li><p>Experience articulating and translating organizational questions and using statistical techniques to arrive at an answer using available data</p></li><li><p>Strong critical thinking and active listening skills to infer organizational needs and ability to work closely with leadership team at a strategic level</p></li><li><p>Experience with statistical software (e.g., R, Python) and database languages (e.g., SQL)</p></li><li><p>Experience coding with a general purpose programming language (i.e. Java, C/C++, Python) preferred</p></li><li><p>Strong data visualization skills</p></li><li><p>Can work independently and collaboratively.</p></li><li><p>Ability to exhibit flexibility, initiative, and innovation to succeed in an ambiguous and fast-paced environment</p></li></ul><br><br><div class=\"h3\">Additional Information</div><p><strong>Benefits</strong></p><p>\u00a0</p><ul><li><p>Healthcare:\u00a0 We pay 100% of your medical, dental, and vision coverage and 50% of the premium for your spouse and dependents.</p></li><li><p>Retirement:\u00a0 We have a 401k Program with company matching.</p></li><li><p>Paid Time Off:\u00a0 We value work-life balance and encourage our team members to take time off. In addition to 12 Paid Company Holidays, we offer the following paid time off:</p></li></ul><ul><li><p>20 Paid PTO days (25 PTO days after reaching the three-year mark)</p></li><li><p>5 Sick days</p></li><li><p>Two weeks of company shutdown during the week of July 4th and between Christmas and New Year\u2019s</p></li><li><p>2 \u201cFloater\u201d days to be used at your discretion</p></li><li><p>Parental Leave: To help support new parents in the workplace, we offer 12 weeks of paid parental leave.</p></li><li><p>Mental Health and other Supports:\u00a0 We live in a stressful world that can affect us physically and emotionally,. To support workers\u2019 well-being, we offer, at no cost to workers, mental health support services through BetterHelp.com. We also offer\u00a0 at no cost to workers, Life Insurance, Short Term Disability, and Long Term Disability benefits.</p></li></ul><p><br>\u00a0</p><p><strong>Perks</strong></p><p>\u00a0</p><ul><li><p>Flexible Work Schedules: We are 100% remote for the foreseeable future, and will continue to offer flexible schedules. Our policies and norms around work schedules are a recognition that we care about work outcomes over time spent at the office.</p></li><li><p>Professional Development: We believe that developing our team members\u2019 skills is a pathway to accomplishing our mission. To this end, we offer you $1,000 annually for the professional development opportunities of your choice.</p></li><li><p>Home Office:\u00a0 We will purchase a work computer for you.\u00a0 We offer a new hire home office stipend up to $500 for the cost of setting up your home for the office as well as a $75 monthly broadband reimbursement.</p></li></ul><p><br>\u00a0</p><p><strong>Additional Information</strong></p><p>\u00a0</p><p>At SkillUp, our mission is to help workers get rehired for in-demand jobs in high-growth industries. Success in this mission requires that we don\u2019t just accept difference\u2014but that we celebrate it and embrace the diverse community and backgrounds individuals come from. In short, it\u2019s one of our key values.\u00a0</p><p>\u00a0</p><p>We stay true to our mission by ensuring that our place can be anyone\u2019s place, and embrace diversity and equal opportunity in a serious way. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. The more inclusive we are, the better our work will be. As a proud equal opportunity employer, SkillUp does not discriminate on the basis of race, color, ancestry, national origin, religion or religious creed, mental or physical disability, medical condition, genetic information, sex (including pregnancy, childbirth, and related medical conditions), sexual orientation, gender identity, gender expression, age, marital status, military or veteran status, citizenship, or other characteristics protected by state or federal law or local ordinance.</p><p>\u00a0</p><p>Let us end without all the legal mumbo-jumbo. Your gender, your gods, your skin color or your bigshot relative don\u2019t make a difference here. SkillUp is an open-minded meritocracy. We recognize that diverse teams make the strongest teams, and we encourage people from all backgrounds to apply. And being inclusive isn't just a catch-phrase for us - it\u2019s mission critical.\u00a0 If you\u2019re smart, good at what you do, and passionate about changing lives - come as you are.</p>"}, {"id": 985204, "url": "https://remotive.io/remote-jobs/data/head-of-data-985204", "title": "Head of Data", "company_name": "Citadel API", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-11T05:40:40", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>The Company you'll Join</strong></p>\n<p>At Citadel, our mission is to make verifications easy for everyone.</p>\n<p>We think it's crazy that it can take 5 to 7 days to verify someone's employment or income. Alternatives are even worse, an API call should\u00a0<strong>not</strong>\u00a0cost $40.</p>\n<p>When Citadel succeeds, we'll save billions of dollars for companies and billions of hours for people who're still filling out forms and uploading paystubs.</p>\n<p>Imagine applying for a loan or verifying your job history with a click of a button. That's what Citadel is empowering.</p>\n<p><strong>The Team You'll Work With</strong></p>\n<p>We're a small but mighty team of engineers, product managers, and business folks who built and launched products at Apple, Uber, Facebook, Carta, Venmo, Telegram, and Plaid. We're well funded by US-based top VC funds.</p>\n<p>We like to nerd out about using the cutting-edge tech and building frictionless user experiences. We love crafting great products and see our users delighted by what we build.</p>\n<p>We're a distributed team with no plans to start an office anytime soon. We don't really care where you are, but we care a lot about who you are. If you like solving customer pain points, helping your team members excel at what they do, being part of a community, and care about quality, you'll fit in.</p>\n<p><strong>What You'll Do</strong></p>\n<ul><li>Lead the team of Data Analysts, Data Scientists and Data Engineers</li><li>Drive implementation and improvement of all data and machine learning products (e.g. search, OCR)</li><li>Define, report, and monitor key performance indicators of product areas</li><li>Convert analytical insights into concrete, meaningful recommendations for business or product improvement, and succinctly communicate these findings to various partners and leadership</li></ul>\n<p><strong>About You</strong></p>\n<ul><li>7+ years experience in data science, machine learning and analytics</li><li>A track record of leading data team and driving cross-functional initiatives</li><li>Experience with building and maintaining data pipelines, ensuring data integrity</li><li>Proficient at both SQL and Python</li></ul>\n<p><strong>Bonus points!</strong></p>\n<ul><li>Experience with building data operations</li><li>Experience with DAG orchestrators (eg. Airflow)</li><li>Experience with search quality analysis and search optimization</li><li>Consumer-facing product experience</li></ul>\n"}, {"id": 978362, "url": "https://remotive.io/remote-jobs/data/data-scientist-978362", "title": "Data Scientist", "company_name": "Dext", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-10T13:40:17", "candidate_required_location": "Europe Only", "salary": "", "description": "<p><br>Check our <a class=\"external\" href=\"https://engineering.dext.com/\" rel=\"nofollow\" target=\"_blank\"><strong>Work With Us</strong></a> page where we give answers to the most important questions you may have.<br><br></p>\n<p><strong>WE ARE DEXT!<br></strong>Our suite of tools makes accountants more productive, profitable and powerful. In doing so we give them back the most precious commodity, time, which they can then use to add greater value to their clients.</p>\n<p>Accountants and bookkeepers are the backbones of every successful business. For more than a decade we\u2019ve empowered our partners with innovative technology solutions to make businesses better. Dext allows them to meet the challenges they face today, tomorrow and in the future.</p>\n<p>\u00a0</p>\n<p><strong>Architecture &amp; Stack<br></strong>Our systems are mostly done using Ruby on Rails. We use Python for machine learning. We have a large web app, a few smaller ones, a few mobile apps (Android and iOS), a growing fleet of services (in the sense of Service-Oriented Architecture) talking via HTTP.</p>\n<p>\u00a0</p>\n<p><strong>Team, Challenges &amp; You<br></strong>The development team is mostly in Bulgaria. Because we\u2019re a remote company we have people in Sofia, Plovdiv, Burgas, Varna, Ruse. Everyone can choose where to work from.</p>\n<p>We have reasonable processes, organised Kanban boards, stand-ups that don\u2019t last more than 10 minutes and product owners writing detailed (sometimes a bit too detailed) specifications. We value highly the quality of the code and good practices. We\u2019ve suffered enough without them. Our management is well aware of that. We\u2019ve even had the need to explain that we don\u2019t need so much time for paying back technical debt. Some of us even talk about those things (<a class=\"external\" href=\"https://forcepush.simplecast.fm/code-reviews\" rel=\"nofollow\">code reviews</a>,<a class=\"external\" href=\"https://forcepush.simplecast.fm/36ee836b\" rel=\"nofollow\"> automated testing</a>,<a class=\"external\" href=\"https://forcepush.simplecast.fm/4bf42d33\" rel=\"nofollow\"> refactoring</a>).</p>\n<p>\u00a0</p>\n<p><strong>About the role<br></strong>We are looking for a Data Scientist to analyze large amounts of raw information to find patterns that will help improve our company. We have lots of data in several databases, some of it is already neatly organised, some not so much. You will need to understand our product requirements and customer needs and help expand them. In this role, you should be highly analytical with a knack for analysis, math and statistics. Critical thinking and problem-solving skills are essential for interpreting data</p>\n<p>\u00a0</p>\n<p><strong>What you'll do</strong></p>\n<ul>\n<li>Carry out preprocessing of structured and unstructured data</li>\n<li>Analyze large amounts of information to discover trends and patterns</li>\n<li>Suggest predictive models and work with the team to build and improve our machine-learning algorithms</li>\n<li>Present information using data visualization techniques</li>\n<li>Propose solutions and strategies to business challenges</li>\n<li>Collaborate with engineering and product development teams</li>\n</ul>\n<p>\u00a0</p>\n<p><strong>What we're expecting</strong></p>\n<ul>\n<li>Proven experience as a Data Scientist</li>\n<li>Understanding of machine-learning and operations research</li>\n<li>Knowledge of Python and SQL (R is nice as well)</li>\n<li>Experience with scikit-learn, pandas, NumPy, plotting libraries, etc.</li>\n<li>Experience using business intelligence tools</li>\n<li>Problem-solving aptitude and analytical thinking</li>\n<li>Excellent communication and presentation skills</li>\n<li>BSc/BA or higher in science, economics or engineering</li>\n</ul>\n<p>\u00a0</p>\n<p><strong>Benefits</strong></p>\n<p>Remote work is now the norm.<br><br>The difference is that we've been fully remote for many years now, and know how to properly work remotely. Additional benefits for our Bulgaria-based team include an employer-paid additional medical insurance, life and risk insurance, and 25-days of paid annual leave. There are additional compensation and time off for participation in the on-call rotation.<br><br>When there's no pandemic, the team gets together for monthly team drinks and an off-site somewhere beautiful twice a year. We hope to resume these activities as soon as the situation permits. We strive for quality and a stress-free work environment.</p>\n<p>We want our colleagues to learn and grow. We\u2019ll be happy to have a like-minded person join us!<br><br>If you are interested please <strong>APPLY</strong> using the button below.<br><br>Confidentiality of all applications is assured. Only shortlisted candidates will be contacted!</p>\n"}, {"id": 972650, "url": "https://remotive.io/remote-jobs/data/data-engineer-972650", "title": "Data Engineer", "company_name": "YieldX", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-09T17:41:45", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>Company Overview:</strong>\u00a0</p>\n<p>At\u00a0YieldX, our mission is to democratize fixed income investing with a comprehensive ecosystem of digital tools that power personalization at scale.\u00a0<br>\u00a0<br>YieldX\u00a0is an end-to-end digital platform with smart workflows, AI-powered analytics and a reimagined user experience for financial professionals and investors in the fixed income markets. Flexible and scalable technology\u00a0eliminates\u00a0time-consuming manual processes and replaces antiquated technology with a modern API-first infrastructure, while intuitive interfaces allow for\u00a0pushbutton\u00a0construction of custom portfolios tailored to an investor's goals and risk tolerance within minutes.\u00a0<br>\u00a0<br>The enterprise-grade platform was designed to offer an unprecedented range of options \u2013 including a choice of end-to-end or a la carte solutions \u2013 to support a wide range of business strategies. RIAs, broker-dealers, banks, and fintech companies and family offices can use\u00a0YieldX's\u00a0SaaS apps and API technology to deliver personalized and\u00a0optimized\u00a0fixed income solutions to their clients.\u00a0</p>\n<p><strong>Life at\u00a0</strong><strong>YieldX:\u00a0</strong></p>\n<p>YieldX\u00a0was built and funded by fintech, asset management, and capital markets\u00a0industry veterans with successful track records in building companies. You will be challenged and rewarded as you contribute to a collective mission towards success.\u00a0YieldX\u00a0offers competitive compensation and\u00a0benefits\u00a0and\u00a0seeks\u00a0to grow our human capital base through building an all-star team of dedicated, kind, intelligent, motivated, and diverse individuals. We are looking for intellectually curious, motivated, collaborative team players that have a demonstrated interest in financial services and investment management technology.\u00a0</p>\n<p><strong>Requirements:</strong>\u00a0</p>\n<ul><li>Minimum of 5 years of experience at a major financial institution or fintech\u00a0building\u00a0enterprise data solutions.\u00a0\u00a0\u00a0</li><li>Experience with financial securities, particularly fixed-income funds and bonds.\u00a0<br> </li><li>Strong familiarity with both SQL and NoSQL databases, such as\u00a0Postgres and\u00a0DynamoDB.\u00a0</li><li>Fluent in Java\u00a0and\u00a0Python.\u00a0</li><li>Expertise in cloud data management and computing technologies, such as AWS\u00a0Kinesis\u00a0and\u00a0Apache Flink.\u00a0</li><li>Well-versed\u00a0in modern data technologies including Docker, Kubernetes, etc.\u00a0</li><li>Extensive\u00a0experience in distributed computing, working with large-scale structured and unstructured datasets, and developing and maintaining data lakes and data warehouses\u00a0</li><li>Has experience in data pipeline and workflow management tools.\u00a0</li><li>Must be self-directed,\u00a0confident\u00a0and able to work in a fast-paced environment\u00a0</li><li>Excellent communication, both written and spoken with both technical and not-so-technical people.\u00a0</li></ul>\n<p><strong>YieldX</strong><strong>\u00a0Benefits:\u00a0\u00a0</strong></p>\n<ul><li>Insurance - Medical, Dental, Vision, HSA option with employer match\u00a0</li><li>Flexible working hours and work from home\u00a0\u00a0</li><li>Work from home\u00a0stipend\u00a0for new employees\u00a0\u00a0</li><li>Brand new MacBook Pro for new employees\u00a0\u00a0</li><li>Unlimited PTO and 6 paid company holidays\u00a0\u00a0</li><li>Gym membership discount options\u00a0\u00a0</li></ul>\n<p>Note to Recruiters and Placement Agencies:\u00a0YieldX\u00a0does not accept unsolicited agency resumes.\u00a0YieldX\u00a0does not pay placement fees for candidates\u00a0submitted\u00a0by any agency other than its approved partners.\u00a0</p>\n<p>You must\u00a0be authorized to\u00a0work in U.S.\u00a0YieldX\u00a0currently does not sponsor H1B work visas.\u00a0</p>\n"}, {"id": 975744, "url": "https://remotive.io/remote-jobs/data/data-scientist-machine-learning-975744", "title": "Data Scientist: Machine Learning", "company_name": "Pngme", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-08T17:39:10", "candidate_required_location": "USA Only", "salary": "", "description": "<div><strong style=\"font-size: 13pt;\">Data Scientist - Machine Learning</strong></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11pt;\">About the role</strong></div>\n<div><span style=\"font-size: 11pt;\">PngMe is looking for a mid-to-senior-level Data Scientist who can independently run deep data investigations, partner with our product and engineering teams, support our customers with analytic and modeling solutions, and evangelize data science across the organization.</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11pt;\">Responsibilities</strong></div>\n<div><span style=\"font-size: 11pt;\">- Run impactful inferential analyses and data investigations to develop deep understanding of data\u00a0</span></div>\n<div><span style=\"font-size: 11pt;\">-Identify recurring patterns, root causes, and propose actionable product solutions</span></div>\n<div><span style=\"font-size: 11pt;\">-Build, validate, fine-tune, and deploy machine learning models as product via a robust MLOps pipeline</span></div>\n<div><span style=\"font-size: 11pt;\">-Partner with the product, design, and engineering teams to define and monitor key business metrics, build visualizations and dashboards, present actionable insights across the organization, and collaborate on platform functionality</span></div>\n<div><span style=\"font-size: 11pt;\">-Work collaboratively with customers to identify problems, build analytics &amp; modeling solutions, present insights, and demonstrate the value of Pngme\u2019s products</span></div>\n<div><span style=\"font-size: 11pt;\">-Provide thought leadership on developing cultural excellence around statistical analysis, experimentation, and modeling</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11pt;\">Requirements</strong></div>\n<div><span style=\"font-size: 11pt;\">-Bachelor\u2019s degree or equivalent experience in Computer Science, Mathematics, Statistics, Economics, Operations Research, Engineering, or a closely related field</span></div>\n<div><span style=\"font-size: 11pt;\">-5+ years of professional experience as a data scientist\u00a0</span></div>\n<div><span style=\"font-size: 11pt;\">-Working knowledge of scientific computing language (Python preferred), SQL, and data visualization tools.</span></div>\n<div>-Strong<span style=\"font-size: 11pt;\"> knowledge of probability and statistics. Deep understanding of experimentation analysis workflows</span></div>\n<div><span style=\"font-size: 11pt;\">-Comfortable with working in cloud environment such as AWS (ec2, emr, Redshift, Sagemaker)</span></div>\n<div><span style=\"font-size: 11pt;\">-Excellent communication skills to convey complex technical concepts and information to both technical and non-technical audiences</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11pt;\">Plus</strong></div>\n<div><span style=\"font-size: 11pt;\">-Industry experience with credit risk analysis and underwriting principles</span></div>\n<div><span style=\"font-size: 11pt;\">-Data engineering experience and data pipeline tooling (Airflow, Spark)</span></div>\n<div><span style=\"font-size: 11pt;\">-Experience working with customers to identify problems and provide solutions</span></div>\n<div><span style=\"font-size: 11pt;\">-Familiarity with NLP concepts and practical application on text data</span></div>\n<div><span style=\"font-size: 11pt;\">-Experience deploying models into production environment (Sagemaker, MLFlow, Kubeflow)</span></div>\n<div><span style=\"font-size: 11pt;\">-Kaggle Master / Grandmaster</span></div>\n<div>\u00a0</div>\n<div><strong>Benefits:</strong></div>\n<div>- Mission driven company focused on giving equal everyone equal access to finance</div>\n<div>- We invest heavily in our team and strive to provide a supportive work culture</div>\n<div>- Flexible work policy from our global offices (when open) or remote</div>\n<div>- Innovative engineering and product culture</div>\n<div>- Inclusion and diversity as a company priority\u00a0</div>\n<div>- Founder-led company</div>\n<div>- Inclusive stock option plans</div>\n<div>- Competitive compensation packages\u00a0</div>\n<div>- Comprehensive benefits (including 100% healthcare, dental, vision and 401k)</div>\n<div>- Additional benefits include home office reimbursements</div>\n<div>\u00a0</div>\n<div>Salary: $140,000 - $200,000 USD</div>\n"}, {"id": 975743, "url": "https://remotive.io/remote-jobs/data/data-scientist-natural-language-processing-975743", "title": "Data Scientist - Natural Language Processing", "company_name": "Pngme", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-08T13:41:14", "candidate_required_location": "USA Only", "salary": "", "description": "<div><strong style=\"font-size: 13pt;\">Data Scientist - NLP</strong></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11pt;\">About the role</strong></div>\n<div><span style=\"font-size: 11pt;\">PngMe is looking for a senior-level NLP-specialized Data Scientist who can independently research, experiment, build, and productize NLP-based solutions to translating unstructured text data.</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11pt;\">Responsibilities</strong></div>\n<div><span style=\"font-size: 11pt;\">-Apply NLP/NLU techniques such as named entity recognition, text classification, and statistical language models to translate unstructured text into machine-readable form</span></div>\n<div><span style=\"font-size: 11pt;\">-Develop solutions in collaboration with data engineering to deploy algorithms through an MLOps pipeline</span></div>\n<div><span style=\"font-size: 11pt;\">-Build a rigorous experimentation framework to evaluate algorithm efficacy and drive a culture of iteration, optimization, and model tuning.</span></div>\n<div>-Work <span style=\"font-size: 11pt;\">with customers to identify, design, and NLP/NLU models for product use cases</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11pt;\">Requirements</strong></div>\n<div><span style=\"font-size: 11pt;\">-Bachelor\u2019s degree or equivalent experience in Computer Science, Mathematics, Statistics, Economics, Operations Research, Engineering, or a closely related field</span></div>\n<div><span style=\"font-size: 11pt;\">-5+ years of professional experience as a data scientist\u00a0</span></div>\n<div><span style=\"font-size: 11pt;\">-Working knowledge of scientific computing language (Python preferred), SQL, and data visualization tools</span></div>\n<div><span style=\"font-size: 11pt;\">-Strong knowledge of probability and statistics. Deep understanding of experimentation analysis workflows</span></div>\n<div><span style=\"font-size: 11pt;\">-Comfortable with working in cloud environment such as AWS (ec2, emr, Redshift, Sagemaker)</span></div>\n<div><span style=\"font-size: 11pt;\">-Excellent communication skills to convey complex technical concepts and information to both technical and non-technical audiences</span></div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 11pt;\">Plus</strong></div>\n<div><span style=\"font-size: 11pt;\">-Industry experience with credit risk analysis and underwriting principles</span></div>\n<div><span style=\"font-size: 11pt;\">-Data engineering experience and data pipeline tooling (Airflow, Spark)</span></div>\n<div><span style=\"font-size: 11pt;\">-Experience working with customers to identify problems and provide solutions</span></div>\n<div><span style=\"font-size: 11pt;\">-Familiarity with NLP concepts and practical application on text data</span></div>\n<div><span style=\"font-size: 11pt;\">-Experience deploying models into production environment (Sagemaker, MLFlow, Kubeflow)</span></div>\n<div><span style=\"font-size: 11pt;\">-Kaggle Master / Grandmaster</span></div>\n<div>\u00a0</div>\n<div><strong>Benefits:</strong></div>\n<div>- Mission driven company focused on giving equal everyone equal access to finance</div>\n<div>- We invest heavily in our team and strive to provide a supportive work culture</div>\n<div>- Flexible work policy from our global offices (when open) or remote</div>\n<div>- Innovative engineering and product culture</div>\n<div>- Inclusion and diversity as a company priority\u00a0</div>\n<div>- Founder-led company</div>\n<div>- Inclusive stock option plans</div>\n<div>- Competitive compensation packages\u00a0</div>\n<div>- Comprehensive benefits (including 100% healthcare, dental, vision and 401k)</div>\n<div>- Additional benefits include home office reimbursements</div>\n<div>\u00a0</div>\n<div>Salary: $140,000 - $200,000 USD</div>\n"}, {"id": 967070, "url": "https://remotive.io/remote-jobs/data/data-engineer-967070", "title": "Data Engineer", "company_name": "LYTT", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-06T01:39:29", "candidate_required_location": "UK Only", "salary": "", "description": "<p><strong>Title: </strong>Data Engineer</p>\n<p><strong>Location: </strong>Remote First &amp; London</p>\n<p><strong>Reports To:</strong> Chief Product &amp; Technology Officer</p>\n<p><br><strong>About LYTT</strong><br>We are a fast-growing technology start up and our aim is to shape the future of Energy through advanced<br>analytics. We are building an award-winning platform and Software as a Service (SaaS) solution to tackle<br>complex energy challenges in extreme environments by designing and deploying ground-breaking technology<br>that interprets data captured from fibre optic cables deep in the subsurface into actionable information.<br><br></p>\n<p><strong>About the role</strong><br>Use your background in distributed data processing, stream processing, software engineering design, and data modelling concepts to develop reliable and scalable production systems.<br>Support our data scientists to deploy code multiple times a day and take care of running your services in production on AWS and Azure.<br>Contribute across the entire software delivery life cycle \u2013 concept, design, build, deploy, test, release and post implementation support.<br>Applying good engineering practises - implement processes, systems and tools to aid and you and your team in day to day development work.<br>We\u2019ll need you to help build alerting systems and service status dashboards for data pipelines running models in production.<br>Support Agile development methods and best practices.<br>Quickly acquire new data engineering skills and work with new technologies with little support.<br>Work with the wider development teams to ensure the spread of best practices and knowledge.</p>\n<p><strong>Requirements</strong></p>\n<p>Minimum 2 years\u2019 experience with Python building data pipelines (streaming or batch)<br>Understanding of Object Oriented Programming concepts<br>Experience in an agile development team<br>Working experience with CI/CD &amp; test-automation in Python<br>Experience with AWS &amp; Azure cloud environments<br><br></p>\n<p>We know that sometimes people can be put off applying for a job if they think they can\u2019t tick every box, but we<br>realise that the \u2018perfect candidate\u2019 doesn\u2019t exist. If you\u2019re excited about working with us and can do most of<br>what we are looking for, go ahead and apply. You could be exactly what we need!</p>\n<p><strong>Benefits</strong></p>\n<p><img alt=\":alarm_clock:\" src=\"https://a.slack-edge.com/production-standard-emoji-assets/13.0/apple-medium/23f0.png\"> Flexible working<br><img alt=\":house_with_garden:\" src=\"https://a.slack-edge.com/production-standard-emoji-assets/13.0/apple-medium/1f3e1.png\"> Happy for you to be fully remote <strong>within the UK</strong><br><img alt=\":aeroplane:\" src=\"https://a.slack-edge.com/production-standard-emoji-assets/13.0/apple-medium/2708-fe0f.png\"> 25 days annual leave<br><img alt=\":yellow_heart:\" src=\"https://a.slack-edge.com/production-standard-emoji-assets/13.0/apple-medium/1f49b.png\"> A (genuine) commitment to wellness<br><img alt=\":baby_symbol:\" src=\"https://a.slack-edge.com/production-standard-emoji-assets/13.0/apple-medium/1f6bc.png\"> Enhanced parental leave<br><img alt=\":chart_with_upwards_trend:\" src=\"https://a.slack-edge.com/production-standard-emoji-assets/13.0/apple-medium/1f4c8.png\"> 20% Bonus &amp; Equity <br><img alt=\":hospital:\" src=\"https://a.slack-edge.com/production-standard-emoji-assets/13.0/apple-medium/1f3e5.png\"> Private Medical Insurance<br><img alt=\":blue_heart:\" src=\"https://a.slack-edge.com/production-standard-emoji-assets/13.0/apple-medium/1f499.png\"> A brilliant team, who care</p>\n"}, {"id": 966155, "url": "https://remotive.io/remote-jobs/data/data-advertising-strategist-966155", "title": "Data & Advertising Strategist", "company_name": "Stand Up America", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-05T05:40:49", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>Location: Remote</strong></p>\n<p>Stand Up America is a progressive, digital-first advocacy organization with 2 million grassroots members who are working to stand up to corruption and build a more representative democracy. We're fighting for democracy reforms at the local, state, and federal level that would expand voting rights, reduce the impact of big money in our politics, and end structural barriers that conservatives have built to impede progressive change. Our members have driven more than a million constituent calls to their representatives, mobilized tens of thousands of protestors, contacted tens of millions of voters, and helped pass bold democracy reforms at the state and federal levels.</p>\n<p>We envision a democracy where:\u00a0</p>\n<ul><li>Every American has representation, regardless of where they live, what they look like, or how they identify.\u00a0</li><li>Racist barriers to the ballot are torn down and voting rights are expanded to ensure that voting is accessible, secure, and treated as the sacred right that it is.\u00a0</li><li>Americans from all walks of life can run for office and win based on the power of their ideas, voice, and experience \u2014 not on how much money they can raise from themselves or wealthy donors.\u00a0</li><li>Our government is responsive to the will of the American people \u2014 and will finally take bold action on the pressing issues facing our nation, from gun violence and climate change to immigration reform and racial &amp; economic justice.</li></ul>\n<p>The work we do matters. That's why Stand Up America is focused on using data to help us do our work as effectively and efficiently as possible. Our data team was integral in helping us contact over 25 million voters in 2020 and drive 1.6 million calls to lawmakers, and provides insights to help fuel our robust advocacy efforts towards building a more just and equitable democracy. We are seeking a data &amp; advertising strategist to help support our team's exciting work.</p>\n<p><strong>You will:</strong></p>\n<ul><li>Manage and optimize pixeling and conversions for our digital paid acquisition program that both drives action and effectively builds a community of activists dedicated to defending our democracy.</li><li>Help build reports and dashboards on our digital program that monitor progress toward advocacy, electoral, and digital goals, data which helps us reflect on our program's performance and make decisions about how we continue to grow and engage our community of highly motivated activists.</li><li>Help project manage data and technology projects and pull ad hoc data as needed to support our overall program.</li><li>As needed, provide support with setting up and monitoring digital ads.</li></ul>\n<p><strong>Must-haves:</strong></p>\n<ul><li>2+ years of experience with programming languages like SQL or Python, tools like Google Analytics or Facebook Ads Manager, or software programs like Microsoft Excel or Google Sheets, preferably analyzing direct response marketing programs.</li><li>Adaptability and willingness to learn new things, especially as the progressive data technology ecosystem continues to evolve over time.</li><li>Strong attention to detail, as the reports and dashboards created will help guide strategic decisions for our program</li></ul>\n<p><strong>Nice-to-haves:</strong></p>\n<ul><li>Experience working with progressive infrastructure, including tools like Civis, ActionKit, EveryAction, ThruTalk, Spoke or Hustle (just to name a few).</li><li>Ability to manage tasks and deadlines effectively.</li><li>Passion about voting rights, reducing the influence of big money in our elections, and strengthening our democracy.</li></ul>\n<p>Stand Up America celebrates diversity in race, ethnicity, gender, age, sexual orientation, class, ability, life experiences, and background. We're an Equal Opportunity Employer \u2014 women, Black, Indigenous, and people of color, people with disabilities, and LGBTQ candidates are strongly encouraged to apply. Stand Up America's commitment to diversity, equity, and inclusion is key to our mission of building a more representative democracy and reforming a political system that has given white, wealthy Americans a louder voice and more power than Black, Indigenous, and people of color for far too long.\u00a0</p>\n<p><a href=\"https://www.standupamerica.com/sua-dei-commitment/\" rel=\"nofollow\"><strong>For more information about our commitment to diversity, equity, and inclusion internally and in our advocacy efforts, click here.</strong></a></p>\n<p><strong>Salary &amp; Benefits</strong></p>\n<p>Our benefits include:</p>\n<ul><li>Medical, dental, vision, and life insurance, including 100% subsidy of monthly premiums</li><li>SIMPLE IRA with matching of employee contributions up to 3% of salary</li><li>3 weeks flexible paid time off per calendar year, plus an additional week in December, for a total of 4 weeks per year</li><li>Additional paid holidays\u00a0</li><li>Unlimited sick days\u00a0</li><li>12 weeks of paid parental leave\u00a0</li><li>Annual professional development stipend\u00a0</li><li>Computer and accessories for at-home and in-office work\u00a0</li><li>A fun work environment with colleagues who are respectful of one another and passionate about their work.</li></ul>\n<p>Salary range: $65,000 - $75,000 annually, commensurate with experience.<br></p>\n"}, {"id": 965896, "url": "https://remotive.io/remote-jobs/data/data-solution-architect-965896", "title": "Data Solution Architect", "company_name": "Wavicle Data Solutions", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-04T21:40:17", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>Wavicle Data Solutions </strong>designs and delivers data and analytics solutions to reduce time, cost, and risk of companies\u2019 data projects, improving the quality of their analytics and decisions now and into the future<strong>.  </strong>As a privately-held consulting service organization with popular, name brand clients across multiple industries, Wavicle offers exciting opportunities for data scientists, solutions architects, developers, and consultants to jump right in and contribute to meaningful, innovative solutions.<br></p> <p>Our 250+ local, nearshore and offshore consultants, data architects, cloud engineers, and developers build cost-effective, right-fit solutions leveraging our team\u2019s deep business acumen and knowledge of cutting-edge data and analytics technology and frameworks.</p> <p><br></p><p>At Wavicle, you\u2019ll find a challenging and rewarding work environment where we enjoy working as a team to exceed client expectations. Employees appreciate being part of something meaningful at Wavicle.  Wavicle has been recognized by industry leaders as follows:</p> <ul> <li>Chicago Tribune\u2019s Top Workplaces</li> <li>Inc 500 Fastest Growing Private Companies in the US</li> <li>Crain\u2019s Fast 50 fastest growing companies in the Chicago area</li> <li>Talend Expert Partner recognition</li> <li>Microsoft Gold Data Platform competency</li> </ul> <p><a class=\"external\" rel=\"nofollow\"></a><strong>About the Role: </strong></p> <p>We are looking for a <strong>Solution Architect </strong>who will perform mission critical duties in our data engineering strategy, contributing to and leading the development of our Enterprise Data and Analytics Platforms. A passionate professional who can blend the ever-evolving technology landscape of Cloud and Advanced Analytics with the complex and high-impact space of E-Commerce and Direct Sales. </p> <p>The<strong> Solution Architect </strong>will be responsible for leading a team of talented engineers to develop and maintain the foundation of next generation data platforms. This role will be responsible for expanding, optimizing, and monitoring our expanding data pipelines through meticulous architecting, intelligent business logic, consistent data governance, testing and continuous delivery.</p> <p><strong>Responsibilities:</strong></p> <ul> <li>Lead and provide advanced data engineering expertise for projects that enable analytics to drive optimization of decisions for client(s), within a team of engineers.</li> <li>Design new methods and processes to ensure maximum effectiveness of client data.</li> <li>Partner with data analysts/scientists to provide solutions enabling statistical analysis tools and data visualization applications.</li> <li>Identify processes and tools that can be shifted towards automation to enable seamless development and self-service analytics workloads.</li> <li>Partner with various business units and data stewards to understand the business needs.</li> <li>Obtain and/or maintain technical expertise of available data manipulation and preparation tools (Talend, Informatica, Matillion etc) as well as programming languages ( Python, Spark, EMR, etc.)</li> </ul> <ul> <li>Ensure data is secure, relevant, and maintains high quality standards.</li> <li>Identify and implement industry best practices.</li> <li>Evaluate new data sets to determine appropriate ingestion techniques.</li> <li>Build, manage and optimize data pipelines through a variety of ETL tools, including custom infrastructure and 3rd-party tooling (AWS, GCP, Databricks, Snowflake).</li> <li>Work with internal engineering teams and vendors to understand business logic to ensure veracity in datasets.</li> <li>Generate documentation on existing production data logic and its influencing business processes in order to reconcile knowledge gaps between the business, engineering, and data collection.</li> </ul><p><strong>Requirements</strong></p><ul> <li>8-10 years of experience in delivering data engineering solutions that include batch and streaming capabilities.</li> <li>5+ years of strategic/management consulting experience is highly preferred.</li> <li>Experience building, testing, automating and optimizing data pipelines.</li> <li>Experience using AWS, Databricks, Snowflake or similar products.</li> <li>Strong understanding and prior use of SQL and be highly proficient in the workings of data technologies (Hadoop, Hive, Spark, Kafka, low latency data stores, Airflow, etc.).</li> <li>Deep understanding of data testing techniques, and a proven record of driving sustainable change to the software development practice to improve quality and performance.</li> <li>Proficiency with data querying languages (e.g. SQL), programming languages (e.g. Python, Spark, Java, etc.).</li> <li>Expertise selecting context-appropriate data modeling techniques, including Kimball dimensional modeling, slowly changing dimensions, snowflake, and others.</li> <li>Passion for software development and data and be highly skilled in performing data extraction, transformation and processing to optimize quantitative analyses on various business functions.</li> <li>Familiarity with Scrum, DevOps, and DataOps methodologies, and supporting tools such as JIRA.</li> <li>Experience with AWS technologies such as Redshift, RDS, S3, Glacier, EC2, Lambda, API Gateway, Elastic Map Reduce, Kinesis, and Glue.</li> <li>Experience with managing AWS infrastructure as code, including the use of Cloud Formation, Git, and GitLab.</li> <li>Excellent oral and written communication skills.</li> <li>Strong presentation skills and the ability to communicate analytical and technical concepts with confidence and in an easy-to-understand fashion to technical and non-technical audiences.</li> <li>Bachelor or Master Degree in Computer Science or relevant field is required.</li> <li><strong>Remote work now; however, Post COVID, travel can be up to 50% to the client location (as required by the client).</strong></li> </ul><p><br></p> <p><strong><i>Equal Opportunity Employer </i></strong><strong><i>(to be included with job board posts, not Wavicle website)</i></strong></p> <p>Wavicle is an Equal Opportunity Employer and committed to creating an inclusive environment for all employees. We welcome and encourage diversity in the workplace regardless of race, color, religion, national origin, gender, pregnancy, sexual orientation, gender identity, age, physical or mental disability, genetic information or veteran status.</p><p><strong>Benefits</strong></p><ul> <li>Health Care Plan (Medical, Dental &amp; Vision)</li> <li>Retirement Plan (401k, IRA)</li> <li>Life Insurance (Basic, Voluntary &amp; AD&amp;D)</li> <li>Unlimited Paid Time Off (Vacation, Sick &amp; Public Holidays)</li> <li>Short Term &amp; Long Term Disability</li> <li>Training &amp; Development</li> <li>Work From Home</li> <li>College Tuition Benefit</li> <li>Bonus Program</li> </ul><p><br></p>"}, {"id": 925587, "url": "https://remotive.io/remote-jobs/data/data-scientist-925587", "title": "Data Scientist", "company_name": "Hello Alice", "category": "Data", "tags": [], "job_type": "", "publication_date": "2021-11-04T01:40:45", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>Work with a Purpose:</strong></p><p>At Hello Alice we are about equal access fueled by technology and powered by everyone who believes that diverse small business participation isn\u2019t just the right thing to do, but the smart thing to do. That\u2019s true of our small business owners, and it\u2019s true of our team. If you agree, keep reading.  </p> <p><strong>Job Summary: </strong></p><p>As part of the Data Science team at  Hello Alice, you will play an important role in driving our  Data Science mission forward.  We build tools and products using Data Science and Artificial Intelligence (AI) that empower small business owners.  By using data, machine learning, and AI we augment human intelligence and cognition for optimal decision-making.  We strive to evangelize on the importance of being a data-driven organization and use data to tell stories and uncover insights. </p> <p>You\u2019ll report directly to the Director of Data Science. </p><p><strong>Role and Responsibilities: </strong></p><p><em>Here\u2019s what you\u2019ll be working on day-to-day, but as a nimble organization that puts our small business community at the forefront, flexibility is key, and other responsibilities may arise. </em></p><ul> <li>Apply various data science methods to understanding the most important aspects of our product, users, and business</li> <li>Transform data into insights that can be utilized by people without a programming or data science background.</li> <li>Evangelizing evidence-based decision making by partnering with key decision makers (including senior-level and executive management) and driving democratized accessibility of data and insights</li> <li>Design and build data set processes for modeling, data mining, and production purposes</li> <li>Determine new ways to improve data quality and predictive capabilities</li> <li>Perform and interpret data studies and product experiments concerning new data sources or new uses for existing data sources</li> <li>Develop prototypes, proof of concepts, algorithms, predictive models, and custom analysis</li> <li>Provide research on topics including Hello Alice's business model and recommendation techniques </li> <li>Deliver reports and insights on data findings that are understandable to non-data scientists</li> </ul><p><br><br></p><p><strong>Required Skills and Experiences:</strong></p><ul> <li>Degree in a related field such as Mathematics, Statistics, Analytics or Computer Science</li> <li>1-2 years of experience which can include relevant internship experience</li> <li>Basic knowledge of statistics to include linear and logistic regression, supervised machine learning and time series forecasting</li> <li>Knowledge of building  statistical, machine learning, NLP, and AI models</li> <li>Prior experience with different models and projects with the ability to explain in detail</li> <li>Experience with tools and programming language to include Excel, PowerBI, Tableau, Mode Analytics or Shiny</li> <li>Cloud databases including Google Cloud platform, AWS, Microsoft Azure</li> <li>R or Python and SQL experience is required</li> <li>Ability to identify a business problem, define and create a solution and convert the solution into an insight feature</li> </ul><p><br></p><p><strong>Benefits &amp; Perks</strong></p><br><ul> <li>Generous PTO days </li> <li>Competitive compensation, benefit, and equity package</li> <li>Work from home stipend </li> <li>Professional development</li> <li>Diverse, fun, and unique work environment</li> </ul> <p><br></p><p><strong>About Hello Alice:</strong></p> <p>Hello Alice is a free, multichannel platform that helps businesses launch and grow. With a community of nearly 500,000 business owners in all 50 states and across the globe, Hello Alice is building the largest network of owners in the country while tracking data and trends to increase the success rate for entrepreneurs. Our partners include enterprise business services, government agencies, and institutions looking to serve small- and medium-business owners to ensure increased revenues and promote scale. A Latina owned company, founded by Carolyn Rodz and Elizabeth Gore, we believe in business for all by providing access to all owners including women, people of color, veterans, and everyone with an entrepreneurial spirit. To learn more, visit helloalice.com, as well as Twitter, LinkedIn, Instagram, and Facebook.</p> <p>Hello Alice is a fully remote team, so all United States locations are considered. </p> <p><em>Hello Alice is an Equal Employment Opportunity employer that will consider all qualified applicants, regardless of race, color, religion, gender, sexual orientation, marital status, gender identity or expression, national origin, genetics, age, disability status, protected veteran status, or any other characteristic protected by applicable law.</em></p> <p><a class=\"external\" href=\"http://www.helloalice.com/\" rel=\"nofollow\">www.helloalice.com</a> //<a class=\"external\" href=\"https://twitter.com/HelloAlice\" rel=\"nofollow\"> Twitter</a> //<a class=\"external\" href=\"http://www.facebook.com/aliceconnects\" rel=\"nofollow\"> Facebook</a> //<a class=\"external\" href=\"https://www.instagram.com/helloalice_com/\" rel=\"nofollow\"> Instagram</a> //<a class=\"external\" href=\"https://www.linkedin.com/company/25067438/\" rel=\"nofollow\"> LinkedIn</a></p>"}, {"id": 963976, "url": "https://remotive.io/remote-jobs/data/senior-data-analyst-963976", "title": "Senior Data Analyst", "company_name": "Banyan", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-03T09:47:03", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>About Banyan</strong></p>\n<p>BANYAN is a global interchange for SKU-level receipt data, with a mission to make it easy for consumers to connect their receipts to the apps and services they choose, unlocking value for merchants and enabling financial institutions and fintech apps to create incredible, personalized experiences for their customers.</p>\n<p>We're a growing team of more than 25 employees distributed across the US, with offices in Holmdel, NJ and Chicago, IL. Our investors include FinVC, TTV Capital, Motivate Ventures, and Manifold Group, and we have ambitions to become a major player in the future of fintech.</p>\n<p><strong>Overview of Role</strong></p>\n<p>Banyan is looking to make its second hire on the Product Analytics team, who can take on a \u201cfull-stack\u201d role across business intelligence, data onboarding, and analytics engineering. As a Senior Data Analyst, you'll report to the Director of Product Ops &amp; Analytics, and build out internal product analytics &amp; reporting dashboards, lead data evaluations and transformations of client data (merchant receipts and financial transactions), and perform ad-hoc product analyses for key fundraising, sales enablement, and product initiatives. Currently, our stack is based on GCP (BigQuery), and consists of Looker, dbt, and soon-to-be other modern data orchestration and ingestion tools.</p>\n<p>You'll work closely with a variety of stakeholders across the organization, and serve as an authority on the key product metrics that will drive our business. The right candidate will be analytical, passionate, comfortable with ambiguity and changing priorities, and has a good mix of technical skills and business intuition. This role is a great opportunity for an experienced generalist interested in building things from the ground up as initial duties will span multiple areas of analytics and shift to greater specializations or focus areas over time.</p>\n<p></p><p>We're looking for someone who is passionate about the developing practices of data analysis, business intelligence, and analytics engineering who can quickly absorb the business context of our company. We recognize that many great applicants will come with differing levels of experience and backgrounds (or may not have worked with the specific tools in our stack), so if you are interested and passionate about our company vision and mission, please apply!</p>\n<p></p>\n<p><strong>Responsibilities</strong></p>\n<ul><li>Define and track foundational metrics and build internal BI dashboard(s) and reporting using Looker</li><li>Write SQL queries and dbt code for analytics transformations, version control, and testing</li><li>Develop standardized report(s) in Looker for external use cases built off of core data platform</li><li>Collaborate with clients to understand their data structure and produce initial data quality diagnostics</li><li>Write and deploy client-specific transformation logic (data models) to integrate merchant and transaction data into Banyan core data platform</li><li>Perform ad-hoc product analyses and proofs-of-concept for key fundraising, sales enablement, and product strategy use cases</li><li>Partner with data engineering and other stakeholders to improve our core data platform (e.g. data quality testing)</li><li>Document our data, ensure data accuracy, and create &amp; improve datasets to meet Banyan needs</li><li>Research new tools and methodologies to enhance our stack and development process</li></ul>\n<p><strong>Qualifications</strong></p>\n<ul><li>3+ years of relevant working experience in data analytics and/or business intelligence, preferably in a tech company or startup</li><li>Strong proficiency in SQL</li><li>Experience with business intelligence dashboarding &amp; reporting tools, e.g. Tableau, PowerBI, Looker (preferred)</li><li>Experience with data evaluation, transformation, and modeling</li><li>Experience working with modern data warehouses, e.g. Snowflake, AWS Redshift, Google BigQuery (preferred)</li><li>Experience in analytics engineering, e.g. LookML, dbt (preferred)</li><li>Knowledge of version control and GitHub actions</li><li>Good communication skills (written and verbal)</li><li>Attention to detail and desire for end-to-end ownership of deliverables</li><li>Self-motivated, proactive, and fairly autonomous; comfortable working in a fast-paced environment</li><li>Collaborative with a positive attitude, interest in learning, and strong sense of empathy</li></ul>\n<p><strong>Desired Experience</strong></p>\n<ul><li>Experience with Python</li><li>Exposure to data orchestration tools like Airflow, Prefect, or Dagster</li><li>Experience with data warehouse and schema design frameworks &amp; techniques</li><li>Familiarity with retail &amp; CPG data or financial transaction data</li></ul>\n<p><strong>Benefits</strong></p>\n<ul><li>Competitive salary and equity</li><li>Medical, dental, and vision insurance plans</li><li>Flexible vacation policy</li><li>Paid parental leave</li><li>Work-from-home remotely, w/ occasional travel for bi-annual company retreats<ul><li>Option to work semi-regularly in office if located near Chicago, IL or Holmdel, NJ offices</li></ul></li><li>Learning and development initiatives &amp; assistance</li></ul>\n<p></p>\n<p>Banyan is an equal opportunity employer and committed to providing employees with a work environment free of discrimination and harassment. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status.</p>\n"}, {"id": 964862, "url": "https://remotive.io/remote-jobs/data/ai-ml-data-scientist-964862", "title": "AI/ML Data Scientist", "company_name": "Experfy Inc", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-02T17:41:17", "candidate_required_location": "USA Only", "salary": "", "description": "<strong>This is a 100% Remote role with USA based client.</strong><p>At Experfy, we rely on powerfully insightful data to power our systems and solutions. We\u2019re seeking an experienced data scientist to deliver that insight to us on a daily basis. Our ideal team member will have the mathematical and statistical expertise you\u2019d expect, but a natural curiosity and creative mind that\u2019s not so easy to find. As you mine, interpret and clean our data, we will rely on you to ask questions, connect the dots, and uncover opportunities that lie hidden within\u2014all with the ultimate goal of realizing the data\u2019s full potential. You will join a team of data specialists, but will \u201cslice and dice\u201d data using your own methods, creating new visions for the future.</p><br>Objectives of this Role<ul> <li>Collaborate with product design and engineering to develop an understanding of needs</li> <li>Research and devise innovative statistical models for data analysis</li> <li>Communicate findings to all stakeholders</li> <li>Enable smarter business processes\u2014and implement analytics for meaningful insights</li> <li>Keep current with technology and industry developments</li> </ul><br>Daily and Monthly Responsibilities<ul> <li>Work as the lead data strategist, identifying and integrating new datasets that can be leveraged through our product capabilities and work closely with the engineering team to strategize and execute the development of data products</li> <li>Execute analytical experiments methodically to help solve various problems and make a true impact across various domains and industries</li> <li>Identify relevant data sources and sets to mine for client business needs, and collect large structured and unstructured datasets and variables</li> <li>Devise and utilize algorithms and models to mine big data stores, perform data and error analysis to improve models, and clean and validate data for uniformity and accuracy</li> <li>Developing AI/ML algorithms to analyze huge volumes of historical data to make predictions and recommendations</li> <li>Developing microservices with integrations to large datasets and other sub systems such as Elastic Search</li> <li>Analyze data for trends and patterns, and Interpret data with a clear objective in mind</li> <li>Implement analytical models into production by collaborating with software developers and machine learning engineers</li> <li>Documenting artificial intelligence and machine learning processes</li> <li>Communicate analytic solutions to stakeholders and implement improvements as needed to operational systems</li> </ul><p><strong>Requirements</strong></p><p>Skills and Qualifications</p><ul> <li>Bachelor\u2019s degree in statistics, applied mathematics, or related discipline or computer science</li> <li>7+ years experience in data science</li> <li>Proficiency with data mining, mathematics, and statistical analysis</li> <li>Advanced pattern recognition and predictive modeling experience</li> <li>Extensive knowledge of AI/ML frameworks, libraries, data structures, data modeling, and software architecture</li> <li>Five plus years of developing models and algorithms independently, writing your own code, developing a strategy for algorithmic experimentation, and deploying in production</li> <li>Proficiency with Python and Go programming languages</li> <li>Experience with Microservices architecture</li> <li>Experience with SQL and NoSQL databases such as MongoDB, Postgres, Neo4j, etc.</li> <li>Experience with AWS, Azure, or other distributed compute services</li> <li>Comfort working in a dynamic, research-oriented group with several ongoing concurrent projects</li> </ul>"}, {"id": 964940, "url": "https://remotive.io/remote-jobs/data/data-engineer-kafka-964940", "title": "Data Engineer (Kafka)", "company_name": "Frontiers", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-11-02T09:43:50", "candidate_required_location": "Spain only", "salary": "", "description": "<p>We are looking for a Data Engineer who will work with technical teams to improve the quality, scalability and resilience of our industry leading data products across the company.</p>\n<p>You\u2019ll form part of our \u201c<em>Services and Integration</em>\u201d unit which is responsible for the development of standalone applications that can be plugged into our publishing platform. In addition you will have a strong focus on Kafka and will spearhead the adoption of Kafka across multiple teams.</p>\n<p>\u00a0</p>\n<p><strong>Key Responsibilities</strong></p>\n<ul>\n<li>Help expose different products for integrations</li>\n<li>Analyze and implement ETL solutions with Kafka for business use-cases</li>\n<li>Support development teams in the modelling, design, construction, evolution, and decommission of their data-intensive applications and data models</li>\n<li>Understand and promote the best frameworks and solutions, technical standards, and key technologies, to effectively support existing and future business requirements</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<ul>\n<li>Strong experience with Kafka, Kafka Connect, KSQL</li>\n<li>Strong experience with relational databases (MS SQL Server, PostgreSQL)</li>\n<li>Experience of non-relational database engines (MongoDB, Elastic Search)</li>\n<li>Expertise in data processing: data ingest and transformation, batch processing, streaming data processing, distributed processing, monitoring, optimization, logging</li>\n<li>Experienced in troubleshooting data processing and data storage</li>\n<li>Experience with streaming and batch ETLs</li>\n<li>Familiarity with Azure or similar (AWS, GCP)</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<ul>\n<li>25 annual leave days + 4 well-being days</li>\n<li>Participation in the annual company bonus scheme</li>\n<li>Flexible working framework and remote working opportunities across Spain</li>\n<li>Extensive learning opportunities through our Pluralsight and LinkedIn Learning partnership</li>\n<li>3 volunteer days through our online platform</li>\n<li>Access to Headspace app</li>\n<li>Online Yoga classes</li>\n</ul>\n<p><strong>Who we are </strong></p>\n<p>Frontiers is an award-winning open science platform and leading open-access scholarly publisher. We are one of the largest and most cited publishers globally. To date, our 200,000 freely available research articles have received more than one billion views and downloads and two million citations.</p>\n<p>Our journals span science, health, humanities, and social sciences, engineering, and sustainability. And we continue to expand into new academic disciplines so more researchers can publish open access.</p>\n"}, {"id": 963650, "url": "https://remotive.io/remote-jobs/data/adobe-data-analyst-963650", "title": "Adobe Data Analyst", "company_name": "pureIntegration", "category": "Data", "tags": [], "job_type": "contract", "publication_date": "2021-11-01T17:41:13", "candidate_required_location": "USA Only", "salary": "", "description": "<p><br><br></p>\n<div class=\"h3\">Company Description</div>\n<p><u><strong>\u200b\u200b\u200b\u200b\u200b\u200b</strong></u></p>\n<p><br><br></p>\n<div class=\"h3\">Job Description</div>\n<p>PureIntegration is seeking an<strong> Adobe Analyst </strong>to join our team! This exciting role will work with cross-functional teams to develop analytics requirements, measurement plans, impact analyses, and dashboards to support each new feature. Build reporting that will enable the broader team to understand the customer journey and path to conversion.</p>\n<p><strong><u>Location:</u></strong>\u00a0Remote Role - Physical Location, Philadelphia, PA</p>\n<p><strong>Work Arrangement:</strong>\u00a0 Contract</p>\n<p><strong>Work Authorization:</strong>\u00a0GC, USCIT - We Do Not Sponsor H1B Visas, or C2C</p>\n<p><strong><u>Responsibilities:</u></strong></p>\n<ul>\n<li>Build reporting that will enable the broader team to understand the customer journey and path to conversion.</li>\n<li>Optimize the implementation and maintenance of online and offline digital analytics and sales technologies.</li>\n<li>Ensure proper tagging and reporting of digital data to drive high-quality, accurate business decisions.</li>\n<li>Utilize various data visualization tools and analysis techniques to effectively measure digital effectiveness, including:\n<ul>\n<li>Goal Setting and Performance to Budget</li>\n<li>Understanding site behavior and engagement</li>\n<li>Provide Analytics Implementation Support</li>\n<li>Identify Website Errors</li>\n<li>Data Alignment and offline reconciliation</li>\n<li>Dashboarding/Data Visualization</li>\n<li>Ad hoc reporting</li>\n</ul>\n</li>\n<li>Using digital data, provide actionable insights and recommendations that demonstrate bottom-line value to senior leadership and other internal stakeholders.\u00a0</li>\n<li>Develop business cases to support acting on these insights and recommendations.\u00a0 Lead key analytics initiatives with minimal oversight by leadership team.\u00a0 Develop reputation as trusted analytics expert within the broader team.</li>\n<li>Support standard reports at weekly, monthly, quarterly, or other cadences.\u00a0 Build superior dashboards, models, and forecasts to support business planning or other initiatives.\u00a0 Partner with the cross-functional team to optimize and improve existing processes.\u00a0 Monitor and maintain data quality and integrity.</li>\n<li>Consistent exercise of independent judgment and discretion in matters of significance.</li>\n<li>Regular, consistent, and punctual attendance. Must be able to work nights and weekends, variable schedule(s) and overtime as necessary.</li>\n<li>Other duties and responsibilities as assigned.</li>\n</ul>\n<p><strong><u>Requirements:</u></strong></p>\n<ul>\n<li>Bachelor\u2019s degree or equivalent</li>\n<li>3+ years of experience in Adobe Digital Web Analytics</li>\n<li>Expertise with Adobe Stack or Google Analytics</li>\n<li>Experience with data visualization\u00a0tools (i.e. Tableau, Domo, etc.)</li>\n<li>Some experience with SQL\u00a0preferred</li>\n<li>Goal setting &amp; Project Management skills, ability to prioritize tasks</li>\n<li>Must be a self-starter, who needs little direction</li>\n</ul>\n<p>\u00a0</p>\n<p><br><br></p>\n<div class=\"h3\">Qualifications</div>\n<p><br><br></p>\n<div class=\"h3\">Additional Information</div>\n<p>All your information will be kept confidential according to EEO guidelines.</p>\n<div>\u00a0</div>\n<p>Are you self-motivated, collaborative, and client-focused? Are you looking for a challenging and rewarding career? Then\u00a0<strong>pureIntegration\u00a0</strong>would love to hear from you! Your career journey starts here!\u00a0</p>\n<p><strong>pureIntegration,</strong> a systems integration company headquartered in the DC area, serves clients in the fastest growing industries \u2013 communications, media, and entertainment. Our industry-focused offerings and collaborative client approach\u00a0has\u00a0resulted in a 97% client satisfaction rating. As a leading service organization, we recognize our most valuable assets are our people, both as individuals and how they come together as a whole. As such, we encourage our team members to become fearless in exploring ideas and opportunities to act on them.</p>\n<p>In over 16\u00a0years of Digital Transformation consulting and professional services, pureIntegration has successfully designed, integrated, and deployed winning solutions at scale which have resulted in measurable performance increases. Most importantly, we have done it while maintaining 97% client satisfaction for the past 15 years.\u00a0 With a rich heritage in Communications, Media and Entertainment, our diverse and expanding portfolio includes Fortune 500 enterprises spanning Utilities, Manufacturing, Insurance, CPG, Healthcare, Logistics and other select verticals.</p>\n<p><strong><em>pureIntegration is an Equal Opportunity Employer (EOE), qualified applicants are considered for employment without regard to age, race, color, religion, sex, national origin, sexual orientation, disability, or veteran status.</em></strong></p>\n"}, {"id": 964979, "url": "https://remotive.io/remote-jobs/data/lead-database-developer-964979", "title": "Lead Database Developer", "company_name": "Careshield", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-30T01:48:36", "candidate_required_location": "UK Only", "salary": "", "description": "<p><strong>Do you have a Passion for Innovation?</strong><br><br><strong>About Us<br></strong>CareShield are a market leader in the development and delivery of innovative and cutting-edge training solutions within the Care Sector<strong>. </strong>We are a <strong><u>rapidly expanding</u></strong> company that can offer you the opportunity to grow and develop. <br><br>Care is at the heart of everything CareShield do.<strong><br><br>About the Role<br></strong>As Lead Database Developer, you will be responsible for the development of CareShield\u2019s MSSQL databases including ensuring the reliability of existing databases, defining, and extending the architecture of our databases and technical specification. You will also be responsible for the guidance of work completed by members of the application development team.</p>\n<p><br>This is a fantastic opportunity for an experienced database developer to join a rapidly expanding company. CareShield are currently on a strong growth trajectory and require a technology leader to help build and develop quality cloud-based products for our customers.</p>\n<p><br>This role will be based in CareShield\u2019s Stevenage Head Office full-time. A hybrid role would be considered with a minimum of 2 days a week in the Stevenage Head Office with the remaining days remote working \u2013 <strong><u>You must already hold the right to work in the UK</u></strong></p>\n<p><strong><br>What Benefits Can You Expect?</strong></p>\n<ul>\n<li>25 days holiday plus bank holidays. (33 in Total)</li>\n<li>Additional day off for Birthday</li>\n<li>Christmas Shutdown</li>\n<li>Generous pension scheme</li>\n<li>Mobile Phone &amp; Laptop provided</li>\n<li>Access to Legal, Financial and Medical Advice for you and your family (via EAP)</li>\n<li>Counselling, Bereavement and CBT services available (via EAP)</li>\n<li>Access to a Wellbeing Portal and Health App that includes fitness, holistic health and wellbeing advice</li>\n<li>Discounts on over 2,000 brand products via Perks at Work including up to 50% of Cinema Tickets</li>\n<li>Hours of work are Monday to Thursday 8.30am to 5:30pm, Fridays 8.30am to 4pm</li>\n<li>Salary: \u00a340,000 - \u00a350,000 (DOE)</li>\n</ul>\n<p><strong>Main Responsibilities for the Role Include:</strong></p>\n<ul>\n<li>Responsible for ensuring availability and performance of the databases that support the organisations products</li>\n<li>Design of new database architecture (tables and workflows) as new applications are developed</li>\n<li>Development of database code e.g. stored procedures and reports to support the development of CareShield applications</li>\n<li>Proactively monitor the database systems to ensure secure services with minimum downtime (both SQL Server interface)</li>\n<li>Responsible for providing trend analysis to management team to enable them to make informed decisions regarding resource management</li>\n<li>Responsible for troubleshooting and problem solving of SQL development</li>\n<li>Line management of other development team members</li>\n</ul>\n<p><strong><br>The <u>MUST HAVE </u>Skills:</strong></p>\n<ul>\n<li>Minimum of 3 years\u2019 experience of working in application development environment(s) in a role requiring a similar skill set</li>\n<li>Experience of MS SQL up to and including MS SQL 2019 and associated applications</li>\n<li>In depth SQL Server database administration experience</li>\n<li>Experience of managing multiple MS SQL RDBMS on large systems</li>\n<li>Strong self-sufficiency and initiative working on database projects</li>\n<li>Practical experience in monitoring and tuning a database to provide a high availability service</li>\n<li>Experience of Transactional SQL and DTS stored procedures</li>\n<li>Practical experience in managing the internal and external MS SQL database security</li>\n<li>Experienced in the usage and implementation of web services</li>\n</ul>\n<p><strong><br>Not Essential but would be an Advantage</strong></p>\n<ul>\n<li>Be familiar with Agile development methodologies</li>\n<li>Have a good understanding of code versioning, especially GIT</li>\n<li>Experience in other code environments: Angular, .NET Core, ASP.NET, JavaScript, WEB APIs</li>\n<li>Hold a development qualification e.g. relevant degree or certification such as Microsoft Certification</li>\n</ul>\n<p><br>Contact us to find out more!<br><br>We are looking for people to take ownership and pride in their work, as well as pulling together as a part of a team. It is an exciting time to be a part of CareShield, a rapidly growing company.</p>\n<p>\u00a0</p>\n<p>As this role will include access to learner data, and as part of our commitment to safeguarding and promoting the welfare of young people and vulnerable adults, an Enhanced DBS check will be requested in the event of being offered a position with us.</p>\n"}, {"id": 953055, "url": "https://remotive.io/remote-jobs/data/senior-sdet-data-analytics-953055", "title": "Senior SDET - Data & Analytics", "company_name": "MacroHealth", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-29T01:41:23", "candidate_required_location": "Canada Only", "salary": "", "description": "<p><br><br></p>\n<div class=\"h3\">Company Description</div>\n<p>The U.S. health sector is complex and dynamic - a vast and diverse network of entities that impacts the population and economy like no other industry. At USD$3.3 Trillion, healthcare spending represents nearly 18% of U.S. GDP. It is complex and inefficient. Health service buying, selling, and settlements have seen little change in the past decade despite clear changes in available information, technology, regulation, and market consolidation.</p>\n<p>Enter MacroHealth. MacroHealth is a mission-driven company. We are building the most advanced and trusted market platform for health service payers and providers. The company\u2019s vision is to create Intelligent Health Markets by building technology, knowledge and relationships that enable payers and providers to optimize the buying and selling of health services.</p>\n<p>We are expanding our team of passionate thought leaders as we pursue our goal of disrupting the U.S. health sector with our vision and technology. We are committed to developing leading edge solutions in a supportive environment focused on customer success and employee fulfillment. We provide our engineers an environment in which they can contribute from day one while also providing opportunities for learning and growth.</p>\n<p><br><br></p>\n<div class=\"h3\">Job Description</div>\n<p>Are you interested in being part of an expanding team tasked to build the next-generation industry-leading data platform for healthcare markets? We are looking for smart, passionate, and highly skilled\u202f <strong>Senior\u00a0Software Development Engineer in Test\u00a0</strong><strong>\u202f</strong>to join the effort to define and build the future of MacroHealth. You will be joining the\u00a0<strong>Data\u00a0</strong>team at MacroHealth. The work you\u2019ll do directly impacts the experience of our customers.</p>\n<p><strong>Responsibilities:\u202f</strong></p>\n<p>You will be an instrumental part of the Data Analytics team at MacroHealth, entrusted with writing automated tests and frameworks to help ensure the quality of our data platform. Because you\u2019re obsessed with quality and delivering rock solid products to our customers, you\u2019ll leverage your prior experience to institute tools and processes that the engineering team can adopt to increase overall productivity. We are looking for smart, creative, and hardworking individuals who know how to write effective code, communicate well, and learn from other engineers.</p>\n<p>This position requires you to be a self-starter, innovative and with the ability to take ownership, work with tight timelines, and handle various tasks simultaneously while continuing to develop a positive work culture. You will join a world-renowned leadership team with a track record of leading the development of multiple successful companies and products.</p>\n<p><br><br></p>\n<div class=\"h3\">Qualifications</div>\n<p><strong>Your background includes:\u202f</strong></p>\n<ul>\n<li>5+ years of experience building automated test suites and frameworks to help ensure the quality of enterprise-class software</li>\n<li>Ability to work in multiple programming languages: Java &amp; Python are currently the major tool of choice within Data Analytics team, but experience with comparable languages is also valuable.</li>\n<li>Practical experience working in at least one public cloud ecosystem. We currently use Azure, but experience with AWS or Google is equally valuable.</li>\n<li>Experience with data processing frameworks and tools, such as Spark, Hadoop, Hive, Kafka, etc.</li>\n<li>Knowledge of performance and security testing concepts</li>\n<li>Experience with version control systems, CI/CD, and maintenance of test environments</li>\n<li>Bachelor\u2019s degree in Computer Science or related field, or equivalent work experience</li>\n<li>Strong communication skills, both verbal and written</li>\n<li>Thriving in a people-first culture of teamwork and respect.</li>\n</ul>\n<p><strong>Your background may additionally include:</strong></p>\n<ul>\n<li>Ability to evaluate and select tools to use as part of a larger automation framework</li>\n<li>Familiarity with BDD/TDD and test automation at the unit, component and system test levels</li>\n<li>Leadership experience; you may have acted as a QA lead, or technical lead, in an enterprise software company</li>\n<li>Knowledge of\u202fthe US Healthcare space including\u202fstandards\u202fsuch as HIPAA\u202f</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">Additional Information</div>\n<p><strong>What you can expect</strong></p>\n<p>The success and engagement of our team members is the top priority for MacroHealth as a company. \u00a0We provide a compelling package with competitive compensation and benefits as well as attractive incentive structures. \u00a0Our collaborative work environment means each team member can rely on the skills, expertise, and support of one another across the company. \u00a0We are open to new perspectives for improving our operations and fueling future growth and are committed to attracting and developing a diverse and engaged team.\u00a0</p>\n<p>This role requires legal authorization to work in Canada.</p>\n<div>\u00a0</div>\n<p>MacroHealth is an equal opportunity employer.</p>\n"}, {"id": 953613, "url": "https://remotive.io/remote-jobs/data/data-scientist-pricing-strategy-analytics-953613", "title": "Data Scientist  - Pricing Strategy & Analytics", "company_name": "Loadsmart", "category": "Data", "tags": [], "job_type": "contract", "publication_date": "2021-10-28T17:43:32", "candidate_required_location": "Latin America Only", "salary": "", "description": "<div><strong>ARE YOU INTERESTED IN JOINING A HYPER-GROWTH LOGISTICS TECH COMPANY?</strong></div>\n<div>\u00a0</div>\n<div>\u2192 Do you see yourself deep diving into internal and external data, leading a multitude of analyses and projects that generate insights for the overall pricing strategy?</div>\n<div>\u2192 Are you capable of bridging theory to practice, simplifying complex concepts to a larger audience and communicating your analyses and models to stakeholders?</div>\n<div>\u2192 Do you want to work with many different teams to assist in identifying which multi-million dollar bets we should make to maximize yield and minimize risk?</div>\n<div>\u00a0</div>\n<div>If so, nice to meet you! We are Loadsmart and we have recently created a new Data Scientist in Pricing Strategy &amp; Analytics role. We are a Series C-funded logistic technology company that has increased our revenue by 200% year over year, led by a leadership team of logistics veterans and experienced engineers, product leaders and data scientists continuing to disrupt this $800 billion industry.</div>\n<div>\u00a0</div>\n<div>We are seeking a data scientist /economist who thrives in a dynamic and fast-paced global company.\u00a0</div>\n<div>\u00a0</div>\n<div>\u00a0</div>\n<div><strong>LOCATION: </strong>Remote from anywhere in Latin America</div>\n<p><br><br></p>\n<div class=\"h3\">What you get to do:</div>\n<ul>\n<li>Lead statistical &amp; econometric analyses, leveraging both internal and external market data to create pricing strategies that optimize revenue, PnL, and manage brokerage risk in both spot and contracted freight markets in the US. This includes:</li>\n</ul>\n<ul>\n<li>Identifying patterns and trends that help feed our pricing strategy</li>\n</ul>\n<ul>\n<li>Understanding the dynamics of our machine learning pricing algorithms to create optimal strategies on top of existing algorithms</li>\n</ul>\n<ul>\n<li>Leveraging macroeconomic and industry level data and analytics to identify actionable business opportunities and improve our lane-level and company-level strategy</li>\n</ul>\n<ul>\n<li>Leverage technical expertise to design database structures, automate recurring tasks, and publish market research &amp; insights internally (potentially externally down the road)</li>\n</ul>\n<ul>\n<li>Optimize Loadsmart\u2019s PnL by enhancing Loadsmart\u2019s spot (day-to-day) and contracted (long-term) pricing</li>\n</ul>\n<ul>\n<li>Collaborate with Sales, Account Management, Carrier Sales, Product, Engineering, Data Science, and existing Pricing Strategy teams to provide data-driven insights and to enhance knowledge and understanding of the truckload market</li>\n</ul>\n<ul>\n<li>Create the foundation for building / growing a business-facing data science &amp; analytics\u00a0team.</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">You have experience:</div>\n<ul>\n<li>5+ years of experience in a highly analytical data science, statistics, economics, finance or related roles</li>\n</ul>\n<ul>\n<li>Proficient in verbal and written English \u2013 you will be communicating with native English speakers daily</li>\n</ul>\n<ul>\n<li>Proficiency in R, Python or similar programming language, advanced Microsoft Excel skills and a basic working knowledge of SQL</li>\n</ul>\n<ul>\n<li>Masters / PhD is a plus</li>\n</ul>\n<ul>\n<li>Academic background and/or job experience in economics &amp; finance is a plus</li>\n</ul>\n<ul>\n<li>Proficiency in modelling time series data is a plus</li>\n</ul>\n<ul>\n<li>Effective analytical and problem-solving capabilities</li>\n</ul>\n<ul>\n<li>Able to excel alongside and within groups to maintain a collaborative work environment</li>\n</ul>\n<ul>\n<li>Detail oriented and focused</li>\n</ul>\n<ul>\n<li><strong>Note:</strong> This role does not require knowledge of software engineering in activities such as : Implementing models into production, configuring APIs, maintaining tech infrastructure, data pipelines, etc.</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">Your colleagues describe you as:</div>\n<ul>\n<li>Highly analytical - data driven, logical reasoning, strategic, also having an eye for the business bottom line\u00a0</li>\n</ul>\n<ul>\n<li>Detail orientated &amp; organized - structured, can balance multiple projects/deadlines</li>\n</ul>\n<ul>\n<li>Strong communicator - clear &amp; specific</li>\n</ul>\n<ul>\n<li>Agile and proactive - independent self-starter.</li>\n</ul>\n<div><strong>WORKING AT LOADSMART:</strong></div>\n<div>\u00a0</div>\n<div><strong>Prosperity</strong></div>\n<div>\u2022 Competitive base salaries - we believe in rewarding top talent\u00a0</div>\n<div>\u2022 Extremely competitive Equity package</div>\n<div>\u2022 Signing bonus - because you will work remotely, you will use it as you like: to setup your home office, get a new laptop or buy that amazing coffee machine to make your days happier :)</div>\n<div>\u2022 Training budget - we will support you on developing your skills.</div>\n<div>\u00a0</div>\n<div><strong>Happiness</strong></div>\n<div>\u2022 Unlimited time off</div>\n<div>\u2022 Wellbeing initiatives</div>\n<div>\u2022 Lots of engagement activities;</div>\n<div>\u2022 An opportunity to work with a diverse, global community of 450+ Loadies united by our core value of Teamwork\u00a0</div>\n<div>\u2022 Regular recognition, feedback, and transparency across all levels</div>\n<div>\u2022 Opportunities for you to join our community service initiatives.</div>\n<div>\u00a0</div>\n<div>At Loadsmart, we believe our biggest asset is our people. We are proud to be an equal opportunity employer, hiring and developing individuals from diverse backgrounds and experiences to add to our collaborative culture. Loadsmart treats all candidates and employees with respect and does not discriminate in our recruiting, hiring, and promoting processes, including on the basis of race, color, religion, sex, age, sexual orientation, gender identity and/or expression, national origin, veteran status, or disability.</div>\n"}, {"id": 953260, "url": "https://remotive.io/remote-jobs/data/data-modeler-953260", "title": "Data Modeler", "company_name": "Param Solutions", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-27T21:48:28", "candidate_required_location": "USA Only", "salary": "", "description": "<p><u><strong>Clearance Requirement:</strong></u> Must be US Citizen or Permanent Holder.</p>\n<p><u><strong>Overview:</strong></u></p>\n<p>We are seeking a talented data modeler to assist with the analysis, design, and implementation of information solutions. As a data modeler, you will be working closely with data stewards, data architects, business architects, solution architects, and DBA's to capture business requirements in logical data models. You will work to ensure corresponding physical data models map to the logical data models. To ensure success as a data modeler, you should have in-depth knowledge of 3NF and dimensional logical data modeling methods as well as excellent communication skills. Ultimately, the data modeler should be able to detail logical models that align with physical data models produced based on those models and work to reduce data redundancy, streamline data movements, and improve enterprise information management.</p>\n<p><u><strong>Responsibilities:</strong></u></p>\n<ul><li>Analyze and translate business requirements into conceptual and fully detailed logical data models.</li><li>Create logical data models based on existing applications and databases.</li><li>Review the existing data models and update as needed</li><li>Implement and Maintain data dictionary, data model across multiple interdependent systems.</li><li>Contribute to ongoing updates to data modeling standards and guidelines.</li><li>Work with business architects, data architect, data stewards to capture business requirements in a Logical Data Model.</li><li>Contribute to assessing the appropriate data platform(s) for solutioning efforts.</li><li>Evaluate implemented application databases for variances from standards.</li><li>Evaluate physical data models to ensure they align to the corresponding logical data models.</li><li>Works closely with other architects, DBAs, development teams, security, and operations staff, etc.</li></ul>\n<p><u><strong>Qualifications:</strong></u></p>\n<ul><li>BS in information systems or computer science</li><li>5+ years of experience with data modeling with Oracle database</li><li>Expert in data modeling experience (Conceptual, Logical, Physical/ERD) using proven techniques and modern tools</li><li>5+ years of experience writing Queries, acquiring data from primary and secondary data sources, and maintaining databases</li><li>5+ years of database development and troubleshooting skills and ability to work closely across multiple teams and vendors to ensure successful releases and enterprise scale data migration.</li><li>5+ years of experience designing, developing, and managing enterprise-level databases using Oracle</li><li>Experience implementing large-scale solutions that empower business data and enterprise data integration using Oracle</li></ul>\n"}, {"id": 953420, "url": "https://remotive.io/remote-jobs/data/marketing-data-analyst-953420", "title": "Marketing Data Analyst", "company_name": "Iron Horse", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-25T09:55:29", "candidate_required_location": "USA Only", "salary": "", "description": "<div class=\"h1\">About the Role</div><p>Iron Horse is a leader in creating data-driven programs that create a bridge between marketing efforts and sales. We're transforming the way our clients connect with their customers to deepen engagement and increase revenue. Our client roster includes some of the largest names in the Fortune 1000.\u00a0</p>\n<p>We are looking for a marketing analyst who can help drive insights for the integrated marketing programs we create, execute and manage for our customers. We are looking for someone who understands the metrics that drive marketing, has the curiosity to ask the right questions, and the ability to present findings to clients in a clear and compelling manner.</p>\n<p>In this role, you would be using digital analytics tools to extract and analyze data that describes the customer and campaign experience. You would be part of a small team that uses data to create insights and make strategic recommendations via weekly, monthly and quarterly presentations to our customers. Does that sound exciting to you? Great, read on to learn more.</p><p>This position is available as 100% remote. Candidates must live in the United States, but those who reside in the Portland, OR or San Francisco area have the option to work in office. Candidate must be authorized to work in the United States.</p>\n<div class=\"h1\">Key Responsibilities</div>\n<ul><li>Analyzing the customer journey across an integrated marketing campaign and recommending optimization strategies\u00a0</li><li>Leveraging data to identify ways to grow revenue, customer engagement and conversion</li><li>Building dashboards and presentations for marketing programs that highlight performance on key metrics</li><li>Utilizing company, user and marketing response history data to drive segmentation for new email nurture campaigns</li><li>Reviewing work of other analysts to ensure high quality output for our clients</li><li>Bread crumb analysis of user behavior based on channel, offers and geography</li><li>Developing and implementing statistical models to predict lead generation strategies</li><li>Consistently model our company values to Pursue Excellence, Think Differently, Act Professionally and Drive Growth.</li><li>Additional duties as assigned</li></ul>\n<div class=\"h1\">You are a good fit if you have...</div>\n<ul><li>2+ years of relevant work experience</li><li>A deep knowledge of mathematics, statistics, computer science, or engineering</li><li>Experience in strategy consulting, Internet marketing, decision support, or related field</li><li>Proficiency with relational databases and SQL</li><li>Familiarity with analytics softwares (Google Analytics, Adobe Analytics).</li><li>Experience with Tableau, Power BI or similar data visualization tool</li><li>Proficient with Excel or Google Sheets (Formulas, VLookUps)</li><li>Structured, organized and detail oriented with ability to validate / triangulate data and derive insights</li><li>A comfort working on multiple projects under defined timelines</li><li>Strong understanding of digital marketing and key performance metrics</li></ul>\n<div class=\"h1\">The ideal candidate has...</div>\n<ul><li>Strong PowerPoint/Google Slides skills; ability to tell the story and deliver key takeaways based on data and analysis</li><li>Experience working with complex data sets with 1 million+ records.\u00a0</li><li>Adobe Analytics certification</li><li>Experience with Alteryx or RedShift</li><li>Knowledge of marketing automation (HubSpot, Eloqua, Marketo) and CRM (Salesforce, MS Dynamics) systems</li></ul>\n<div class=\"h1\">It would be nice to have...</div>\n<ul><li>B.S. Degree in mathematics, statistics, computer science, or engineering or equivalent experience. Overall, we're not looking for someone with the right degree. We're looking for someone who has the right skills and can put them into action.</li></ul>\n"}, {"id": 951820, "url": "https://remotive.io/remote-jobs/data/analytics-engineer-951820", "title": "Analytics Engineer", "company_name": "Colvin", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-23T21:41:19", "candidate_required_location": "Anywhere", "salary": "", "description": "<p>Colvin is a global scale-up from Barcelona, disrupting the floriculture and gifting industry.<br>We are reinventing the way flowers and plants are enjoyed, from our farmers to our customers' doors. Because we believe small gestures and details can change everything and we want to help people bring these small gestures in their day-to-day and help them be with their loved ones' when they can't.<br>We envision a world more human and emotional, where we inspire people to connect with each other more often and in more meaningful ways.<br>Colvin currently operates in 4 countries and has offices in Barcelona, but with a remote-first culture. Work from anywhere when you feel like or come and meet the team at the office. We are powered by a culture of ownership, innovation, customer obsession and humbleness, always going the next mile to achieve what we propose to our customers.<br>We recently closed our \u20ac15M financing and we\u2019ve been recognized as LinkedIn's Top 2 Startup 2020 in Spain. But all of that is just the beginning of a long journey to continue inspiring people to connect more often and disrupt the floriculture and gifting space global.</p>\n<p><strong>We are looking for an Analytics Engineer</strong> who comes from the field of Computer Science. This person should have experience 2-3 years working in ETL process and he/she wants to develop his/her data career to Data engineer. This person should be very oriented to software development best practises, technicall person who loves working in data.</p>\n<div class=\"h3\">What you will do?</div>\n<ul>\n<li>Work closely with data analysts and backend engineers to understand business requirements and provide data ready for analysis.</li>\n<li>Design high-performance, reusable, and scalable data models for our data warehouse to ensure that our end-users get consistent and reliable answers when running their own analyses.</li>\n<li>Be a SQL whiz! You know how to write SQL which is easy to understand, simple to troubleshoot and that is highly performant.</li>\n<li>Work in data connections with Cloud functions and Fivetran and in data transformations with dbt.</li>\n<li>Continuously discover, transform, test, deploy and document data sources</li>\n<li>Apply, help define, and champion data warehouse governance: data quality, testing, coding best practises, and peer reviews</li>\n<li>Apply advanced aggregations and data wrangling techniques for predictive analytics</li>\n<li>Contribute towards the strategy and design of self service analytics reporting in Looker.</li>\n<li>Apply software engineering best practices like version control and continuous integration to the analytics code base.</li>\n<li>Coach analysts and data scientists on software engineering best practices.</li>\n</ul>\n<div class=\"h3\">What are we looking for?</div>\n<ul>\n<li>Bachelors or Masters Degree in Computer Science (or equivalent work experience).</li>\n<li>Experience working as part of a data team; preferably as either a data analyst or data engineer.</li>\n<li>Excellent SQL skills, Data Modelling and Python</li>\n<li>Working experience with Google Cloud Platform/Amazon Web Services</li>\n<li>Experience with task orchestration tools (Ex.Airflow, Luigi)</li>\n<li>Cloud Data Warehousing experience in Bigquery or another distributed platform (e.g. Redshift or Snowflake)</li>\n<li>Import and transform data from many third-party APIs</li>\n<li>Experience of GitHub actions a plus</li>\n<li>Nice-to-haves: prior experience modelling data in LookML and dbt (data build tool)</li>\n</ul>\n<div class=\"h3\">What it\u2019s like to work in Colvin?</div>\n<ul>\n<li>Join a talented, international and young team where all ideas count and we take care of your development really seriously.</li>\n<li>Remote first culture &amp; flexible working hours.</li>\n<li>Possibility to work in our coworking in Barcelona open 24h with services like free gym.</li>\n<li>Discounts in our website.</li>\n<li>Flexible retribution for kindergarten, transportation and food.</li>\n</ul>\n<div class=\"h3\">\u00a0</div>\n"}, {"id": 942841, "url": "https://remotive.io/remote-jobs/data/data-storyteller-contrast-labs-942841", "title": "Data Storyteller, Contrast Labs", "company_name": "Contrast Security", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-23T02:32:07", "candidate_required_location": "USA Only", "salary": "", "description": "<div><strong><a class=\"postings-link\" href=\"https://www.contrastsecurity.com/security-influencers/inc-magazine-best-workplaces-2020\" rel=\"nofollow\" style=\"font-size: 18px;\">Contrast Security named to Inc.'s \u201cBest Workplaces of 2020\u201d</a></strong></div>\n<div>\u00a0</div>\n<div>Contrast Security is the world\u2019s leading provider of security technology that enables software applications to protect themselves against cyberattacks, heralding the new era of self-protecting software. Contrast's patented deep security instrumentation is the breakthrough technology that enables highly accurate assessment and always-on protection of an entire application portfolio, without disruptive scanning or expensive security experts. Only Contrast has sensors that work actively inside applications to uncover vulnerabilities, prevent data breaches, and secure the entire enterprise from development, to operations, to production.</div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 18px;\">About the Position</strong></div>\n<div>This position will oversee storytelling using Contrast product data and primary research for marketing content and measuring customer value. Assist with survey-driven marketing data analytics and storytelling projects. This is a key role that will have the opportunity to do two things:</div>\n<div>1. Share critical security trends and \"a-ha\" moments to developers and security professionals about the code they write</div>\n<div>2. Work with our customers (and our Account teams) to quantify the value their AppSec teams and programs are delivering to their companies</div>\n<div>\u00a0</div>\n<div><strong style=\"font-size: 18px;\">About You</strong></div>\n<div>You are a deeply curious part-writer, part-data scientist, part-project manager who loves thinking critically and working collaboratively. You know how to tell great stories with data, but you also know how to \"go get the data\" if needed. You know that stories are how we make sense of numbers, and you thrive on the creative challenge of transforming our data into compelling stories across platforms and channels. You understand data visualization techniques and consider yourself a true partner to designers to get stories told across platforms, including social and video. You are a true team player who will own your own workstream, and you would enjoy \u201cyes, and\u201d content brainstorm sessions being part of your weekly cadence.</div>\n<p><br><br></p>\n<div class=\"h3\">Responsibilities</div>\n<ul>\n<li>Craft compelling narratives and insights using data collected by Contrast Security in-product as well through primary research</li>\n</ul>\n<ul>\n<li>Work with Contrast's customers, Customer Success and Sales to build value models that quantify the benefits delivered by our products</li>\n</ul>\n<ul>\n<li>Collaborate with the Cloud Infrastructure Data Analytics team to deliver near real-time analytics insights\u00a0</li>\n</ul>\n<ul>\n<li>Partner with the Cloud Infrastructure Data Analytics team, Sales, Marketing, Engineering, and Customer Success teams to select and implement a self-service data visualization tool (which will sit on top of the data warehouse/data lake)</li>\n</ul>\n<ul>\n<li>Oversee data analytics and modeling needed to generate Contrast Labs bimonthly and annual reports tied to Contrast data</li>\n</ul>\n<ul>\n<li>Participate as a data subject-matter expert in Contrast webinars and podcasts</li>\n</ul>\n<ul>\n<li>Continuously innovate and evolve data analytics and storytelling programs\u00a0</li>\n</ul>\n<ul>\n<li>Other duties as assigned</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">Qualifications</div>\n<ul>\n<li>5+ years of experience in roles of increasing responsibility managing data analytics with storytelling as a critical function</li>\n</ul>\n<ul>\n<li>BA/BS degree in math, statistics, economics, computer science, data science, or related quantitative field</li>\n</ul>\n<ul>\n<li>2+ years of experience crafting compelling narratives with data</li>\n</ul>\n<ul>\n<li>Some exposure to Value Engineering, TCO or ROI modeling</li>\n</ul>\n<ul>\n<li>Experience with SQL and relational databases</li>\n</ul>\n<ul>\n<li>Experience working with BI visualization platforms\u00a0</li>\n</ul>\n<ul>\n<li>Experience with one programming language\u2014preferably Python</li>\n</ul>\n<ul>\n<li>Expert knowledge of project management and working cross-functionally with Sales, Marketing, Engineering, and Customer Success</li>\n</ul>\n<ul>\n<li>Expert knowledge of Microsoft Word, PowerPoint, and Excel\u00a0</li>\n</ul>\n<ul>\n<li>Outstanding problem-solving, interpersonal, and communication skills\u00a0</li>\n</ul>\n<ul>\n<li>Ability to work and navigate across organizations functions to achieve positive outcomes for all parties involved</li>\n</ul>\n<div>\u00a0</div>\n<div><em>We are focused on building a diverse and inclusive workforce. If you\u2019re excited about this role, but do not meet 100% of the qualifications listed above, we encourage you to apply.</em></div>\n<p><br><br></p>\n<div class=\"h3\">What We Offer</div>\n<ul>\n<li>Competitive compensation</li>\n</ul>\n<ul>\n<li>Medical, dental, vision benefits</li>\n</ul>\n<ul>\n<li>401(k)</li>\n</ul>\n<ul>\n<li>Flexible paid time off</li>\n</ul>\n<div><span style=\"font-size: 10px;\">#LI-132606351 #LI-remote</span></div>\n<div>\u00a0</div>\n<div><strong>We are changing the world of software security.\u00a0<em>Do it with us.\u00a0</em></strong>\u00a0</div>\n<div>We believe in what we do and are passionate about helping our customers secure their business.</div>\n<div><strong>If you\u2019re looking for a challenge and want to enjoy where you work, you\u2019ll love Contrast Security.</strong></div>\n<div>\u00a0</div>\n<div><em>Contrast Security is committed to a diverse and inclusive workplace. Contrast Security is an equal opportunity employer and our team is comprised of individuals from many diverse backgrounds, lifestyles, and locations.</em></div>\n<div>\u00a0</div>\n<div><span style=\"font-size: 10px;\">By submitting your application, you are providing Personal Information about yourself (cover letter, resume, email address, etc.) and hereby give your consent for Contrast Security, Inc. and/or our HR-related Service Providers, to use this information for the purpose of processing, evaluating and responding to your application for current and future career opportunities. If you are a resident of the European Economic Area or are applying for a position in the European Economic Area,\u00a0</span><a class=\"postings-link\" href=\"https://www.contrastsecurity.com/privacy-matters\" rel=\"nofollow\" style=\"font-size: 10px;\">Contrast\u2019s Privacy Statement</a><span style=\"font-size: 10px;\">\u00a0reflects our policies around compliance with the General Data Protection Regulation (\u201cGDPR\u201d) and your rights respective to\u00a0</span><a class=\"postings-link\" href=\"http://gdpr.as/\" rel=\"nofollow\" style=\"font-size: 10px;\">GDPR</a><span style=\"font-size: 10px;\">\u00a0as a California resident, you are entitled to certain rights under CCPA:\u00a0The California Consumer Privacy Act of 2018 (\u201cCCPA\u201d) will go into effect on January 1, 2020. Under CCPA, businesses must be overtly transparent about the personal information they collect, use, and store on California residents. CCPA also gives employees, applicants, independent contractors, emergency contacts and dependents (\u201cCA Employee\u201d) new rights to privacy.</span></div>\n<div><em style=\"font-size: 10px;\">* We could support remote work in most states except Colorado.</em></div>\n<div>\u00a0</div>\n<div><em>Recruitment Agencies: Although we value the services you provide, at this time we are not accepting resumes from agencies, headhunters, or other suppliers who have not signed a formal agreement with us.</em></div>\n"}, {"id": 941301, "url": "https://remotive.io/remote-jobs/data/lead-data-engineer-m-f-x-941301", "title": "Lead Data Engineer (m/f/x)", "company_name": "Scalable Capital GmbH", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-21T13:51:55", "candidate_required_location": "Germany Only", "salary": "", "description": "<p><br><br></p>\n<div class=\"h3\">Company Description</div>\n<p>Scalable Capital was founded in 2014, entering the FinTech industry with the aim of democratizing investment management and brokerage. Our mission is to use modern technology to make investments both easier and more affordable. Today, Scalable Capital is Europe's largest digital asset manager with assets valued over 6\u00a0billion Euros under management, a neo-broker for independent decision makers, and a European leader in providing B2B digital asset management platform solutions. Visit our<a href=\"https://de.scalable.capital/blog\" rel=\"nofollow\">\u00a0finance</a>\u00a0blog or tune in for our<a href=\"https://de.scalable.capital/podcast?utm_medium=email&amp;utm_source=personalmail&amp;utm_campaign=email&amp;utm_content=max_ooo\" rel=\"nofollow\">\u00a0podcast</a>\u00a0to find out what our Expert Team has to say.</p>\n<p>If you are looking for scalability in your professional career, join us in re-defining how investors think about wealth creation and in making first class investment services available to everyone.</p>\n<p>Work with our team\u00a0onsite or remote from\u00a0anywhere in Germany.</p>\n<p><br><br></p>\n<div class=\"h3\">Job Description</div>\n<ul>\n<li>Be responsible for a group of Engineers that\u00a0build our cloud-based data platform</li>\n<li>Create and execute the team\u2019s roadmap in coordination with stakeholders such as management, marketing, sales and quantitative research</li>\n<li>Shape an AWS based stream and batch processing solution, ingesting data from 3rd party, as well as internal backend services</li>\n<li>Ensure\u00a0we collect all data required to execute on the company\u2019s mission</li>\n<li>Build\u00a0interactive dashboards and reporting solutions</li>\n<li>Provide\u00a0a trustful environment for your team and develop their skills, such as giving technical talks, how to share knowledge and how to work together</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">Qualifications</div>\n<ul>\n<li>Experience in leading a data team</li>\n<li>Experience in building a cloud-based data platform, ideally on AWS</li>\n<li>A strong background of software development in Java, Kotlin or Python</li>\n<li>A strong business sense, understand our mission and what it takes to achieve it</li>\n<li>Strong communication skills, you are able to tell stories using data and drive discussions with other business leaders</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">Additional Information</div>\n<ul>\n<li>Be part of one of the fastest-growing and most visible Fintech startups in Europe, creating innovative services that have a substantial impact on the lives of our customers</li>\n<li>The ability to work with an international, diverse, inclusive, and ever-growing team that loves creating the best products for our clients</li>\n<li>Enjoy an office in a great location in the middle of Munich or Prenzlauer Berg, one of the hippest neighborhoods of Berlin or choose to work remote</li>\n<li>Learn and grow by joining our in-house knowledge sharing sessions and spending your individual Education Budget\u00a0</li>\n<li>Work productively with the latest hardware and tools</li>\n<li>Say goodbye to order commissions and say hello to your complimentary subscription of Scalable Capital's PRIME Broker</li>\n<li>Benefit from an attractive compensation package</li>\n<li>Learn and Experience German culture first hand by joining our free German language classes</li>\n</ul>\n"}, {"id": 940199, "url": "https://remotive.io/remote-jobs/data/data-integration-engineer-940199", "title": "Data Integration Engineer", "company_name": "Onebridge", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-21T02:18:14", "candidate_required_location": "USA Only", "salary": "", "description": "<p>Onebridge\u00a0is a Consulting firm with an HQ in Indianapolis, and clients dispersed throughout the\u00a0United States and beyond.\u00a0We have an exciting opportunity\u00a0for\u00a0a\u00a0Senior Data Engineer to\u00a0join\u00a0one of our clients on a direct-hire basis.\u00a0\u00a0</p>\n<p>100% Remote - USA\u00a0</p>\n<p><strong>Data Integration Engineer | About You\u00a0</strong>\u00a0</p>\n<p>The Data Engineer will serve in a key role within our Data Practice, working with clients to develop end-to-end data-driven solutions. Must be highly analytical and have the proven ability to develop and reverse engineer complex solutions. Critical thinking and advanced problem-solving skills are core behaviors among the team. Strong team and project lead experience will be valuable for this role.\u00a0\u00a0\u00a0</p>\n<p><strong>Data Integration Engineer | Core Responsibilities</strong>\u00a0\u00a0</p>\n<ul><li>Collaborate with cross-functional stakeholders to formulate and complete full cycle analysis that includes data gathering, analysis, and strategic insights and recommendations\u00a0</li></ul>\n<ul><li>Utilize e-commerce platforms and social media APIs to enhance\u00a0the\u00a0organizations\u00a0application and user insights.\u00a0</li><li>Design, develop, and test databases, data warehouses, data lakes, queries and views, reports, and dashboards.\u00a0\u00a0\u00a0</li><li>Utilizes best in class ETL and ELT practices to perform data conversions, imports, and exports of data within and between internal and external software systems.\u00a0\u00a0</li><li>Merges\u00a0platforms with enterprise systems and applications.\u00a0\u00a0</li></ul>\n<ul><li>Provides advisory and solutioning expertise to a broad range of cross functional teams.\u00a0\u00a0</li></ul>\n<p><strong>Data Integration Engineer | Skills &amp; Experience</strong>\u00a0\u00a0</p>\n<ul><li>Bachelor's level degree or equivalent experience required.\u00a0\u00a0</li><li>Experience working within an eCommerce environment is critical to understanding the data landscape.\u00a0\u00a0</li><li>Experienced using\u00a0social media APIs\u00a0and e-commerce platforms\u00a0including\u00a0Shopify, including\u00a0building\u00a0and integrating\u00a0REST APIs and web hooks.\u00a0</li><li>SQL experience\u00a0required, but experience with\u00a0Redshift or Vertica\u00a0could be valuable.\u00a0</li></ul>\n<ul><li>Experienced using\u00a0data visualization platforms (Tableau, Looker, Periscope, etc.)\u00a0</li></ul>\n<ul><li>Solid understanding of ETL strategies and design, (staging environments, data transformation, change data capture, slowly changing dimensions, etc.), with an eye towards delivering functional and useful solutions in a timely manner.\u00a0\u00a0</li><li>Python proficiency for data analytics including pandas,\u00a0sklern, matplotlib, seaborn, plot.ly.\u00a0</li></ul>\n<figure><img src=\"https://gallery-cdn.breezy.hr/a7c5e/Job Posting Footer 2021.png\"></figure>\n"}, {"id": 940029, "url": "https://remotive.io/remote-jobs/data/data-engineer-940029", "title": "Data Engineer", "company_name": "Bigtincan", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-20T17:48:29", "candidate_required_location": "USA Only", "salary": "", "description": "<p>100% Remote Position</p>\n<p>In this role, you will lead the continuous improvement and support of our data science process. The Data Engineer oversees the collection and organization of data and also develops and maintains the system to monitor the end-to-end data science workflow. This includes the process to generate models, verify production model outputs, modify training data based on review, rerun pipeline to create new models based on modified training data, and transfer new models into production.</p>\n<p><strong>Requirements</strong></p>\n<ul>\n<li>Knowledge of python at a production system level. Experience in design, development, and operations of python production systems. Desired experience in data engineering, data science, ML and working on teams doing continuous improvement data science. (Python &amp; SQL)</li>\n<li>Strong \u201chands-on\u201d knowledge with application development, data platforms, and databases (ie. databricks) application software SDLC and business reporting/analytics.</li>\n<li>Experience as a solution architect for business information systems, focusing on database architecture, data modeling, data analysis, model validation and application integration.</li>\n<li>In-depth knowledge of large database design techniques, data transformation, and migration using ETL tools.</li>\n<li>Experience with relational and dimensional data modeling using ERWIN, understanding of star and snowflake schemas, familiarity with feature engineering pipelines, and thorough understanding of data warehousing concepts like facts, dimensions, and surrogate keys.</li>\n<li>Familiarity with business intelligence tools.</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<p>\u00a0</p>\n<p>Perks &amp; Benefits</p>\n<ul>\n<li>Stock Option Plan</li>\n<li>Work From Home</li>\n<li>Training &amp; Development</li>\n<li>Paid Time Off (Vacation, Sick &amp; Public Holidays)</li>\n<li>Life Insurance (Basic, Voluntary &amp; AD&amp;D)</li>\n<li>Retirement Plan (401k, IRA)</li>\n<li>Health Care Plan (Medical, Dental &amp; Vision)</li>\n</ul>\n<p>ABOUT</p>\n<p>Bigtincan is an AI-powered Sales Enablement Automation Platform that adapts to your sales process, delivering the right content to the right users based on role, time, location, association and/or event - with all the automation and productivity tools needed to engage with content in one integrated, intuitive platform.</p>\n<p>Since our inception in 2011, Bigtincan has grown into a global industry leader headquartered in Waltham, Massachusetts with offices in Glasgow and Sydney, Australia. We've partnered with Apple, AT&amp;T, and other technology leaders and are used by the largest, most successful companies in the world such as Exxon, Titleist, Guess Jeans, and Amazon, to accelerate their sales and marketing initiatives.</p>\n<p>For more information, please visit <a class=\"external\" href=\"http://www.bigtincan.com/\" rel=\"nofollow\">www.bigtincan.com</a> or follow @bigtincan on Twitter.</p>\n"}, {"id": 920667, "url": "https://remotive.io/remote-jobs/data/data-engineer-920667", "title": "Data Engineer", "company_name": "aim4hire", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-16T17:42:10", "candidate_required_location": "USA Only", "salary": "", "description": "<p style=\"min-height: 1.5em;\"><strong>Our Client in the Cybersecurity space is scaling a team of Data Engineers and seeking elite additions to the team. Full-time Salary, benefits, stock options &amp; fully-remote.</strong></p>\n<p style=\"min-height: 1.5em;\"><strong>Responsibilities:</strong></p>\n<ul>\n<li>building (1) data provisioning frameworks, (2) data integration into data warehouse, data marts and other analytical repositories (3) integration of analytical results into operational systems, (4) development of data lakes and other data archival stores.</li>\n<li>Optimally leverage the data integration tool components for developing efficient solutions for data management, data wrangling, data packaging and integration. Develop overall design and determine division of labor across various architectural components</li>\n<li>Deploy and customize Standard Architecture components</li>\n</ul>\n<p style=\"min-height: 1.5em;\"><strong>Skills and Qualifications:</strong></p>\n<ul>\n<li>Bachelor\u2019s Degree or foreign equivalent in Computer Science, Electrical Engineering, Mathematics, Computer Applications, Information Systems or Engineering is required</li>\n<li>Experience building high-performance, and scalable distributed systems</li>\n<li>Experience in ETL and ELT workflow management</li>\n</ul>\n<ul>\n<li>Continuous Data Movement/ Streaming/ Messaging:</li>\n<li>Experience using Kafka as a distributed messaging system</li>\n<li>Experience with Kafka producer and consumer APIs</li>\n</ul>\n"}, {"id": 920759, "url": "https://remotive.io/remote-jobs/data/data-engineer-920759", "title": "Data Engineer", "company_name": "ready", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-16T10:01:21", "candidate_required_location": "Anywhere", "salary": "", "description": "<div class=\"h3\">A bit about\u00a0<strong>you</strong>\u00a0\ud83e\udd47</div>\n<p style=\"min-height: 1.5em;\">You\u2019re an experienced engineer skilled in working with large, disparate data sets. You\u2019ve automated ETL before, and thrive in environments of high complexity.</p>\n<ul>\n<li>Desire to constantly learn and try new things</li>\n<li>Comfortable working remotely</li>\n<li>Humble but ambitious, knowledgeable but curious</li>\n<li>3+ years experience building data systems</li>\n<li>Bachelor\u2019s degree or higher in computer science or equivalent field</li>\n<li>Geospatial experience very helpful but not required</li>\n<li>Ability to work efficiently and independently in a fast-paced environment and a desire to wear many hats</li>\n<li>Strong English communication skills \u2013 verbal and written</li>\n<li>Analytical thinker, detail oriented</li>\n<li>Creative at problem solving</li>\n</ul>\n<div class=\"h3\">About your role at Ready \u26a1\ufe0f</div>\n<ul>\n<li>Design, develop, and implement ETL automation for customer data ingestion, pipeline, and data integrations with our core application.</li>\n<li>Work with our backend team to ensure scalable performance of data-intensive features as we grow.</li>\n<li>Make it possible to leverage data in the context of our product\u2019s geospatial features.</li>\n<li>Surface business intelligence insights for our company, and our customers (product will include features that help our customers understand their business).</li>\n<li>You\u2019ll have a major impact on your team and company here at Ready.</li>\n<li>You\u2019ll collaborate with customers and team members to solve real problems, but you\u2019ll also own key parts of the system.</li>\n<li>This role could become a leadership position within Ready as we continue growing together.</li>\n</ul>\n<div class=\"h3\">About what you get\u2026</div>\n<ul>\n<li>Competitive salary plus meaningful equity upside</li>\n<li>Opportunities to learn and grow: not just coding \u2013 all things startups</li>\n<li><strong>Work from anywhere</strong>\u00a0you want, as long as you can get great internet (and your work here at Ready helps make this true in more places)</li>\n<li>We get together 2x / year for optional retreats</li>\n<li>We\u2019re actively shaping our benefits program: have a say in which benefits matter to you</li>\n<li>The chance to hone your skills on a cutting edge stack alongside bright ambitious team members</li>\n</ul>\n"}, {"id": 920985, "url": "https://remotive.io/remote-jobs/data/data-engineer-920985", "title": "Data Engineer", "company_name": "OpenTeams", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-15T13:43:18", "candidate_required_location": "USA Only", "salary": "", "description": "<p>OpenTeams is looking for a full-time Data Engineer to place at a data science and analytics firm. Their aim is to enable their clients to reach actionable insights in a demonstrable and transparent manner. This position requires a candidate currently authorized to work full-time in the United States permanently.</p>\n<div class=\"h2\">Who we are</div>\n<p>OpenTeams is the services marketplace where open source software users can find, vet, and contract with service providers. We believe in a culture of do-ers, learners, and collaborators. We are looking for people who are motivated, humble, curious, and respectful of others. OpenTeams is committed to creating diverse &amp; inclusive work environments. Women &amp; underrepresented groups are statistically less likely to apply to positions unless they meet 100% of the qualifications; we encourage you to contradict this unfortunate trend by applying! We look forward to your application.</p>\n<div class=\"h2\">What you'll do</div>\n<p>As a Data Engineer, you will work with a team to provide data science and data strategy consulting services for a variety of industries. There is a particular focus on rapid prototyping of internal and external analytics products. The data sets and approaches used for a project are varied and seen as an opportunity for innovation and collaboration as each unique task arrives. There is also an opportunity to design the system architecture to scale out as business needs grow.</p>\n<div class=\"h1\">Required Skills</div>\n<ul><li>Fluency in at least one programming language.</li><li>Experience manipulating, aggregating, and expanding data assets.</li><li>Experience with cloud solutions\u2014Google Cloud Platform is most commonly used, but Amazon Web Services, Azure, and other platforms are utilized as well.</li><li>Experience building robust data management systems in cloud environments.</li><li>Experience with automated deployment, continuous integration, and in-depth testing.</li><li>Working knowledge of basic data structures and algorithms</li></ul>\n<p>Additionally one or more of the following skills will help you stand out:</p>\n<ul><li>Proficiency in Python (especially the PyData/SciPy/NumPy stack).</li><li>Experience with ETL data pipelines.</li><li>Knowledge of common website practices and structure.</li><li>Writing tests for code.</li><li>Experience with creating AI/ML models.</li><li>Basic exposure to DevOps, CI/CD, automated testing and deployment.</li></ul>\n<div class=\"h1\">Why you should apply</div>\n<p>OpenTeams career placements are driven by the demands of companies seeking talent with great experience or potential. We strive to connect you with a working environment that gives you room to learn and grow. OpenTeams is committed to supporting diverse and inclusive work environments and is proud to be an equal opportunity employer. All qualified applicants will receive equal consideration for recruitment, interviews, employment, training, compensation, promotion, and related activities without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, veteran status or any and all other protected classes and in accordance with all applicable laws.</p>\n<p></p>\n"}, {"id": 921360, "url": "https://remotive.io/remote-jobs/data/data-engineer-921360", "title": "Data Engineer", "company_name": "Boclips", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-15T05:59:12", "candidate_required_location": "GMT +/- 3 hours", "salary": "", "description": "<div class=\"h3\">About Boclips</div>\n<p>Boclips is the small but mighty educational technology start-up with a distributed team across US, UK, Poland and the Middle East. Our customers build interactive courseware and e-textbooks; we provide the educational media that brings these spaces to life.</p>\n<div class=\"h3\">Data at Boclips</div>\n<p>We have 2 million videos in our catalogue that need enriching metadata such as categories, education level, pedagogy (hook / explainer / context builder etc). The data science team is building and improving models in these areas that need deploying into our production system and monitoring. A data engineer should also help in showing best practice to the data scientists when delivering production models. We have a small and experienced team working to shape data at Boclips, you'd be working alongside <a class=\"external\" href=\"https://www.linkedin.com/in/dosht/\" rel=\"nofollow\">Mou</a>, <a class=\"external\" href=\"https://www.linkedin.com/in/ryanvarley/\" rel=\"nofollow\">Ryan</a>, <a class=\"external\" href=\"https://www.linkedin.com/in/raulvences/\" rel=\"nofollow\">Raul</a> and <a class=\"external\" href=\"https://www.linkedin.com/in/arminbagrat/\" rel=\"nofollow\">Armins</a>!</p>\n<p>We also have a vision to capture all data in a clean format that is easily queried. We need to improve and expand the pipeline to support this, define and improve the schemas being queried and ensure it can be used effectively by the business (currently we use looker).</p>\n<div class=\"h3\">About the role</div>\n<ul>\n<li>We pair-program a lot to share context, learn from each other and solve problems more quickly.</li>\n<li>We deliver continuously, run experiments and communicate results in short cycles and ship code frequently.</li>\n<li>We use TDD. Following the red/green refactor cycle of Test-Driven Development is enjoyable and helps to keep everything in perspective. It helps us as engineers to think through a problem, detailing required functionality through tests.</li>\n<li>Data. Gathering events from users\u2019 actions allows for better decisions on improvements and choosing new features.</li>\n<li>Automation. As a startup we're still in the phase of building and optimising our internal workflows. We're continuously looking at ways to automate back office tasks to make everyone happy.</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<div class=\"h3\">Must have</div>\n<ul>\n<li>Top level communication skills and in English!</li>\n<li>A well rounded understanding of <strong>data lakes, data pipelines</strong>.</li>\n<li>Openness towards <strong>domain-driven design, pair programming and TDD</strong>.</li>\n</ul>\n<div class=\"h3\">Nice to have/tech stack:</div>\n<p>We leverage state of the art technologies to deliver our solutions. We expect most candidates will have three of the following.</p>\n<ul>\n<li>Experience working with <strong>GCP, Kubernetes, and Terraform</strong></li>\n<li><strong>Elasticsearch and MongoDB</strong>.</li>\n<li><strong>Data modelling and BigQuery</strong> or a similar technology</li>\n<li>Experience working with <strong>looker</strong> or similar technology</li>\n<li>Familiarity with <strong>CI/CD pipelines</strong>.</li>\n<li>Experience deploying machine learning models</li>\n</ul>\n<div class=\"h3\">We believe in hiring for engineering aptitude over niche or deeply technical skills</div>\n<ul>\n<li>You can communicate clearly to all audiences, including non-technical team members and external partners.</li>\n</ul>\n<ul>\n<li>You advocate for writing high-quality code and leaving things in a better state than you found them.</li>\n<li>You\u2019re a well-rounded data engineer who likes to understand the business context and anything else that might impact the product</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<div class=\"h3\">What we offer</div>\n<ul>\n<li>Good base salary + annual bonus</li>\n<li>Contract or permanent role</li>\n<li>Fully remote (GMT +/- 3 hours), on site in London or Warsaw, or hybrid working.</li>\n<li>30 days leave (exc bank holidays)</li>\n<li>Private Healthcare</li>\n<li>Share Options (if permanent)</li>\n<li>MacBooks as standard</li>\n</ul>\n<p>\u00a0</p>\n<p>\u00a0</p>\n<p>\u00a0</p>\n"}, {"id": 920894, "url": "https://remotive.io/remote-jobs/data/sr-data-engineer-920894", "title": "Sr. Data Engineer", "company_name": "Pattern", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-14T09:47:28", "candidate_required_location": "USA Only", "salary": "", "description": "<p>Are you obsessed with data, partner success, taking action, and changing the game? If you have a whole lot of hustle and a touch of nerd, come work with Pattern and use your skills to push the one of the fastest-growing companies in the U.S. to the top of the list!</p>\n<p>Pattern is a leading ecommerce accelerator located in the Silicon Slopes tech hub in Utah, with offices in Asia, Australia, Europe, Middle East, and North America. We are one of the fastest growing companies in the Inc. 5000 with over $400M in 2020 revenues and are already profitable. Some of the biggest consumer brands like Nestle, Sylvania, Kong, Panasonic, Sorel, Skullcandy, and Popsockets trust Pattern with their business. Pattern recruits talent from top tech companies including Amazon, Apple, Google, eBay, Oracle, and Adobe and hires the best of the best.</p>\n<p>Pattern values data and the engineering required to take full advantage of it. As a Data Engineer at Pattern, you will work on business problems that have a huge impact on how the company maintains our competitive edge. This position can be based in Lehi, UT or be remote.</p>\n<p><strong>What does a Senior Data Engineer\u00a0do at Pattern?</strong></p>\n<ul><li><strong></strong>Develop, deploy, and support real-time, automated, scalable data streams from a variety of sources into the data lake or data warehouse.<br></li><li>Develop and implement data auditing strategies and processes to ensure data quality; identify and resolve problems associated with large scale data processing workflows; implement technical solutions to maintain data pipeline processes and troubleshoot failures<br></li><li>Collaborate with technology teams and partners to specify data requirements and provide access to data<br></li><li>Tune application and query performance using profiling tools and SQL or other relevant query language<br></li><li>Understand business, operations, and and analytics requirements for data<br></li><li>Build data expertise and own data quality for assigned areas of ownership<br></li><li>Work with data infrastructure to triage issues and drive to resolution<br></li></ul>\n<p><strong>What will I need to thrive in this role?</strong></p>\n<ul><li><strong></strong>Bachelor's degree in data science, data analytics, information management, computer science, information technology, related field, or equivalent professional experience<br></li><li>3+ years of experience working with SQL<br></li><li>3+ years of experience in implementing modern data architecture-based data warehouses<br></li><li>2+ years of experience working with data warehouses such as Redshift, BigQuery, or Snowflake and understand data architecture design<br></li><li>Excellent software engineering and scripting knowledge<br></li><li>Strong communication skills (both in presentation and comprehension) along with the aptitude for thought leadership in data management and analytics<br></li><li>Expertise with data systems working with massive data sets from various data sources<br></li><li>Ability to lead a team of data engineers<br></li></ul>\n<ul><li><strong>What will give me an advantage in this role?</strong></li><li>Experience working with time series databases<br></li><li>Advanced knowledge of SQL, including the ability to write stored procedures, triggers, analytic/windowing functions, and tuning<br></li><li>Advanced knowledge of Snowflake, including the ability to write and orchestrate streams and tasks<br></li><li>Background in Big Data, non-relational databases, Machine Learning and Data Mining<br></li><li>Experience with cloud-based technologies including SNS, SQS, SES, S3, Lambda, and Glue<br></li><li>Experience with modern data platforms like Cassandra, DynamoDB, Apache Airflow, Spark, or ElasticSearch<br></li><li>Expertise in data quality and data governance<br></li></ul>\n<p><strong>What is Pattern about?</strong></p>\n<p>At Pattern, we are</p>\n<p>Data Fanatics: Our edge is always found in the data</p>\n<p>Partner Obsessed: We put our partners first</p>\n<p>Team of Doers: We have a bias for action</p>\n<p>Game Changers: We encourage innovation</p>\n<p><strong>Why should I work at Pattern?</strong></p>\n<p>Pattern offers big opportunities to make a difference in the ecommerce accelerator industry! We are a company full of talented industry experts that evolves quickly and often, we set big goals and work tirelessly to achieve them, and we love our Pattern family. We also believe in having fun and balancing our lives, so we offer awesome benefits that include</p>\n<ul><li>       Unlimited PTO</li><li>       Paid Holidays</li><li>       Onsite Fitness Center</li><li>       Company Paid Life Insurance</li><li>       Casual Dress Code</li><li>       Competitive Pay</li><li>       Health, Vision, and Dental Insurance</li><li>       401(k)</li></ul>\n<p><strong>What is the hiring process?</strong></p>\n<ul><li>       An initial phone interview with Pattern's talent acquisition team</li><li>       An onsite interview with a panel of department leaders</li></ul>\n<p><em>Pattern provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, color, religion, age, sex, national origin, disability, status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws.</em></p>\n<p><em>#LI-EW1<br></em></p>\n"}, {"id": 921271, "url": "https://remotive.io/remote-jobs/data/database-developer-921271", "title": "Database Developer", "company_name": "Employment Hero", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-13T22:16:32", "candidate_required_location": "Australia Only", "salary": "", "description": "<p>Employment Hero is one of Australia's fastest-growing tech companies. Our world-class software is the easiest way for small to medium-sized businesses to manage HR, payroll, employee engagement, and benefits. Having expanded globally in late 2020 we will continue to grow rapidly in 2021 and beyond.</p>\n<p>We believe in distributed employment and take a \u2018Remote First' approach with our team. We don't mind if you live in Broome, Bendigo or Bondi, if you've got the skills for the role and the passion for our mission then we want to hear from you.</p>\n<p>Due to our rapid expansion, we're hiring several newly created roles in our Core Technology team. The new Database Developer will take the lead on database design, development, testing, and performance tuning.</p>\n<p><em>Employment Hero celebrates diverse perspectives and experiences, we invite people of all backgrounds and identities to apply for this position.</em></p>\n<p><strong>Responsibilities</strong></p>\n<ul>\n<li>Analyse, maintain and optimise Employment Hero databases</li>\n<li>Own and report on performance metrics of SQL and non-SQL databases</li>\n<li>Regular identification and improvement of slow-running queries and related optimisations</li>\n<li>Work closely with the Engineering team to improve applications and establish best practices for database performance and concurrency</li>\n<li>Drive currency and upgrades of database platforms</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<ul>\n<li>Proven track record of designing and developing database solutions, with solid understanding of SQL-based database structures, theories &amp; practices</li>\n<li>5+ years designing, running and optimising large and complex database systems on a PostgreSQL platform</li>\n<li>Knowledge and experience running databases within the AWS cloud platform (AWS RDS, AWS Aurora)</li>\n<li>3+ years of programming experience with proficiency in one of the following languages: C, C++, C#, Go, JavaScript, Python, Ruby</li>\n<li>Experience within a microservices-based architecture and its influence on database design</li>\n<li>Excellent troubleshooting and problem-solving skillsBachelor's degree in Computer Science, Software Engineering or equivalent</li>\n</ul>\n<p><strong>These things would be an added bonus - but they aren't required</strong></p>\n<ul>\n<li>Experience working with and managing non-SQL database platforms</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<ul>\n<li>Self, health, wealth and happiness programs</li>\n<li>Work from home available</li>\n<li>Remote-first and flexible working arrangements</li>\n<li>Our Sydney office is dog friendly and remains open for team meetings, collaboration days and those who need a day away from their home office (we are a COVID-safe workspace for those who choose to use it!)</li>\n<li>A generous budget to spend on setting up your home office (if you need a desk, chair, screen? You name it!)</li>\n<li>We set you up for success with the latest and greatest hardware, tools and tech</li>\n<li>Continuing education / post-graduate assistance program</li>\n<li>Virtual yoga classes</li>\n<li>Weekly virtual happy-hour and social events to get to know your new colleagues</li>\n<li>Quarterly &amp; yearly team celebrations</li>\n<li>Access to the EH Employee Benefits Program and Hero Rewards Shop, of course!</li>\n</ul>\n<p><strong>Why Join Employment Hero? </strong></p>\n<p>* LinkedIn Top 25 Startups 2021, ranked #2 in Australia</p>\n<p>* The Australian Top 100 Innovators List 2021</p>\n<p>* Raised $140M Series E round led by Insight Partners July 2021</p>\n<p>* Raised $45M Series D round led by Seek 2021</p>\n<p>* Deloitte Technology Fast 50 2020, ranked #42 in Australia</p>\n<p>* LinkedIn Top 10 Startups 2020</p>\n<p>* Raised $22M Series C Round led by Seek July 2019</p>\n<p>* Raised $8 mill series B round led by Seek and OneVentures</p>\n<p>* Deloitte Technology Fast 50 2019, ranked #20 in Australia</p>\n<p>* GetApp Category Leader Q1 2019</p>\n<p>* Deloitte Technology Fast 50 2018, ranked #12 in Australia</p>\n<p>* HRD Gold Medalist - Human Capital Management Systems 2018</p>\n<p>* HRD Gold Medalist - Rewards and Recognition Service Provider 2018</p>\n<p>* HRD Rewards and Recognition Employer of Choice 2018</p>\n<p>* LinkedIn Top 25 Startups 2018</p>\n<p>* EY Entrepreneur of the Year National Finalist 2018</p>\n<p>* Dynamic Business Top 10 Entrepreneurs, our CEO Ben Thompson ranked #2</p>\n<p>* BRW Most Innovative Companies 2015</p>\n<p>* Anthill Smart 100 List 2015</p>\n<p>* Startup Daily Top 50 Emerging Leaders 2015</p>\n<p>* HRD Employer of Choice Award 2015</p>\n<p>* Aon Hewitt Best Employers 2013</p>\n"}, {"id": 921016, "url": "https://remotive.io/remote-jobs/data/software-engineer-distributed-database-921016", "title": "Software Engineer - Distributed Database", "company_name": "Ahana", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-13T05:48:27", "candidate_required_location": "USA Only", "salary": "", "description": "<p></p>\n<p>Ahana is the self-service analytics startup for Presto, the fastest growing open source SQL project today. Backed by Google Ventures and Lux Capital, Ahana offers its customers the first cloud-native managed service for Presto which simplifies the deployment, management, and integration of Presto. The cloud data analytics market is expected to grow from $10B to $100B in the next 10 years. Ahana Cloud for Presto simplifies and unifies data analytics on disparate data sources such as databases and data lakes on Amazon Web Services (AWS). The founders are experts in Presto, databases, cloud, and open-source GTM, hailing from Uber, Teradata, Splunk, Couchbase, Alibaba, IBM, and Aviatrix. We are an all-remote company with a female co-founder leading the product team.</p>\n<p><strong>Software Engineer \u2013 Database Development</strong></p>\n<p>What you will be doing: You will be working with leading database engineers as they develop and push the PrestoDB open source project forward. </p>\n<p><strong>Responsibilities &amp; Competencies </strong></p>\n<ul><li>BS/MS in Computer Science or related field.\u00a0 \u00a0</li><li>Competency\u00a0in Java 8+, C++, or equivalent system languages.\u00a0\u00a0<br></li><li>Relevant course work in core software concepts (eg. File systems, data structures, algorithms, operating systems, programming languages, etc.)<br></li><li>Willingness to succeed in a startup environment.</li><li>Hands-on experience with distributed systems\u00a0is a major plus.</li><li>       Documented open source contributions are a major plus.</li></ul>\n<p><strong>Benefits Include:</strong></p>\n<ul><li>Comprehensive health coverage including medical, dental, and vision</li><li>Equity awards</li><li>Flexible time off (FTO)</li><li>401K Plan</li><li>Life Insurance</li><li>100% Remote Work Environment</li></ul>\n<p><strong>More About Ahana</strong></p>\n<p><a href=\"https://ahana.io/\" rel=\"nofollow\">Ahana</a> is the only company with a cloud-native managed service for Presto on Amazon Web Services that simplifies the deployment, management, and integration of Presto and enables cloud and data platform teams to provide self-service, SQL analytics for their organization's analysts and scientists. As the Presto market continues to grow exponentially, Ahana's mission is to simplify interactive analytics as well as foster growth and evangelize the PrestoDB community. Founded in 2020, Ahana is headquartered in San Mateo, CA, and operates as an all-remote company. Investors include GV, Lux Capital, and Leslie Ventures. Follow Ahana on<a href=\"https://www.linkedin.com/company/ahana-io\" rel=\"nofollow\"> </a><a href=\"https://www.linkedin.com/company/ahana-io\" rel=\"nofollow\">LinkedIn</a>,<a href=\"https://twitter.com/AhanaIO\" rel=\"nofollow\"> </a><a href=\"https://twitter.com/AhanaIO\" rel=\"nofollow\">Twitter</a>, and<a href=\"http://prestodb.slack.com/\" rel=\"nofollow\"> </a><a href=\"http://prestodb.slack.com/\" rel=\"nofollow\">PrestoDB Slack</a>.<br><br></p>\n"}, {"id": 917294, "url": "https://remotive.io/remote-jobs/data/senior-data-engineer-917294", "title": "Senior Data Engineer", "company_name": "Mantium", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-11T01:59:35", "candidate_required_location": "Anywhere", "salary": "", "description": "<p><strong>Mantium</strong> enables the AI enthusiasts (personal and professional) to rapidly prototype and share large language models, solving one of the biggest barriers to AI adoption: deployment. And to keep your deployed AI behaving well in the real world, Mantium also includes security measures, logging, and human-in-the-loop. It's your AI, make it heard.</p>\n<p><strong>Responsibilities</strong></p>\n<p>You will be helping to build the EDW as part of our \u2018fine-tuning' team. Mantium handles massive amounts of unstructured data and transforms the data into JSONL for advanced model building.</p>\n<ul>\n<li>Design EDW.</li>\n<li>Build data pipeline and provide design oversight.</li>\n<li>Actively participates in and often leads peer development and code reviews within each sprint, with focus on test driven development and Continuous Integration and Continuous Development (CICD).</li>\n</ul>\n<p><strong>Minimum Qualifications</strong></p>\n<ul>\n<li>Familiar with Python 3</li>\n<li>Flexible and able to adapt to a fast paced quickly changing environment</li>\n</ul>\n<ul>\n<li>6 years of ETL &amp; database architectural design</li>\n<li>3 years of data modeling and ETL tooling</li>\n<li>3 years of data management and governance experience</li>\n</ul>\n<p><strong>Why you should join</strong></p>\n<p>Mantium is a globally distributed team and well funded by top-tier venture capital firms. You'll have the ability to make an impact on a rapidly growing company that values autonomy, mastery, and purpose.</p>\n"}, {"id": 917227, "url": "https://remotive.io/remote-jobs/data/medical-device-data-engineer-917227", "title": "Medical device Data engineer", "company_name": "Sentium", "category": "Data", "tags": [], "job_type": "contract", "publication_date": "2021-10-10T14:01:56", "candidate_required_location": "CET (GMT+2)", "salary": "", "description": "<p><strong>Remote\u00a0</strong><strong>Data Engineer for Europe-based consulting project</strong></p>\n<p>Sentium is looking for a senior level data engineer to join an active consulting team. The project is a focused on building scalable data pipelines to bring medical device data to the cloud in order to enable analytics. Candidates must have significant experience working with life science data and must be familiar with life science areas such as\u00a0GMP and\u00a0medical device configuration.</p>\n<p>\u00a0</p>\n<p><strong>Technical requirements</strong></p>\n<ul>\n<li>Python</li>\n<li>Java</li>\n<li>IoT data systems (NiFi, MQTT or similar)</li>\n<li>GCP (Google Cloud Platform)</li>\n</ul>\n<p>\u00a0</p>\n<p><strong>Project details</strong></p>\n<ul>\n<li>Duration: 1 year</li>\n<li>Location: Remote-only</li>\n<li>Timezone: CET (GMT+2)</li>\n<li>Commitment: Full-time</li>\n</ul>\n<p>\u00a0</p>\n<p><strong>What does Sentium do?</strong></p>\n<p>Sentium is an explosive tech scale-up making a name for itself as an innovator in the big data and artificial intelligence analytics space. Founded as a challenger consultancy firm with a strong focus on Life Sciences and Finance, Sentium has delivered consistently successful projects ranging from building advanced predictive machine learning models, designing at-scale IoT data pipelines, international digital transformation initiatives and cutting-edge business intelligence development.</p>\n<p>In addition to consultancy, Sentium invests heavily into internal R&amp;D projects, developing proprietary innovations in the AI, BI and productivity spaces.</p>\n<p>\u00a0</p>\n<p><strong>What makes Sentium different?</strong></p>\n<p>Sentium has embraced the post-2020 new way of working and has thrived. While the core management team is based in London, Sentium is a remote-only company that enables it to draw upon a hugely diverse international talent pool. Sentium has team members from 4 continents and based in 8 different countries, and this blend of backgrounds and expertises leads to a collective depth of knowledge and experience that is unmatched. In its recruitment, Sentium prioritises rigorous knowledge and passionate, energetic attitudes resulting in a team rich in both academic qualifications and industry experience.</p>\n<p>\u00a0</p>\n<p>\u00a0</p>\n"}, {"id": 917317, "url": "https://remotive.io/remote-jobs/data/postgresql-data-consultant-aws-aurora-expert-917317", "title": "PostgreSQL Data Consultant - AWS Aurora expert", "company_name": "Sentium", "category": "Data", "tags": [], "job_type": "contract", "publication_date": "2021-10-09T13:54:09", "candidate_required_location": "CET (GMT+1)", "salary": "", "description": "<p><strong>Remote PostgreSQL\u00a0</strong><strong>Data Consultant with expertise in AWS Aurora</strong></p>\n<p>Sentium is looking for a senior data consultant to join an active consulting team. The project is a large-scale database migration for an international client in the petrochemical\u00a0industry. The consultant will be required to provide specialist expertise on an ongoing migration from MS SQL server to AWS Aurora cloud database. Key tasks will include performance optimization, database scripting and other specialised technical tasks</p>\n<p>\u00a0</p>\n<p><strong>Technical requirements</strong></p>\n<ul>\n<li>PostgreSQL (expert level)</li>\n<li>AWS</li>\n<li>AWS Aurora</li>\n</ul>\n<p>\u00a0</p>\n<p><strong>Project details</strong></p>\n<ul>\n<li>Duration: 1 year</li>\n<li>Location: Remote-only</li>\n<li>Timezone: CET (GMT+1)</li>\n<li>Commitment: Full-time</li>\n</ul>\n<p>\u00a0</p>\n<p><strong>What does Sentium do?</strong></p>\n<p>Sentium is an explosive tech scale-up making a name for itself as an innovator in the big data and artificial intelligence analytics space. Founded as a challenger consultancy firm with a strong focus on Life Sciences and Finance, Sentium has delivered consistently successful projects ranging from building advanced predictive machine learning models, designing at-scale IoT data pipelines, international digital transformation initiatives and cutting-edge business intelligence development.</p>\n<p>In addition to consultancy, Sentium invests heavily into internal R&amp;D projects, developing proprietary innovations in the AI, BI and productivity spaces.</p>\n<p>\u00a0</p>\n<p><strong>What makes Sentium different?</strong></p>\n<p>Sentium has embraced the post-2020 new way of working and has thrived. While the core management team is based in London, Sentium is a remote-only company that enables it to draw upon a hugely diverse international talent pool. Sentium has team members from 4 continents and based in 8 different countries, and this blend of backgrounds and expertises leads to a collective depth of knowledge and experience that is unmatched. In its recruitment, Sentium prioritises rigorous knowledge and passionate, energetic attitudes resulting in a team rich in both academic qualifications and industry experience.</p>\n"}, {"id": 918157, "url": "https://remotive.io/remote-jobs/data/data-analyst-looker-918157", "title": "Data Analyst (Looker)", "company_name": "Plentific", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-08T17:47:33", "candidate_required_location": "Europe Only", "salary": "", "description": "<p>Plentific is one of the fastest-growing property technology companies in the UK and Germany, with offices in the US and Turkey. Its mission is to improve lives by making property work better for everyone. The platform empowers landlords and property managers to manage their properties and internal trades workforce, source local trade talent, build community cohesion and provide better services than ever before. The end-to-end solution offers a flexible approach to compliance management, repairs reporting and delivery, ensuring landlords and property managers can be confident that their property meets necessary standards.</p>\n<p>Since 2013, Plentific has:</p>\n<ul>\n<li>Dramatically improved outcomes by speeding up service delivery fivefold and creating economic opportunities within local communities.</li>\n<li>Set a new industry benchmark on responsive repairs by reducing typical time frames (20 days) to less than 4 days.</li>\n<li>Entered partnerships with social enterprises to help people into trades jobs, and thus rebuild their lives.</li>\n</ul>\n<p>Plentific has been recognised by multiple awarding bodies since its inception, including:</p>\n<ul>\n<li>\u2018Deal of the Year - Residential\u2019 at the UK PropTech Awards 2018.</li>\n<li>\u2018Business Change/Transformation\u2019 Award at the UK Business Awards 2019.</li>\n<li>Recognised as \u2018Professional Services Partner\u2019 at the UK Housing Awards 2019.</li>\n<li>Repairs and Maintenance Provider of the Year at the 24Housing Awards 2019.</li>\n<li>Featured on the Deloitte Technology Fast 50 list 2020.</li>\n<li>Most Collaborative Business Award - PropTech at the UK Proptech Awards 2020.</li>\n</ul>\n<p>Following a major funding round, Plentific has recently expanded into the US multi-family market and has plans to enter the wider professional and commercial real estate sector in Europe this year.</p>\n<p>In sum, Plentific is a technology-led business developing cutting-edge solutions - and that\u2019s only possible to do with a great team. Our culture is open, empowering and fast-paced. If you\u2019re tenacious, passionate and driven, you will fit right in.</p>\n<p><a class=\"external\" href=\"http://plentific.com/careers\" rel=\"nofollow\">plentific.com/careers</a></p>\n<p><strong>The Role</strong></p>\n<p>We currently have a number of remote team members based in the UK, Germany, Turkey, Poland, Ukraine, Italy, Slovakia, Spain, Portugal and Romania.</p>\n<p>We\u2019re looking for a motivated data analyst to join our growing business. You will be reporting to the Data Engineering Tech Lead and support and work with the rest of the Data Engineering team and other company functions.</p>\n<p>We are growing fast and there is ample space for career development for motivated people. You\u2019ll be working alongside very technical and motivated teams. Working with a variety of internal teams, you\u2019ll have the freedom to analyse all aspects of our business in order to help various teams ensure we support our ever-growing user base. For people with the right mindset, this frame of mind provides an intellectually stimulating environment.</p>\n<p><strong>Responsibilities</strong></p>\n<ul>\n<li>Develop Looker reports for the various Plentific teams. You'll work both in the LookML code base as well as creating dashboards</li>\n<li>Liaise with the rest of company functions to understand user requirements and translate them into useful data models</li>\n<li>Have exposure to cutting-edge data-related software engineering areas like embedded analytics or machine learning</li>\n<li>Increase Plentific's users and decision-makers productivity by building innovative products and tools that reduce maintenance overheads and help drive platform adoption</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<ul>\n<li>Experience with Looker, SQL and Python. We perform a live coding interview.</li>\n<li>Experience with Git version control</li>\n<li>Previous knowledge of dbt is a plus</li>\n<li>You are an organised person who works well under pressure and with little direction</li>\n<li>Excellent communication skills with ability to articulate concepts in plain English</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<p>As you can see, we have big plans and are eager to grow our team of dreamers and doers to achieve our vision of managing over 1 million properties through our platform across various countries. You can help us shape the future of property management. Here\u2019s what we offer:</p>\n<ul>\n<li>A competitive compensation package</li>\n<li>Flexible working</li>\n<li>Learning and development fund</li>\n<li>An inherently diverse culture with over 18 nationalities and 21 languages spoken</li>\n</ul>\n"}, {"id": 912361, "url": "https://remotive.io/remote-jobs/data/head-of-data-science-912361", "title": "Head of Data Science", "company_name": "GoFormative", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-06T22:08:28", "candidate_required_location": "USA Only", "salary": "", "description": "<p>Formative is looking for an experienced Head of Data Science to lead a team at our rapidly growing organization. With access to millions of learning-related data points, and reporting directly to our c-suite, this is an opportunity to build the data science team at Formative from the ground up. You will oversee the end-to-end data and analytics across the product and revenue funnels here at Formative to drive strategic decisions across departments, and research to propel us towards achieving our goals.</p>\n<p><strong>You Will</strong></p>\n<ul>\n<li>Oversee the company-wide data strategy across product and revenue, implementing strategic solutions to large-scale long-term problems</li>\n<li>Build data teams and integrate them into an organization</li>\n<li>Collaborate across teams to understand complex problems and ascertain the value of a data solution</li>\n<li>Work hands-on to build and provide solutions - unencumbered by the technical complexity towards accessing new data within or outside of the organization, working with industry experts and academia to use latest technologies and techniques</li>\n<li>Communicate and present findings in a solution- and implementation-oriented approach to the end-users of the data product across our customers and functional business leaders across product, marketing, sales and customer success</li>\n</ul>\n<p><strong>Requirements</strong></p>\n<ul>\n<li>Advanced degree in Data Science/Analytics, Statistics, Mathematics, Computer Science, or equivalent field</li>\n<li>5+ years of relevant work experience across both product usage and revenue data.</li>\n<li>Implemented and scaled a data platform</li>\n<li>Experience developing and implementing strategy, especially in a startup where priorities evolve quickly with new information</li>\n<li>A clear passion for learning new technology independently</li>\n<li>Proficiency in SQL, Python, R, or Java</li>\n<li>Experience building and leading teams of data science, business intelligence, and machine learning professionals</li>\n<li>Must be able to explain technical concepts and analysis implications clearly to a wide audience, including senior executives, and be able to translate data products into action</li>\n</ul>\n<p><strong>Benefits</strong></p>\n<ul>\n<li>Fully Remote position within the US</li>\n<li>Health, dental, and vision insurance</li>\n<li>Health Savings Account and Flexible Spending Account</li>\n<li>Generous 401k Company Match</li>\n<li>Company stock ownership</li>\n<li>One-time $300 Home Office Stipend</li>\n<li>Flexible Paid Time Off</li>\n<li>Paid Parental Leave</li>\n<li>Paid Holidays</li>\n</ul>\n<p><strong>About Formative</strong></p>\n<p>Formative, is an all in one platform that helps educators capture student responses in real-time, to provide immediate feedback and track student progress. Used by 50K+ teachers and 1M+ students every week, Formative's mission is to empower educational partners to accelerate learning by eliminating the need for summative assessments. Today, teachers from over 10,000 school districts across the US and the world have signed up for Formative, driving thousands of learning institutions to upgrade to more powerful partner status. We are on a mission to bring this transformative learning approach to more teachers and students and to contribute to a stronger education system.</p>\n<p><em>At Formative, we celebrate diversity, equity, and inclusion. We aim to foster belonging and empowerment because we understand that every person brings a unique perspective &amp; experience. Our strength is in our promise, as we are committed to cultivating a diverse environment and being an equal opportunity employer without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.</em></p>\n<p><em>#LI-Remote</em></p>\n<p><br><br></p>\n"}, {"id": 911936, "url": "https://remotive.io/remote-jobs/data/project-manager-analytics-911936", "title": "Project Manager - Analytics", "company_name": "AdQuick", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-06T09:56:25", "candidate_required_location": "USA Only", "salary": "", "description": "<div class=\"h3\">Details</div>\n<ul><li>We're looking for an Analytics Account Manager to join our growing Analytics team!<ul><li>The Analytics Account Manager\u00a0will be responsible for managing the processes and clients for accurate data collection, processing, modeling, and analysis.\u00a0</li><li>The ideal candidate has a knack for seeing solutions in sprawling data sets and the business mindset to convert insights into strategic opportunities for our company.\u00a0</li><li>They will ensure data accuracy and consistent reporting by designing and creating optimal processes and procedures for analytics employees to follow.\u00a0</li></ul></li></ul>\n<div class=\"h3\">Responsibilities</div>\n<ul><li>Set up measurement for programmatic campaigns, including conversion tracking, lift studies, halo effect, etc.<ul><li>Web/App Attribution Dashboard</li><li>Mobile Retargeting (Classic, Programmatic)\u00a0</li><li>Brand Lift Study (Classic, Programmatic)\u00a0</li><li>Footfall Measurements</li><li>Retargeting</li><li>QR Codes\u00a0</li></ul></li><li>Define and lead the process for requesting measurement</li><li>Develop a successful measurement strategy for all campaigns\u00a0</li><li>Deliver insights to improve campaign performance\u00a0</li><li>Present metrics on measurements and develop benchmarks\u00a0</li><li>Present measurement results to clients and internal stakeholders\u00a0</li><li>Work with the marketing team to build attribution case studies</li><li>Work with Product Manager to improve the analytics offering\u00a0</li><li>Work with Engineers to troubleshoot issues</li></ul>\n<div class=\"h3\">Background</div>\n<ul><li>3+ years of agency or c / media planning/buying experience in an AM / Ad Ops role</li><li>Can write SQL queries\u00a0</li><li>Knowledge of the Programmatic space, experience in Programmatic DOOH is a plus</li><li>Strong interpersonal skills</li><li>Ideally located CST or EST</li></ul>\n<div class=\"h3\">You are</div>\n<ul><li>Customer obsessed and an expert in the customer experience: you are able to think ahead of your clients wants / needs and are able to quickly problem solve</li><li>Detail-oriented and have a proclivity to think ahead and outside of the box</li><li>Versatile and able to adapt in a rapidly-changing environment</li><li>Tech-savvy: you are considered a power-user of the platform and are able to demonstrate all aspects of the platform to customers</li><li>Scrappy: you're able to balance individual work, cross-team collaboration, and project management</li><li>Data-driven and analytical</li><li>Ambitious and a go-getter</li></ul>\n<div class=\"h3\">Company Description</div>\n<ul><li><strong>Build the operating system for Out-of-Home (OOH) Advertising</strong><ul><li>Simply put, AdQuick is the easiest way to buy outdoor advertising.\u00a0</li><li>Broadest selection of inventory \u2014 our technology builds campaigns based on every available ad location from the large media companies to the sole proprietors. AdQuick also has exclusive access to locations.</li><li>Fastest process \u2014 we're integrated with outdoor ad companies on the backend, so the buying process is seamless and single-threaded, no matter how many different billboard companies your campaign involves.</li><li>Data-driven \u2014 our campaign planning and post-campaign analytics make outdoor advertising more data-driven than it has ever been. See the attached breakdown of some of the metrics we provide to measure your outdoor ad spend. Here and here are posts explaining some of our analytics. Some of our customers include Instacart, Lyft, H&amp;R Block, and OVO music label and we've booked campaigns nationwide.</li></ul></li></ul>\n"}, {"id": 905767, "url": "https://remotive.io/remote-jobs/data/data-scientist-905767", "title": "Data Scientist", "company_name": "Hatch IT", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-10-03T21:52:28", "candidate_required_location": "USA Only", "salary": "", "description": "<div>Embedded Healthcare is seeking a Data Scientist for its Payer &amp; Provider Services Team. This team is responsible for designing, launching, and delivering client projects and deliverables.</div><div>The team works directly with researchers, data scientists, and experts to translate research into actionable strategies and designs for major payers and provider clients.</div><br><br><div class=\"h3\">Responsibilities</div><ul><li>Perform descriptive and advanced statistical analysis using large healthcare and administrative databases</li></ul><ul><li>Synthesize findings and package insights on client spending, utilization, quality, and specific clinical areas</li></ul><ul><li>Work with EHC product team to translate analytics processes to repeatable, scalable solutions</li></ul><ul><li>Collaborate with client services team, product team, researchers, and external stakeholders to navigate challenges</li></ul><ul><li>Facilitate/attend regular project meetings between EHC and client</li></ul><ul><li>Serve as client point of contact for data / statistical analysis workstreams and inputs</li></ul><ul><li>Support overall EHC methodology/strategy development</li></ul><br><br><div class=\"h3\">Qualifications</div><ul><li>2-3 years of experience in healthcare product development/refinement and delivery</li></ul><ul><li>Substantial programming experience in R and SQL</li></ul><ul><li>Additional familiarity with Python strongly preferred</li></ul><ul><li>Extensive experience with analytic work</li></ul><ul><li>Experience owning complex tasks/workstreams and leading others</li></ul><ul><li>Excellent verbal/written communications and executive presentation skills required</li></ul><ul><li>Passion for improving health care a must-- you will get to work alongside some of the country\u2019s leading health care experts.</li></ul><ul><li>Strong work ethic and entrepreneurial spirit \u2013 we are building a company from the ground up, so every team member is given a significant amount of responsibility and growth opportunity!</li></ul><ul><li>Masters degree in statistics, computer science, or similar field preferred/or equivalent experience</li></ul><div><b>If you are interested in learning more about this company or any Startups/Small Businesses in the area, please contact us and check us out </b><a class=\"postings-link\" href=\"https://dmv.myhatchpad.com/jobs/\" rel=\"nofollow\">here</a><b>!!</b>\u00a0</div><div><i>We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status</i></div><div><br></div>"}, {"id": 907764, "url": "https://remotive.io/remote-jobs/data/data-engineer-907764", "title": "Data Engineer", "company_name": "Indigov", "category": "Data", "tags": [], "job_type": "", "publication_date": "2021-10-01T18:05:28", "candidate_required_location": "USA Only", "salary": "", "description": "<div><b>What we\u2019re doing</b></div><div>Did you know it takes a congressional office, on average, 45 days to respond to the most basic constituent request? We view this as a fundamental breakdown in the UX of representative democracy and we're building a platform to fix it.</div><div><br></div><div>Indigov is a constituent relationship management suite for modern representatives. Our platform reduces response times from weeks to minutes for 90% of inbound communication. We spent two years going through an exhaustive technical and legal review process with House of Representatives and are now live in member offices. We are expanding rapidly and need additional team members to join us in our pursuit to build the future of representative democracy across federal, state, and local governments.</div><div><br></div><div><b>Who we are</b></div><div>We are a group of technologists and entrepreneurs passionate about increasing the efficiency of representative democracy for both representatives and those they serve. We have been executives, technicians, and leaders at institutions such as U.S. Congress, Google, Dropbox, USDS, as well as large e-commerce, digital-first media, civic and gov-tech companies.</div><div><br></div><div><b>What you'll do</b></div><div>\u2022\u00a0Data Engineer passionate about architecting and maintaining data pipelines, ingestion, optimization, collection, analysis, and normalization</div><div>\u2022\u00a0Ability to own the process and standards for our data ETL when working with our government partners</div><div>\u2022 Design system architecture in AWS</div><div><br></div><div><b>About you</b></div><div>\u2022 2- 4 years of data engineering experience, ideally at a fast-growing Saas Company</div><div>\u2022\u00a0Comfortable working in SQL and relational databases</div><div>\u2022 Some knowledge of query optimization, data compression and streaming techniques</div><div>\u2022 Experience building ETL and data pipelines, e.g. Airflow, Prefect, etc.</div><div>\u2022 General comfort developing in a well-documented service architecture</div><div>\u2022\u00a0Strong cross-functional communication skills</div><div>\u2022 Experience in tech startups is a plus</div><div><br></div><div><b>What makes an ideal candidate</b></div><div>\u2022 Passion for meaningfully fixing a core component of our democracy</div><div>\u2022 Accountability &amp; ownership. In a small team of early employees it is crucial that we all own the outcome and quality of our work. The buck always stops with you!</div><div>\u2022 Grit. Working with government can be challenging in ways that startups aren\u2019t, but the scale and importance of the problems we are solving more than make up for it. We are looking for folks that share that mentality.</div><div><br></div><div><b>Working at Indigov</b></div><div>\u2022 Competitive salary, equity, healthcare, and 401k</div><div>\u2022 High-degree of autonomy, flexible remote work, and unlimited PTO</div><div>\u2022 Drive technical direction of the company and help improve the efficacy of the U.S. government</div><div>\u2022 Equal opportunity employer</div>"}, {"id": 908061, "url": "https://remotive.io/remote-jobs/data/senior-analyst-customer-analytics-908061", "title": "Senior Analyst, Customer Analytics", "company_name": "Abercrombie and Fitch Co.", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-09-30T10:09:20", "candidate_required_location": "USA Only", "salary": "", "description": "<p><br><br></p>\n<div class=\"h3\">Company Description</div>\n<p>At Abercrombie &amp; Fitch, quality is in our roots and we\u2019re on a mission to honor this rich heritage. With an unwavering focus on our customer, we strive every day to deliver a unique and welcoming experience, whether in our stores or online. Our three global brands, Abercrombie &amp; Fitch, abercrombie kids and Hollister Co., are the embodiment of our passion for the incredible product. At the heart of it all is our amazing 500-acre campus, nestled just outside of Columbus, Ohio. With an open workspace, inspiring views, and even a place to gather as a team around the fire pit, our Home Office fosters a diverse and inclusive culture that consistently seeks the input of our associates and focuses on the future. We are looking for leaders, visionaries, and creatives who are willing to roll up their sleeves and write the next chapter in our brand\u2019s legacy.</p>\n<p>The Customer Analytics role is within A&amp;F Global Data &amp; Analytics team. Primary responsibilities are to monetize our customer data warehouse thru in-depth customer &amp; campaign analyses, incorporate new data types &amp; sources into existing data structures, and develop actionable data insights that drive the company\u2019s bottom line. This role would closely partner with our Marketing / Loyalty / Merchandising / Operations teams to help support their customer analytics/reporting and segmentation needs. Bring passion for learning and data-informed decision making that shapes holistic view of our business with consideration for all aspects of the customer experience - from front-end web &amp; store experience through order fulfillment and customer service.</p>\n<p><strong>What will you be doing?</strong></p>\n<ul>\n<li>Drive partnership, collaboration, and process optimization with strategic partners to deliver the best insights for strategy and program development.</li>\n<li>Help manage brand-specific queue, driving productivity and streamlining asks/ processes to reduce redundancies</li>\n<li>Help guide greener analysts with technical direction, business objectives/ connectivity and storytelling</li>\n<li>Collaborate with CRM vendor, and internal data ops, strategy, and analytics teams to deliver turn-key reporting, build dashboards, and democratize data and insights across the org.</li>\n<li>Analyze customer file, loyalty program performance and campaign results to develop insights and recommendations to drive business strategy and marketing effectiveness</li>\n<li>Communicate and present insights &amp; conclusions to stakeholders in non-technical language; be an evangelist of data-informed decision making and consistently identify new ways to leverage data and analysis.</li>\n<li>Identify synergies and connect dots on disparate customer analytics projects in terms of data, methodologies, processes &amp; insights</li>\n<li>Ideate and design recurring reports/dashboards to identify ongoing trends, diagnose drivers for growth/decline and recommend opportunities for improvement</li>\n<li>Inform, analyze and recommend optimizations for email &amp; push marketing campaigns, designed to reduce churn, drive loyalty and increase revenue</li>\n<li>Identification of target audiences by working cross-functionally with internal teams and agency to gather insights which will improve targeting efforts and generate buy-in for targeting decisions</li>\n<li>Ensure all campaigns are set up and executed according to appropriate specifications and rules\u00a0</li>\n<li>Establish and track ongoing success metrics for various customer marketing initiatives and relate them to return on investment</li>\n<li>Identify &amp; resolve data quality issues within customer database</li>\n</ul>\n<p><strong>What will you need to bring?</strong></p>\n<ul>\n<li>Bachelor's degree in Data Analytics, Statistics, Mathematics, Computer Science, Social Sciences, Information Systems or related quantitative field required; advanced degree preferred</li>\n<li>Proficiency with SQL, R and/or Python, and Tableau</li>\n<li>3-5\u00a0years of customer or marketing analytics; database experience, with a successful track record, either in-house or at an agency/consultancy ideal</li>\n<li>Strong analytical skills,\u00a0data interpretation, and\u00a0problem-solving\u00a0skills</li>\n<li>Strong written, verbal and interpersonal communication skills</li>\n<li>Excellent attention to detail</li>\n<li>Ability to work under pressure to tight deadlines</li>\n<li>Ability to work independently and efficiently with minimal supervision</li>\n<li>Strong project management and inter-departmental coordination skills</li>\n<li>Highly motivated with ability to thrive in a fluid and demanding environment</li>\n</ul>\n<p><strong>OUR COMPANY</strong><br>Abercrombie &amp; Fitch Co. is a portfolio of lifestyle brands including Abercrombie &amp; Fitch, abercrombie kids, Hollister, and Gilly Hicks. Reaching customers across 120+ countries, we strive to create customer-centric, omni-channel experiences for our global customer base.</p>\n<p><strong>OUR VALUES</strong><br>How do we do it? Every day, our associates show up and empower one another to stay curious and think big. As a team of relentless innovators, we aren\u2019t afraid to dream boldly. We are accountable and aim to the highest caliber to understand, push boundaries and embrace change. We coach, mentor, care, and bring our best selves every day because we are in this together. Whether you lead yourself, a team, or the company, everyone is a leader at A&amp;F.\u00a0</p>\n<p><br><br></p>\n<div class=\"h3\">Job Description</div>\n<p><br><br></p>\n<div class=\"h3\">Qualifications</div>\n<p><br><br></p>\n<div class=\"h3\">Additional Information</div>\n<p>ABERCROMBIE &amp; FITCH CO. IS AN EQUAL OPPORTUNITY EMPLOYER</p>\n<p><em>This position is not open to applicants residing in or otherwise based in the State of Colorado.\u00a0 The work location is flexible if approved by the Company, except that the position may not be performed remotely from within the State of Colorado.</em></p>\n"}, {"id": 907836, "url": "https://remotive.io/remote-jobs/data/bi-sisense-reporting-engineer-907836", "title": "BI Sisense Reporting Engineer", "company_name": "SplashFinancial", "category": "Data", "tags": [], "job_type": "", "publication_date": "2021-09-29T09:45:35", "candidate_required_location": "USA Only", "salary": "", "description": "<div><span style=\"font-size: 15px;\">At Splash Financial, we believe people pay too much for their financial products while also suffering through long application and approval processes. So we created a better, faster, and cheaper way.</span></div>\n<div>\u00a0</div>\n<div>Splash is a leading digital lending platform that helps borrowers easily shop and compare financial products from a Splash-powered network of credit union and bank partners. Recently named among the top 250 private FinTech companies in the world by CB Insights, Splash\u2019s unique hybrid marketplace model and automated underwriting platform has helped the average person refinancing their student loans save thousands.</div>\n<div>\u00a0</div>\n<div>Splash Financial's Data team builds the data infrastructure and platform for reporting and analytics. The Data team is part of the engineering organization and uses engineering fundamentals to build solutions that deliver excellent value for the Splash business teams in finance and marketing. As a BI Engineer, you work with cross-functional teams\u2019 members, across business, product, engineering, machine learning, marketing, and other stakeholders, driving projects from conception to launch, to help team leverage data to make better decisions for the Splash business. The role is remote, and the team operates on Eastern time zone.</div>\n<p><br><br></p>\n<div class=\"h3\">What you'll do:</div>\n<ul>\n<li>Collaborating closely with analysts, data engineers, products managers, marketers, and financial analysts to deeply understand their problems and goals, and then design and prioritize solutions to help achieve those goals</li>\n</ul>\n<ul>\n<li>Lead strategy and execution of our analytics roadmap with the goal of scaling our data products to be more accessible, self-serve, reliable, and digestible for all employees across the company</li>\n</ul>\n<ul>\n<li>Architect, build and launch efficient &amp; reliable data models and pipelines in partnership with Data Engineering</li>\n</ul>\n<ul>\n<li>Recommend, develop and implement best practices for reporting, analytics, and generation of key metrics needed to report on the productivity and business performance</li>\n</ul>\n<ul>\n<li>Ability to develop and generate reports and dashboards as required by business stakeholders using Sisense</li>\n</ul>\n<ul>\n<li>Monitor and report on KPIs that measure the success of our data products</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">What you'll need:</div>\n<ul>\n<li>Bachelor\u2019s degree or equivalent required from an accredited institution.</li>\n</ul>\n<ul>\n<li>At least 6-10 years of experience in Information Technology especially with data modeling, data warehousing in cloud, SQL, snowflake, and data visualization tools</li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\">What makes you stand out:</div>\n<ul>\n<li>Strong 5+ years\u2019 experience working on BI -reporting tools like Tableau, PowerBI or Microstrategy, etc. Strong hands-on experience on Sisense reporting is a major plus</li>\n</ul>\n<ul>\n<li>Proven experience working on data and data modeling</li>\n</ul>\n<ul>\n<li>Very strong in SQL, and visualization skills</li>\n</ul>\n<ul>\n<li>Experience preferred but not required with a data build tool (dbt <a href=\"http://getdbt.com\" rel=\"nofollow\">getdbt.com</a>) open-source CLI tool and dbt cloud. dbt is our tool of choice for all SQL development, GitHub integration, and deployment to Snowflake</li>\n</ul>\n<ul>\n<li>Experience with GitHub and CI/CD process is a must-have</li>\n</ul>\n<ul>\n<li>5+ years experience in database technologies. It is required to have experience in Cloud DWH preferably Snowflake as it is our cloud data warehouse</li>\n</ul>\n<ul>\n<li>Work in a fast-paced, creative atmosphere to develop new ideas that adapt to evolving user needs</li>\n</ul>\n<ul>\n<li>Strong visual and verbal communication skills.\uf0b7Excellent communication skills.\uf0b7Analytical skills.</li>\n</ul>\n<ul>\n<li>Experience and desire to work in fast paced startup environment and therefore be able to handle ambiguity and add definition to it.</li>\n</ul>\n<ul>\n<li>Experience working with financial and/or marketing data is a huge plus</li>\n</ul>\n<ul>\n<li>Support User Acceptance Testing by addressing any technical queries or fixing the bug</li>\n</ul>\n<div>Employment at Splash is based on individual merit. Opportunities are open to all, without regard to race, color, religion, sex, creed, age, handicap, national origin, ancestry, military status, veteran status, medical condition, marital status, sexual orientation, affectional preference, or other irrelevant factors.\u00a0Splash is an equal opportunity employer.</div>\n<div>\u00a0</div>\n"}, {"id": 908152, "url": "https://remotive.io/remote-jobs/data/senior-data-scientist-m-f-d-908152", "title": "Senior Data Scientist (m/f/d)", "company_name": "Sellics", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-09-28T05:53:27", "candidate_required_location": "Germany Only", "salary": "", "description": "<p><strong>The high level goal is to help merchants across the world advertise on Amazon in the simplest and the most efficient way. For this we need you to improve our conversion rate prediction modelling, time series forecasting, products clustering and much more.\u00a0</strong></p>\n<p><strong>You will be</strong></p>\n<ul>\n<li>\n<p>Selecting features, building and optimizing classifiers using machine learning techniques</p>\n</li>\n<li>\n<p>Doing data mining using state-of-the-art methods</p>\n</li>\n<li>\n<p>Processing, cleansing, and verifying the integrity of data used for analysis</p>\n</li>\n<li>\n<p>Performing ad-hoc analysis to show Sellics\u2019 expertise with Amazon advertising</p>\n</li>\n</ul>\n<p>\u00a0</p>\n<div><strong><strong>Your background and experience that makes you a good fit for this job:</strong></strong></div>\n<ul>\n<li>\n<p>A relevant PhD / MSc in Computer Science, Maths, Stats or a related area</p>\n</li>\n<li>\n<p>Excellent understanding of machine learning techniques and algorithms, such as LASSO, Decision Forests, NN etc.</p>\n</li>\n<li>\n<p>Excellence with Python</p>\n</li>\n<li>\n<p>Proficiency in using query languages such as SQL or Postgres</p>\n</li>\n<li>\n<p>Good applied statistics skills, such as distributions, statistical testing, regression, etc.</p>\n</li>\n</ul>\n<p><strong>Why Sellics?</strong></p>\n<ul>\n<li>\n<p>A very well located office in the heart of Berlin Mitte incl. a rooftop terrace with pool</p>\n</li>\n<li>\n<p>Flexible office hours</p>\n</li>\n<li>\n<p>Flat hierarchies with open communication</p>\n</li>\n<li>\n<p>High level of responsibility and space to develop</p>\n</li>\n<li>\n<p>Urban Sports Club membership</p>\n</li>\n<li>\n<p>Self Improvement Grant</p>\n</li>\n<li>\n<p>Free food and drinks, regular team events</p>\n</li>\n<li>\n<p>Participation in our annual company trip - this year, we've been to Lisbon!</p>\n</li>\n</ul>\n"}, {"id": 909573, "url": "https://remotive.io/remote-jobs/data/facilitator-data-digital-909573", "title": "Facilitator - Data & Digital", "company_name": "decoded", "category": "Data", "tags": [], "job_type": "freelance", "publication_date": "2021-09-28T05:53:23", "candidate_required_location": "EST + 2 time zones", "salary": "", "description": "<p dir=\"ltr\"><strong>ABOUT DECODED</strong></p>\n<p dir=\"ltr\">We are Decoded and we make technology education human. We help some of the largest and most technologically progressive organizations in the world up-skill and inspire their employees through training programs and workshops. Our mission is to be the world\u2019s greatest technology educator, and to change the way people interact with technology. Curious about our style of teaching? <a href=\"https://www.youtube.com/watch?v=wZprwYTXf6s\" rel=\"nofollow\" target=\"_blank\">Check out our Demystifying the Digital World talk</a>\u00a0to get a taste of how we do, what we do.</p>\n<p><strong>\u00a0</strong></p>\n<p><strong>OVERVIEW</strong><br>Our Data &amp; Digital Leadership Facilitators run short-form workshops in Data Science, Cybersecurity and Programming. You will work with senior leaders from every sector, helping shape their understanding of technology and ability to effectively engage with technical teams.\u00a0You can work remotely from anywhere in the EST + 2 time zones.\u00a0</p>\n<p dir=\"ltr\">\u00a0</p>\n<p dir=\"ltr\">When applying please bear in mind the following:</p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\">We work in an area flooded with tech buzzwords (e.g. AI, machine learning, blockchain) \u2014 in your application show us how you would explain a buzz-wordy term to a room full of people that \u2018get it\u2019 but might have never \u2018done it.\u2019</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">We really enjoy videos, and portfolios of work that show us your skills (make it fun)</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">We deliver training that is technology and innovation focused \u2014 see if your application can reflect this</p>\n</li>\n</ul>\n<p><strong>ESSENTIALS</strong></p>\n<p dir=\"ltr\">As a Data Facilitator at Decoded, you\u2019re ultimately accountable for:</p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Delivering our productized workshops to learners, usually alongside a co-facilitator</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Contextualizing our varied content to specific clients and sectors</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Acting on feedback from peers, learners and the Decoded team</p>\n</li>\n</ul>\n<p dir=\"ltr\"><strong>\u00a0</strong></p>\n<p dir=\"ltr\"><strong>SPECIFIC ROLE &amp; RESPONSIBILITIES</strong></p>\n<p dir=\"ltr\"><strong>Preparation</strong></p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Reviewing exercises and other learning materials before a session</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Learning about your learners and the businesses they work for</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Familiarizing yourself with the course structure and content, proactively filling gaps in your knowledge</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Self assessing your skills and taking up suitable training and professional development opportunities</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Preparing the virtual learning environment: virtual room setup, laptop setup and other tasks as required</p>\n</li>\n</ul>\n<p dir=\"ltr\"><strong>Delivery</strong></p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Delivering a 10/10 learning experience in each workshop</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Communicating complex technical\u00a0concepts and techniques with energy, focus and patience</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Engaging and captivating the attention of a room of busy working professionals</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Collaborating with your co-facilitator to give each session a consistent and balanced pace and tone</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Handling and resolving challenging learning moments with learners</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Facilitating the learning journey for your audience, and leaving no-one behind whilst also providing stimulation for advanced learners</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Enabling an inclusive, collaborative and respectful learning environment</p>\n</li>\n</ul>\n<p dir=\"ltr\">\u00a0</p>\n<p dir=\"ltr\"><strong>\u00a0</strong></p>\n<p dir=\"ltr\"><strong>WHO ARE YOU?</strong></p>\n<p dir=\"ltr\">You are comfortable public speaking and educating any audience \u2014 from teenagers to CEOs. You are confident in your skills at communicating data, coding or cybersecurity related sessions. You are in love with technology and learning.<br><br>Our Facilitators are a community of technology education superstars. They are confident yet humble, and are passionate about giving their learners confidence in the skills required for the future of work. They are founders and entrepreneurs. Physicists and philosophers. Technologists who believe in human potential. Data Scientists that love stories.</p>\n<p dir=\"ltr\">Whatever their background, they are always:</p>\n<ul>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Empathetic</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Obsessed about learning and teaching</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Programming literate</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Curious about new technologies</p>\n</li>\n<li dir=\"ltr\">\n<p dir=\"ltr\">Critical thinkers</p>\n</li>\n</ul>\n<div><strong>\u00a0</strong></div>\n<div><strong>TEAM REPORTING AND STRUCTURE</strong><br>You will be allocated work and supported by the Facilitator Manager and Product team.</div>\n<p>\u00a0</p>\n<p><strong>DAY TO DAY</strong></p>\n<p dir=\"ltr\">Monthly, you'll provide your availability and you will be allocated a varying amount of work by the Facilitation Manager depending on Decoded\u2019s delivery needs, which you can accept or reject. <em>Please note</em> - The amount of work available may vary widely and is not guaranteed.</p>\n<p>\u00a0</p>\n<p><strong>INTERVIEW PROCESS</strong></p>\n<ol>\n<li><strong>Recruiter Chat:</strong> You\u2019ll speak to our people team about your professional experience, while learning about the role and Decoded.</li>\n<li><strong>Content Delivery Prep:</strong> You'll prepare a 10 minute presentation of Decoded content to familiarize yourself with our style of presenting.</li>\n<li><strong>Lightening Talk Delivery: </strong>Once prepped, you'll present it back to the team, with time afterwords for a Q&amp;A for us to learn more about you and you to learn more about the team.</li>\n</ol>\n<div>\u00a0</div>\n"}, {"id": 908443, "url": "https://remotive.io/remote-jobs/data/data-scientist-908443", "title": "Data Scientist", "company_name": "Recurrency", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-09-26T21:47:46", "candidate_required_location": "USA Only", "salary": "", "description": "<div><span style=\"font-size: 12pt; font-family: 'times new roman', times, serif;\">Recurrency is building the automated enterprise. Our product is the world's first enterprise optimization system (EOS), a machine learning application that integrates with legacy enterprise resource planners (ERP) like SAP, Oracle, Microsoft Dynamics, or Epicor, and provides the user with the flows and recommendations on how to better buy, manage, price, and sell their inventory. Our customers are wholesalers and distributors, ranging from family-owned companies to the Fortune 500.</span></div>\n<div>\u00a0</div>\n<div><span style=\"font-size: 12pt; font-family: 'times new roman', times, serif;\">Despite being a multi-trillion dollar industry, wholesale distribution has a striking lack of software to support even basic operations, with most ERPs relying on decades-old architecture. Founded in Los Angeles and supporting a fully-remote team across the US, we are a well-funded Series A-stage startup, backed by some of the most successful VCs in the world.</span></div>\n<div>\u00a0</div>\n<div><span style=\"font-size: 12pt; font-family: 'times new roman', times, serif;\">As a Data Scientist, you will leverage existing knowledge in Machine Learning and Big Data to build and deploy the models that drive key business insight for our customers. As one of the founding members of our team, you'll be engineering the next-generation data science features for the world-wide supply chain. Our team does it all - and you will be a core contributor - designing, testing, and deploying a system of bleeding edge Machine Learning models, preparing data and engineering features, tracking metrics, maintaining the health of our code, and continually growing as an engineer and researcher. The ideal candidate is both forward-thinking and hands-on, has a strong sense of ownership and drive for delivery, and is a good mentor and co-worker. At Recurrency, we pride ourselves on the collaboration between Product, Design, and Engineering and so you have the opportunity to be involved in the entire product lifecycle, from ideation through building, deploying, and continual improvement and evolution.</span></div>\n<p><br><br></p>\n<div class=\"h3\"><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">What you will own:</span></div>\n<ul>\n<li><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">Develop forecasting, recommendation, and pricing models to improve the quality of wholesale distribution systems.</span></li>\n</ul>\n<ul>\n<li><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">Feature engineering and data pipeline design.</span></li>\n</ul>\n<ul>\n<li><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">Metrics building and monitoring.</span></li>\n</ul>\n<ul>\n<li><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">Work with our Engineers and Product team to build and improve efficient data products.</span></li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\"><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">What you will bring on Day 1:</span></div>\n<ul>\n<li><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">MS or PhD in Data Science, Computer Science, Math or related field.</span></li>\n</ul>\n<ul>\n<li><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">3+ years research experience in Machine Learning.</span></li>\n</ul>\n<ul>\n<li><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">Knowledge in forecasting, recommendation, or pricing is a plus.</span></li>\n</ul>\n<ul>\n<li><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">1+ years in a Data Science, Machine Learning or related role.</span></li>\n</ul>\n<ul>\n<li><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">Fluency in Python and PyTorch.</span></li>\n</ul>\n<ul>\n<li><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">Previous experience with databases (Postgres or MongoDB) and Cloud technology stacks (AWS, etc).</span></li>\n</ul>\n<ul>\n<li><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">Foundation in data structures, algorithms, and software design with strong analytical and debugging skills.</span></li>\n</ul>\n<ul>\n<li><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">Strong interpersonal, communication, and collaboration skills with great problem solving abilities.</span></li>\n</ul>\n<ul>\n<li><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">A desire to be part of a diverse and growing team.</span></li>\n</ul>\n<p><br><br></p>\n<div class=\"h3\"><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">Nice-to-haves, which we're sure you'll pick up along the way:</span></div>\n<ul>\n<li><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">Experience with Docker, Airflow, ECS</span></li>\n</ul>\n<div>\u00a0</div>\n<div>\u00a0</div>\n<div><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\">#LI-Remote</span></div>\n<div>\u00a0</div>\n<div><span style=\"font-size: 12pt; font-family: 'times new roman', times, serif;\">Recurrency is a fully-remote team, with team members located throughout the US. While it will never be a requirement, there is a high likelihood that we will eventually develop a bi-coastal office presence, centered around Los Angeles &amp; NYC, for those who prefer in-person to remote work.</span></div>\n<div>\u00a0</div>\n<div><span style=\"font-family: 'times new roman', times, serif; font-size: 12pt;\"><em>Recurrency celebrates and embraces diversity and is committed to building a team that represents a variety of experiences, backgrounds, and skills. We do not discriminate on the basis of race, color, religion, marital status, age, gender identity, gender expression, sexual orientation, non-disqualifying physical or mental disability, national origin, veteran status, or other applicable legally protected characteristics.</em></span></div>\n"}, {"id": 900596, "url": "https://remotive.io/remote-jobs/data/senior-toolkit-engineer-database-900596", "title": "Senior Toolkit Engineer - Database", "company_name": "Timescale", "category": "Data", "tags": [], "job_type": "", "publication_date": "2021-09-25T17:52:48", "candidate_required_location": "Anywhere", "salary": "", "description": "<p>We need extraordinary engineers to join our team in building and expanding the TimescaleDB Toolkit, an extension to ease working with time-series data in TimescaleDB. You will have the opportunity to work with a close-knit team developing SQL functions to ease statistical analysis, data visualization, and general quality-of-life. This role will involve working with a broad range of functionality in a rapidly-moving setting with all development done in the open and visible to users. We primarily work in Rust and SQL.</p>\n<p>Timescale is an all-remote organization, with team members across 6 continents; this is a full-time position and can be located anywhere across a wide range of time zones and locations. English fluency is required, however.</p>\n<div class=\"h3\"><strong>Responsibilities</strong></div>\n<ul>\n<li>Play a core role in helping to design and develop new database capabilities, with a focus on analytics.</li>\n<li>Develop, test, and release new features and functionality from our technical roadmap.</li>\n<li>Continually improve, optimize, and test existing functionality in the Toolkit.</li>\n<li>Work with engineers both at Timescale and the open-source community to coordinate new functionality and deliver powerful integrations of the database into large applications and pipelines.</li>\n<li>Work with our users to understand their needs and ways to improve their experience.</li>\n<li>Be an enthusiastic and personable teammate, receiving and providing code reviews, and otherwise partnering and helping other engineers.</li>\n</ul>\n<div class=\"h3\"><strong>Requirements</strong></div>\n<ul>\n<li>Bachelor\u2019s degree in computer science or equivalent experience.</li>\n<li>5+ years engineering experience.</li>\n<li>Expertise building industrial-strength software in Rust, C, or C++.</li>\n<li>Ability to understand new algorithms.</li>\n</ul>\n<div class=\"h3\"><strong>Preferred</strong></div>\n<ul>\n<li>Experience in developing statistics or graphics toolkits</li>\n<li>Experience with mentoring and developing junior engineers.</li>\n<li>Experience with Rust</li>\n<li>Experience with SQL databases or analytics</li>\n</ul>\n<div class=\"h3\"><strong>About Timescale\u00a0</strong></div>\n<p>At Timescale, we are dedicated to serving developers worldwide, enabling them to build exceptional data-driven products that measure everything that matters: software applications, industrial equipment, financial markets, blockchain activity, consumer behavior, machine learning models, climate change, and more. Analyzing this data across the time dimension (\u201ctime-series data\u201d) enables developers to understand what is happening right now, how that is changing, and why that is changing. Timescale develops TimescaleDB, the category-defining open-source relational database for time-series data, and offers fully-managed TimescaleDB and related database services. Timescale is a remote-first company with a global workforce and is backed by Benchmark Capital, New Enterprise Associates, Redpoint Ventures, Icon Ventures, Two Sigma Ventures, and other leading investors.</p>\n"}, {"id": 902702, "url": "https://remotive.io/remote-jobs/data/senior-data-engineer-902702", "title": "Senior Data Engineer", "company_name": "GumGum", "category": "Data", "tags": [], "job_type": "", "publication_date": "2021-09-23T05:46:23", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>Summary</strong></p>\n<p>GumGum is a global technology and media company specializing in contextual intelligence. For over a decade, we have applied our proven machine learning expertise to extract value from digital content for the advertising industry. The company\u2019s contextual advertising engine, Verity\u2122, comprehends the meaning of text, images and video online, allowing marketers to safely and precisely place ads where people are most engaged. Combining that contextual targeting and brand safety intelligence with proprietary high-impact ad formats, GumGum\u2019s advertising solutions deliver industry leading efficiency, accuracy and performance.</p>\n<p>The <strong>Senior Data Engineer</strong> is responsible for building and maintaining our Data Engineering systems that drive numerous business functions using near real-time data analytics solutions. This role has a core focus on improving performance and scalability of key Data Engineering systems that are essential for operating our advertising business.</p>\n<p>Engineering team members at GumGum are encouraged to share ideas which can often influence system decisions. The person in this role will need to stay relevant and up to date with state-of-the-art technology. Reporting to our Engineering Manager, this role works as part of a team of engineers in the technology division of our Advertising business.</p>\n<p><strong>Responsibilities</strong></p>\n<ul>\n<li>Build, maintain, and improve our data infrastructure which currently handles billions of advertising events every hour</li>\n<li>Design and implement streaming and batch pipelines for data ingestion and delivery</li>\n<li>Curate a data warehouse for business and technical stakeholders</li>\n<li>Contribute to GumGum\u2019s proprietary machine learning forecasting systems</li>\n<li>Develop scripts and APIs that serve internal and external reporting needs</li>\n<li>Investigate and test the capabilities of emerging data technologies</li>\n<li>Collaborate regularly with cross-functional teams\u00a0</li>\n<li>Lead design for medium to large projects with feedback from other engineers - have an architectural perspective.</li>\n<li>Mentor a diverse team of junior and intermediate engineers, both remote and in our Santa Monica office</li>\n</ul>\n<p><strong>Minimum Qualifications</strong></p>\n<ul>\n<li>Bachelor's degree in Computer Science, Engineering, or a related technical field</li>\n<li>4+ years of data engineering or software engineering required</li>\n<li>4+ years building data applications in Scala, Java, and Python required</li>\n<li>Proficient with distributed data processing with Apache Spark\u00a0</li>\n<li>Proficient with SQL and modern data warehouse platforms - Snowflake, Redshift, Big Query, or Synapse\u00a0</li>\n<li>Proficient with workflow management platforms - Airflow, AWS Data Pipeline, Luigi, or Prefect</li>\n<li>Experience designing data models, warehouses, and ETL pipelines\u00a0</li>\n<li>Experience working with streaming technologies is a plus</li>\n<li>2+ years AWS experience required</li>\n<li>Strong communication skills to effectively collaborate with engineers, project managers, and business stakeholders</li>\n<li>Track record of showing initiative and leading difficult data projects</li>\n<li>Deliberate approach to exploring and testing new technologies</li>\n<li>Designs applications and systems with longevity\u00a0 in mind (e.g. scaling, maintenance, reuse, etc.)</li>\n<li>Able to consider and synthesize multiple perspectives and opinions when deciding direction of a project or feature</li>\n</ul>\n<p><strong>Benefits &amp; Perks</strong></p>\n<ul>\n<li>Competitive health, vision and dental benefits</li>\n<li>Healthcare including 100% coverage for Employee + Spouse/family\u00a0</li>\n<li>Dependent care FSA</li>\n<li>Employer-matched 401(k) plan</li>\n<li>Stock incentive program <em>(role dependent)</em></li>\n<li>Paid parental leave</li>\n<li>Goodly - student loan contribution plan</li>\n<li>WFH monthly stipend\u00a0</li>\n<li>Anniversary recognition and awards</li>\n<li>Fitness reimbursement and wellness workshops</li>\n<li>Discounted Pet Health Program</li>\n<li>Flexible time off and work schedule</li>\n<li>Dog-friendly HQ office - we love our fur babies! Check us out on Instagram @dogsofgumgum</li>\n<li>Incredible work/life balance with a collaborative and friendly work space</li>\n<li>A team that has transitioned to remote work impressively, and remains highly collaborative and connected</li>\n<li>GumGum Gives Back volunteering opportunities</li>\n<li>Team building lunches and events, and monthly company celebrations</li>\n<li>Virtual monthly team bonding events</li>\n</ul>\n<p><strong>Career &amp; Development Focus</strong></p>\n<ul>\n<li>Ongoing learning and development for education opportunities such as webinars, books, classes, relevant conferences and events</li>\n<li>Opportunities to pursue business related side projects and yearly Hackathon</li>\n<li>Highly encouraged to contribute to open source software, including our own open source software</li>\n<li>Environment of learning from peers, including meetups, presentations and blog posts</li>\n<li>Opportunity to work with cutting edge technology</li>\n<li>Life Skills sessions - geared towards the whole life/health/person</li>\n<li>Leadership Bites Dinner Series - connecting current and future GumGum leaders over great food and meaningful conversation\u00a0</li>\n<li>Stride - our company council committee to share learnings, give updates and provide feedback to the company regarding initiatives and discussions around diversity, inclusion and equity.</li>\n</ul>\n<p><strong>Return to office: Our big vision for our futuristic \u201cFarmhouses\u201d in 2022!</strong></p>\n<ul>\n<li>Offices will now be referred to as the \u201cGumGum Farmhouse\u201d -- a futuristic space centered around a bigger purpose: flexibility, sustainability, community, and growth!</li>\n<li><strong>GumGum will continue to be a flexible/remote-friendly environment</strong>, however, offices will re-open in 2022 for any employees who choose to come in to collaborate, participate in an event, host your clients, contribute to our growing of plants/herbs/vegetables/etc.</li>\n</ul>\n<p><strong><em>Our Values\u2026</em></strong></p>\n<p><em>Thoughtful\u2026</em>We listen to understand different perspectives, show everyone respect, and relentlessly seek solutions for our clients (internal and external)</p>\n<p><em>Agility</em>\u2026We are quick, nimble, and change direction gracefully, while maintaining control.</p>\n<p><em>Grit</em>\u2026We bring energy and perseverance to everything we do.</p>\n<p><strong><em>Our Culture...</em></strong></p>\n<p>GumGum recently earned LA\u2019s Best Places to Work Award in 2021 by BuiltInLA, and Inc. Magazine\u2019s Best Places to Work in 2020 and it\u2019s no surprise why. With company-sponsored social hours, annual holiday celebrations and on-site gatherings, GumGummers enjoy a fun, creative and collaborative workplace. We provide ourselves on our strong track record of giving employees the autonomy and support they need to succeed.\u00a0</p>\n<p>Check us out on Instagram: @gumgum</p>\n"}, {"id": 902700, "url": "https://remotive.io/remote-jobs/data/data-engineer-902700", "title": "Data Engineer", "company_name": "GumGum", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-09-22T09:44:48", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>Summary</strong></p>\n<p>GumGum is a global technology and media company specializing in contextual intelligence. For over a decade, we have applied our proven machine learning expertise to extract value from digital content for the advertising industry. The company\u2019s contextual advertising engine, Verity\u2122, comprehends the meaning of text, images and video online, allowing marketers to safely and precisely place ads where people are most engaged. Combining that contextual targeting and brand safety intelligence with proprietary high-impact ad formats, GumGum\u2019s advertising solutions deliver industry leading efficiency, accuracy and performance.</p>\n<p>The <strong>Data Engineer</strong> is responsible for building and maintaining our Data Engineering systems that drive numerous business functions using near real-time data analytics solutions. This role has a core focus on improving performance and scalability of key Data Engineering systems that are essential for operating our advertising business.</p>\n<p>Behind the scenes, the Data Engineer will be working with large datasets at the scale of billions of events each hour so it is important that the person in this role is comfortable working with distributed computing in a highly scalable, cloud-based environment. Reporting to our Engineering Manager, this role works as part of a team of engineers in the technology division of our Advertising business.</p>\n<p><strong>Responsibilities</strong></p>\n<ul>\n<li>Build, maintain, and improve our data infrastructure which currently handles billions of advertising events every hour</li>\n<li>Implement and maintain streaming and batch pipelines for data ingestion and delivery</li>\n<li>Curate a data warehouse for business and technical stakeholders</li>\n<li>Contribute to GumGum\u2019s proprietary machine learning forecasting systems</li>\n<li>Develop scripts and APIs that serve internal and external reporting needs\u00a0</li>\n<li>Investigate and test the capabilities of emerging data technologies</li>\n<li>Collaborate regularly with cross-functional teams</li>\n</ul>\n<p><strong>Minimum Qualifications</strong></p>\n<ul>\n<li>Bachelor's degree in Computer Science, Engineering, or a related technical field</li>\n<li>2+ years of data engineering or software engineering experience\u00a0</li>\n<li>2+ years building data applications in Scala, Java, and Python\u00a0</li>\n<li>Proficient with distributed data processing with Apache Spark\u00a0</li>\n<li>Experience with SQL and modern data warehouse platforms - Snowflake, Redshift, Big Query, or Synapse</li>\n<li>Experience with workflow management platforms - Airflow, AWS Data Pipeline, Luigi, or Prefect</li>\n<li>Experience designing data models, warehouses, and ETL pipelines</li>\n<li>Strong communication skills to effectively collaborate with engineers, project managers, and business stakeholders</li>\n<li>Track record of solving difficult data problems with a wide toolset\u00a0</li>\n<li>Enthusiasm for exploring and testing new technologies</li>\n<li>Creates thoughtful code that is purposefully designed and easily understood</li>\n<li>Critical thinker, able to break down complex problems and work with ambiguity</li>\n</ul>\n<p><strong>Benefits &amp; Perks</strong></p>\n<ul>\n<li>Competitive health, vision and dental benefits</li>\n<li>Healthcare including 100% coverage for Employee + Spouse/family\u00a0</li>\n<li>Dependent care FSA</li>\n<li>Employer-matched 401(k) plan</li>\n<li>Stock incentive program <em>(role dependent)</em></li>\n<li>Paid parental leave</li>\n<li>Goodly - student loan contribution plan</li>\n<li>WFH monthly stipend\u00a0</li>\n<li>Anniversary recognition and awards</li>\n<li>Fitness reimbursement and wellness workshops</li>\n<li>Discounted Pet Health Program</li>\n<li>Flexible time off and work schedule</li>\n<li>Dog-friendly HQ office - we love our fur babies! Check us out on Instagram @dogsofgumgum</li>\n<li>Incredible work/life balance with a collaborative and friendly work space</li>\n<li>A team that has transitioned to remote work impressively, and remains highly collaborative and connected</li>\n<li>GumGum Gives Back volunteering opportunities</li>\n<li>Team building lunches and events, and monthly company celebrations</li>\n<li>Virtual monthly team bonding events</li>\n</ul>\n<p><strong>Career &amp; Development Focus</strong></p>\n<ul>\n<li>Ongoing learning and development for education opportunities such as webinars, books, classes, relevant conferences and events</li>\n<li>Opportunities to pursue business related side projects and yearly Hackathon</li>\n<li>Highly encouraged to contribute to open source software, including our own open source software</li>\n<li>Environment of learning from peers, including meetups, presentations and blog posts</li>\n<li>Opportunity to work with cutting edge technology</li>\n<li>Life Skills sessions - geared towards the whole life/health/person\u00a0</li>\n<li>Leadership Bites Dinner Series - connecting current and future GumGum leaders over great food and meaningful conversation\u00a0</li>\n<li>Stride - our company council committee to share learnings, give updates and provide feedback to the company regarding initiatives and discussions around diversity, inclusion and equity.</li>\n</ul>\n<p><strong>Return to office: Our big vision for our futuristic \u201cFarmhouses\u201d in 2022!</strong></p>\n<ul>\n<li>Offices will now be referred to as the \u201cGumGum Farmhouse\u201d -- a futuristic space centered around a bigger purpose: flexibility, sustainability, community, and growth!</li>\n<li><strong>GumGum will continue to be a flexible/remote-friendly environment</strong>, however, offices will re-open in 2022 for any employees who choose to come in to collaborate, participate in an event, host your clients, contribute to our growing of plants/herbs/vegetables/etc.</li>\n</ul>\n<p><strong><em>Our Values\u2026</em></strong></p>\n<p><em>Thoughtful\u2026</em>We listen to understand different perspectives, show everyone respect, and relentlessly seek solutions for our clients (internal and external)</p>\n<p><em>Agility</em>\u2026We are quick, nimble, and change direction gracefully, while maintaining control.</p>\n<p><em>Grit</em>\u2026We bring energy and perseverance to everything we do.</p>\n<p><strong><em>Our Culture...</em></strong></p>\n<p>GumGum recently earned LA\u2019s Best Places to Work Award in 2021 by BuiltInLA, and Inc. Magazine\u2019s Best Places to Work in 2020 and it\u2019s no surprise why. With company-sponsored social hours, annual holiday celebrations and on-site gatherings, GumGummers enjoy a fun, creative and collaborative workplace. We provide ourselves on our strong track record of giving employees the autonomy and support they need to succeed.\u00a0</p>\n<p>Check us out on Instagram: @gumgum</p>\n"}, {"id": 898392, "url": "https://remotive.io/remote-jobs/data/sr-data-scientist-898392", "title": "Sr. Data Scientist", "company_name": "GridMatrix", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-09-20T01:53:04", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>Role Summary\u00a0&amp; Primary Responsibilities</strong></p>\n<p>The Senior Data Scientist is a full time remote role that will support the technical development and implementation of GridMatrix's core products, including its customer facing dashboard and adaptive signal timing algorithms.\u00a0The Senior Data Scientist is expected to use techniques from machine vision and perception to extract data from live video footage, find ways to use this data to optimize/tune object detection and classification algorithms, and to then use the results of those processes with applied statistical methods to calculate metrics of vehicular and pedestrian traffic flow.\u00a0It would also be beneficial for the Senior Data Scientist to have experience with cloud hosting services for the streaming, processing, and storage of both unstructured and structured data.</p>\n<p></p>\n<p><strong>Basic Skill Qualifications</strong></p>\n<ul><li>4+ YOE with object detection, classification, applied statistical methods for real world problem solving</li><li>Previous experience with machine vision based projects</li><li>Previous experience with data visualization for enterprise audiences</li><li>Previous experience with cloud based development</li><li>BA/BS from an accredited university</li><li>MS or equivalent experience in relevant field such data science, statistics, physics, or engineering</li><li>Machine Learning, Deep Learning, Signal processing</li><li>Programming Languages - Python, R,\u00a0SQL, C</li><li>Fluency is both unsupervised &amp; supervised learning models</li></ul>\n<p></p>\n<p><strong>Reporting Structure &amp; Internal/External Collaboration</strong></p>\n<p>The Senior Data Scientist will report to GridMatrix's VP of Engineering, and work closely with its CTO, CEO, and other members of GridMatrix's technical organization, including other Data Science and DevOps engineering staff.\u00a0In addition, the Senior Data Scientist will work with GridMatrix's technical advisory staff, which currently includes an advisor for Autonomous Vehicle Technology, an advisor for Machine Vision, and an advisor for Machine Learning &amp; Data Science.</p>\n<p></p>\n<p>The Senior Data Scientist will also work closely with GridMatrix's external engineering development teams.</p>\n<p></p>\n<p><strong>Research &amp; Development</strong></p>\n<p>The Senior Data Scientist will participate in GridMatrix's research and development activities.\u00a0These will include the development of the company's core intellectual property, as well as serving as a support for GridMatrix's Principal Investigator as well as an independent contributor on successful grant opportunities.\u00a0As a result of these activities, GridMatrix may seek to disclose resulting intellectual property in either professional publications or patent applications.\u00a0</p>\n<p></p>\n<p><strong>Grant Writing</strong></p>\n<p>The Senior Data Scientist will contribute to grant proposal writing efforts.\u00a0These contributions will include the development of grant proposal content, preliminary data gathering, and leveraging internal and external resources as necessary to submit timely and comprehensive proposals.</p>\n<p></p>\n<p><strong>External RFPs and RFQs</strong></p>\n<p>From time-to-time, GridMatrix may respond to requests for proposals (RFPs) and request for quotes (RFQs) issued by cities, states, or other municipalities.\u00a0These RFPs and RFQs may include the opportunity for GridMatrix to supply the issuer with goods and services.\u00a0Portions of these RFPs and RFQs may require technical descriptions of these goods and services.\u00a0In these cases, the Senior Data Scientist may contribute to the development of original content to support GridMatrix's timely and comprehensive response to the RFP.</p>\n<p></p>\n<p><strong>Conferences &amp; Travel</strong></p>\n<p>In this role, the Senior Data Scientist may be required to travel to support GridMatrix's business needs.\u00a0These needs may include both domestic and international travel to represent the company at industry conferences and demonstrations of its technology to prospective customers and other stakeholders.</p>\n<p></p>\n<p><strong>Technical Requirement Development</strong></p>\n<p>The Senior Data Scientist will be expected to contribute to the production of technical requirements documents (TRDs).\u00a0These TRDs will be used both to define product development and also as components of GridMatrix's RFPs to candidate suppliers for goods and services.\u00a0Not only will these TRDs allow GridMatrix to competitively source it's purchases, they will serve as product development artifacts that can be used for future iteration and development.</p>\n<p></p>\n<p><strong>Product Development Timelines</strong></p>\n<p>The Senior Data Scientist will be expected to contribute to product development timelines, including highlighting expected delivery dates and technical risks.</p>\n<p></p>\n<p><strong>Equity Compensation</strong></p>\n<p>The Senior Data Scientist will be eligible to receive performance based equity compensation.</p>\n<p></p>\n<p><strong>Salary &amp; Other Compensation</strong></p>\n<p>GridMatrix offers competitive compensation, including salary, medical, dental, vision, life insurance, company supplied computer, annual WeWork subscription, as well as a 401K plan.</p>\n<p></p>\n<p><strong>EQUAL OPPORTUNITY</strong></p>\n<p>GridMatrix welcomes applications from individuals with diverse professional backgrounds. GridMatrix is an equal opportunity employer that is committed to diversity and inclusion in the workplace. We prohibit discrimination and harassment of any kind based on race, color, sex, religion, sexual orientation, national origin, disability, genetic information, pregnancy, or any other protected characteristic as outlined by federal, state, or local laws.</p>\n<p></p>\n<p>This policy applies to all employment practices within our organization, including hiring, recruiting, promotion, termination, layoff, recall, leave of absence, compensation, benefits, training, and apprenticeship. GridMatrix makes hiring decisions based solely on qualifications, merit, and business needs at the time.</p>\n"}, {"id": 890894, "url": "https://remotive.io/remote-jobs/data/senior-data-analyst-operations-and-marketing-890894", "title": "Senior Data Analyst, Operations and Marketing", "company_name": "Stack Influence", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-09-15T05:43:15", "candidate_required_location": "Anywhere", "salary": "", "description": "<p>Stack Influence is an influencer marketing platform on a mission to connect brands with everyday people. We are a venture-backed startup featured in publications like WIRED, Business Insider, WWD and Quartz, our platform is home to one of the largest micro-influencer communities in the United States.</p>\n<p>We're hiring for our first Data Analyst to build on our data-driven approach. This is a high leverage position. From discovery analyses to AB testing, you will be responsible for all things data in our company. You will directly partner with our 3 co-founders to improve our product and grow our marketplace business. This is a remote, full-time contractor position. Non-US citizens are encouraged to apply.<strong>\u00a0</strong></p>\n<p><u>Our Data Stack: <br></u>Spreadsheets, PostgreSQL, MongoDB, Metabase, Mixpanel, Google Analytics, Instagram, Sendgrid, Woodpecker, Performance Marketing (Google, Facebook ads), Jungle Scout, Lucky Orange, Hubspot<br><strong><br>Qualifications</strong>:</p>\n<ul>\n<li>2+ years of technical skills related to data and analytics</li>\n<li>A previous role in analytics, growth, product management or operations departments of a software or software-enabled company</li>\n<li>Highly skilled at relational databases and writing complex SQL queries</li>\n<li>Highly skilled at Excel</li>\n<li>Ability to use data and metrics to back up assumptions, make recommendations, and drive actions</li>\n<li>Self-motivated, independent, and proactive</li>\n<li>Outstanding communication and presentation abilities, written and verbal</li>\n</ul>\n<p><strong>Nice to have</strong>:\u00a0</p>\n<ul>\n<li>Experience with BI Tools (Tableau,Looker,Power BI, Metabase,etc)</li>\n<li>Experience with\u00a0Paid advertising (such as Google, Bing, Facebook, etc)</li>\n<li>Experience with conversion rate optimization (CRO) using A/B/Multivariate tools (such as Lucky Orange, Optimizely, Google Optimize, Hotjar, etc)</li>\n<li>Experience with CRMs (such as Hubspot, SalesForce, Zoho, etc)</li>\n<li>Javascript or Python programming skills</li>\n</ul>\n<p>\u00a0</p>\n<p><strong>Expectations and Responsibilities:\u00a0</strong></p>\n<ul>\n<li>Measure, analyze and develop a deep understanding of our product, data and customer lifecycle including acquisition, engagement and retention.</li>\n<li>Collaborate with our product, sales, marketing and operations teams to solve problems and identify trends and opportunities.</li>\n<li>Query and update data, build dashboards, and keep a watchful eye on the overall health of our marketplace</li>\n<li>Develop interesting insights about our marketplace and industry to drive data-driven content marketing</li>\n<li>Combine and leverage internal and external data from multiple sources, including web, application, email, and down-funnel</li>\n<li>Develop and own strategies to coordinate, execute, and analyze A/B and multivariate tests to improve operations and marketing conversion rates</li>\n<li>Initiate and drive projects to completion with minimal guidance</li>\n<li>Translate and communicate results to stakeholders, adjusting the level of technical detail as needed</li>\n</ul>\n<p>\u00a0</p>\n"}, {"id": 881013, "url": "https://remotive.io/remote-jobs/data/senior-data-engineer-881013", "title": "Senior Data Engineer", "company_name": "PubNative", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-09-14T21:45:48", "candidate_required_location": "USA Only", "salary": "", "description": "<p><strong>Who we are</strong></p>\n<p><br></p>\n<p dir=\"ltr\">Verve Group\u2019s omnichannel ad platform connects advertisers, agencies, brands, and publishers to people in real-time. With a privacy-first approach, Verve Group offers advertising innovation at scale with full-stack programmatic solutions in brand-safe environments. The global company is a trusted partner of 5,000+ advertisers and brands with direct connections to 4,000+ publishers and apps globally. Verve Group is part of Media and Games Invest (MGI) and has an international presence with over 200 employees in 20+ offices worldwide, spanning the Americas, EMEA, and APAC. Learn more at <a href=\"https://www.verve.com\" rel=\"nofollow\">www.verve.com</a>.</p>\n<p><br></p>\n<p>The <strong>Data Engineering</strong> <strong>team</strong> is looking for a self-driven, software engineering professional.  Candidates must have solid foundational skills and professional experience working on/developing large-scale data processing systems.  They must be able to work with business and technical stakeholders to accurately define requirements and quickly turn around solutions that balance time-to-market concerns with solid engineering/operational principles in a geographically diverse environment.  In addition to development responsibilities, candidates will be expected to provide 2nd/3rd tier operational support.<br></p>\n<p>We are looking for someone who wants to build data pipelines and won\u2019t shy away from playing the detective for some data analysis once in a while.</p>\n<p><strong></strong></p>\n<p><br></p>\n<p><strong>Your Responsibilities:</strong><br></p>\n<ul><li>Interact with stakeholders to define actionable requirements/deliverables, balancing business value with time-to-market</li><li>Interact with project management to define deliverables and accurate timelines</li><li>Provide 2<sup>nd</sup>/3<sup>rd</sup> tier support, in collaboration with business and other technical teams\u00a0</li><li>Master current tools/technologies, and introduce new tools/technologies as gaps in functionality/performance/operability are identified</li><li>Appreciate solving big-data problems that ensure Verve Group remains a market leader</li></ul><ul><li>5-7 years professional software development experience</li><li>3-5 years data engineering experience</li><li>Python/Java/Scala</li><li>Solid SQL skills</li><li>Git experience preferred</li><li>Maven/Gradle or similar build environment tools</li><li>2+ years professional experience working with/developing for Hadoop 2.x and/or Spark</li><li>Professional experience working with/developing for distributed data stores (Snowflake, BigQuery, Couchbase, etc)</li><li>Professional experience working with RDBMS (MySQL, PostGres, etc)</li><li>Experience working in AWS and/or GCP</li><li>Experience working in a Linux/UNIX system</li><li><strong>Work authorization in the US</strong></li></ul>\n<p><br><strong>What we offer:</strong><strong></strong></p>\n<ul><li>Join one of the top mobile advertising companies in the world</li><li>You work with a highly motivated and skilled team of high potentials</li><li>Responsibility, independence, and an opportunity to participate in projects that have a significant impact on Verve Group\u2019s success</li><li>Unlimited vacation days/year</li><li>Medical Insurance<ul><li>Vision &amp; Dental insurance</li></ul></li><li>Life Insurance</li><li><p dir=\"ltr\">AD&amp;D Insurance\u00a0</p></li><li><p dir=\"ltr\">Mobile phone allowance</p></li><li>Work with data that is ACTUALLY big (10s - 100s of Tbs)</li><li>Plenty of flexibility in tech/tooling (if you can justify it)</li><li>Great work-life balance</li></ul>\n<p><strong>Interested? - Please submit your 1-Page CV online + Github, Stack Overflow, blog or Twitter link if you have one.</strong></p>"}, {"id": 890274, "url": "https://remotive.io/remote-jobs/data/healthcare-data-scientist-890274", "title": "Healthcare Data Scientist", "company_name": "John Snow Labs", "category": "Data", "tags": [], "job_type": "contract", "publication_date": "2021-09-14T02:20:35", "candidate_required_location": "Anywhere", "salary": "", "description": "<div class=\"h3\">Company Description</div>\n<p>John Snow Labs is an award-winning AI and NLP company, accelerating progress in data science by providing state-of-the-art software, data, and models. Founded in 2015, it helps healthcare and life science companies build, deploy, and operate AI products and services. John Snow Labs is the winner of the 2018 AI Solution Provider of the Year Award, the 2019 AI Platform of the Year Award, the 2019 International Data Science Foundation Technology award, and the 2020 AI Excellence Award.</p>\n<p>John Snow Labs is the developer of Spark NLP - the world\u2019s most widely used NLP library in the enterprise - and is the world\u2019s leading provider of state-of-the-art clinical NLP software, powering some of the world\u2019s largest healthcare &amp; pharma companies. John Snow Labs is a global team of specialists, of which 33% hold a Ph.D. or M.D. and 75% hold at least a Master\u2019s degree in disciplines covering data science, medicine, software engineering, pharmacy, DevOps and SecOps.</p>\n<p><br><br></p>\n<div class=\"h3\">Job Description</div>\n<p>We are looking for a superstar data scientist, who is familiar and experienced with applying machine learning and deep learning in the area of healthcare. This role requires proven hands-on experience training and optimizing models, building production-ready inference pipelines in Python, performing exploratory data analysis &amp; enrichment, and validating models for issues like bias, overfitting, and concept drift.</p>\n<p>Since we primarily work in healthcare and life science, background in medicine, pharma, bioinformatics, or biostatistics is highly beneficial. A PhD degree in a relevant field is preferred.</p>\n<p><br><br></p>\n<div class=\"h3\">Qualifications</div>\n<p>The primary responsibilities will be working as part of a team in customer-facing projects - building models and machine learning, deep learning, natural language processing, and time series forecasting pipelines that address specific business needs. Working knowledge of Python and TensorFlow are a must; experience with Spark, Spark NLP, and other technology stacks is a big plus. The customer facing aspect of this role also requires strong oral &amp; written communication skills.<br><br>We are looking for experts who are looking for long-term freelancing contracts, and wish to work on cutting-edge problems, learn and grow. This role for individuals who can commit at least 30 hours per week to this project. We are not able to consider agency or team applications.<br><br>This is a career opportunity that will enable you to expand your knowledge and experience of different tools and techniques, work within a team of big data and data science experts, and make a positive impact with your work. If you quality and are interested, please include the words 'John Snow Labs' in your cover letter and explain why you are the best fit for this role.</p>\n<p><br><br></p>\n<div class=\"h3\">Additional Information</div>\n<ul>\n<li>We are a fully virtual company, collaborating across 22 countries.</li>\n<li>Open to candidates worldwide - work remotely from anywhere.</li>\n<li>This is a contract opportunity, not a full-time employment role.</li>\n<li>This role requires the availability of at least 30 hours per week.</li>\n</ul>\n"}, {"id": 888771, "url": "https://remotive.io/remote-jobs/data/marketing-data-analyst-888771", "title": "Marketing Data Analyst", "company_name": "The Dyrt", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-09-12T05:54:17", "candidate_required_location": "USA Only", "salary": "", "description": "<p>The Dyrt is the largest digital camping platform in the world. Every second, a new user visits The Dyrt to access our community-driven campground information.</p>\n<p>If you love the outdoors and want to be part of a fast-growing consumer app,\u00a0 you're in the right place.</p>\n<p>The Role</p>\n<p>The Dyrt is hiring our first-ever full time Marketing Data Analyst.\u00a0</p>\n<p>Do you love discovering new, game-changing views into big data sets? Do you feel right at home owning data manipulation from multiple third party sources? Are you able to find new inferences about user behavior in marketing data and communicate them clearly in dashboards?\u00a0</p>\n<p>If you answered yes, we'd love to hear from you.\u00a0</p>\n<p>You will be responsible for:\u00a0</p>\n<ul>\n<li>Ownership of marketing data</li>\n<li>Dashboard setup and maintenance</li>\n<li>Driving marketing insights by analyzing all marketing data</li>\n<li>Ensuring that The Dyrt's data pipeline remains functional and trustworthy</li>\n<li>Developing frameworks and KPIs tied to company success</li>\n<li>Building models to identify growth opportunities</li>\n<li>Support a data-driven culture with your passion for data-based storytelling and communication</li>\n</ul>\n<p>Your skills include:</p>\n<ul>\n<li>Advanced proficiency in SQL and a statistical package such as R or Python</li>\n<li>Understanding of marketing psychology\u00a0</li>\n<li>Ability to quickly analyze large data and draw inferences</li>\n<li>Strong communication skills with both engineering teams and marketing teams</li>\n<li>Ability to talk through a data problem and come up with a way to fix it</li>\n<li>Understanding of an analytics stack including desktop and mobile app platforms such as google tag manager, web events, app events, firebase, branch, bigquery, iterable, mode</li>\n<li>Advanced understanding of statistical analysis models</li>\n<li>Ability to weigh multiple ways to answer a question and identify the most time-efficient report</li>\n</ul>\n<p>Your qualifications:</p>\n<ul>\n<li>5+ years of experience using Mode, Lookr, or similar BI tool to create reports</li>\n<li>Experience coordinating a data pipeline that ingests millions of data from web users, app users, third-party ad networks, CRMs, and more inputs</li>\n</ul>\n<p>Working Here</p>\n<p>The Dyrt is built by campers, for campers\u2014whether you're new to camping or have been camping your whole life.\u00a0</p>\n<p>We encourage everyone to spend more time outside, including employees. We offer competitive market-rate salaries, a generous vacation plan, and we even pay employee bonuses for using The Dyrt in the wild.</p>\n<p>This is a full-time remote position. Employees are expected to have high-speed internet and a professional working environment sufficient for clear video conferencing during regular working hours. Many of our employees work virtually from Portland, OR but we're flexible on location and encourage all to explore. Our founders even <a href=\"https://www.fox21news.com/news/camping-couple-develops-popular-app-to-help-plan-trips/\" rel=\"nofollow\">work from their van</a>.</p>\n<p>The Dyrt is an equal opportunity workplace. We are especially proud to have a female founder and a higher percentage of female employees than the national average for tech companies. We believe that the outdoors are for everyone, and are committed to building an inclusive platform and community that encourages, supports, and celebrates all people interested in camping.</p>\n<p>Interested candidates should submit a cover letter and resume.</p>\n<p>About The Dyrt</p>\n<p>The Dyrt was started in Portland, OR, is venture-backed, and has 40-50 employees working virtually around the U.S.</p>\n"}, {"id": 883653, "url": "https://remotive.io/remote-jobs/data/data-analyst-883653", "title": "Data Analyst", "company_name": "Uken", "category": "Data", "tags": [], "job_type": "full_time", "publication_date": "2021-09-11T02:31:06", "candidate_required_location": "Canada Only", "salary": "", "description": "<p>Uken builds games that people everywhere love. Who Wants To Be A Millionaire? and Jeopardy! World Tour are the top 2 trivia games, engaging millions of global players every month. In 2020, Uken released Ava\u2019s Manor, a solitaire game where users renovate and decorate the manor while discovering mysterious clues and dabbling in a romantic love story. Uken\u2019s foray into narrative games is an exciting opportunity for the company.\u00a0</p>\n<p>\u00a0</p>\n<p>We consider our\u00a0<strong>Ukenites</strong>\u00a0to be data-driven designers, technologists, and artists. Through collaboration, we pair the craft of design with feedback and data to deliver a pace and rhythm in each game session that immerses our audience and engages them for years. We have a quirky, nerdy culture that fosters creativity, collaboration, quality ideas, innovation, and a data-driven mindset. We believe in moving quickly and improving constantly and that mantra is reflected in the weekly updates we make to our games and internal technologies. We have an appetite for pushing technical boundaries but with a focus on practical use.</p>\n<p>\u00a0</p>\n<p>Uken is looking for a <strong>Data Analyst</strong> to join our team. You will play a vital role in improving existing games and launching new ones by providing Product Managers the tools and insights into player behavior. You will be deeply involved in our data-driven game design process by working closely with game designers. Your role in that process is to analyze and build the datasets used to make sense of our players by building reports and visualizations, developing new metrics, and providing actionable insights about our players.</p>\n<p>\u00a0</p>\n<p>As a\u00a0<strong>Ukenite</strong>, you'll be working on meaningful things like:\u00a0</p>\n<ul>\n<ul>\n<li>Answering business-related questions through exploratory data analyses and ad-hoc reporting that drives engagement, retention, and monetization</li>\n<li>Building data visualizations used by the Product and Leadership teams\u00a0</li>\n<li>Developing new metrics and player cohorts to unlock insights into player behavior</li>\n<li>Continually trying to improve our A/B test analysis process through new tooling and automation</li>\n<li>Deep diving into user behavior to unlock value for the product team</li>\n<li>Collaborating across data teams in the organization to improve data-driven decision-making and elevate Uken\u2019s use of data science.\u00a0</li>\n</ul>\n</ul>\n<p>\u00a0</p>\n<p>Your\u00a0<strong>background\u00a0</strong>should include:\u00a0</p>\n<ul>\n<ul>\n<li>2 years writing complex queries in SQL preferably Redshift</li>\n<li>Attention to detail and proven organization and analytical skills</li>\n<li>Ability to communicate and present information clearly</li>\n<li>Proficiency in Python and/or statistical modeling</li>\n<li>An appetite to learn, grow and take on increasingly more responsibility</li>\n<li>A desire to answer questions that drive business outcomes</li>\n<li>Passion/knowledge of the mobile gaming industry\u00a0</li>\n</ul>\n</ul>\n<p>\u00a0</p>\n<p>It is a\u00a0<strong>big plus</strong>\u00a0if you have:</p>\n<ul>\n<ul>\n<li>Previous experience at a startup or mobile game/app company</li>\n<li>Degree in statistics, economics, math, or a related field</li>\n<li>Experience in a Product Management / Data Analyst role</li>\n<li>Proficiency in Scala</li>\n</ul>\n</ul>\n<p>\u00a0</p>\n<p>What's in it for\u00a0<strong>you</strong>?</p>\n<ul>\n<li>You\u2019ll be equipped with a high-end PC or laptop\u00a0</li>\n<li>Competitive compensation and benefits</li>\n<li>Fully catered lunch, breakfast, and a snack filled kitchen (in-office)</li>\n<li>Uken social nights including mixers, game night, and more - we take entertainment seriously!</li>\n<li>Office-based or home-based work options\u00a0</li>\n<li>Convenient location in the heart of downtown Toronto at Front &amp; John St.\u00a0</li>\n</ul>\n<p>At Uken, we believe there is power in diversity and strive for a diverse, inclusive, and accessible environment. Our ongoing innovative journey relies on each Ukenite to be different. All qualified applicants will be assessed equally regardless of race, ethnicity, national origin, religion, age, sex, sexual attraction, gender identity, or expression, and would not face discrimination based on disability.\u00a0\u00a0</p>\n<p>\u00a0</p>\n<p>Uken is committed to offering reasonable accommodation to job applicants with disabilities. If you need assistance or accommodation due to a disability, please contact us at jobs@uken.com</p>\n"}]}